2018-02-07 18:35:51.245012: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-07 18:35:51.245045: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-07 18:35:51.245055: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-07 18:35:51.410410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-02-07 18:35:51.410701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1060 3GB
major: 6 minor: 1 memoryClockRate (GHz) 1.7085
pciBusID 0000:01:00.0
Total memory: 2.95GiB
Free memory: 2.83GiB
2018-02-07 18:35:51.410720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2018-02-07 18:35:51.410730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2018-02-07 18:35:51.410745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
/home/wilhelmb/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
INFO:hpbandster:DISPATCHER: started the 'discover_worker' thread
INFO:hpbandster:DISPATCHER: started the 'job_runner' thread
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f6bbed60320; connected IPv4; for PYRO:Pyro.NameServer@localhost:34411>
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: No dispatcher found. Waiting for one to initiate contact.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start listening for jobs
INFO:hpbandster:DISPATCHER: Pyro daemon running on localhost:37891
DEBUG:hpbandster:HBMASTER: only 0 worker(s) available, waiting for at least 1.
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 0 currently in the pool.
INFO:hpbandster:DISPATCHER: discovered new worker, hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
INFO:hpbandster:HBMASTER: starting run at 1518024952.9292104
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 0) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1615748165616192, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.10979178369723078, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11195357320430643, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:35:53.862424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
oprimizing data augmentation.
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.9442 - acc: 0.1198 - val_loss: 13.6043 - val_acc: 0.1560
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 0)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10979178369723078, 'base_model': 'MobileNet', 'zoom_range': 0.1615748165616192, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.11195357320430643, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8440366969059366, 'info': {'runtime': 13.46507978439331, 'histories': {'val_acc': [0.15596330309406334], 'loss': [12.669938335679982], 'acc': [0.13013698630136986], 'val_loss': [13.604264075602961]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 1) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.03335897146502426, 'rotation_range': 25, 'optimizer': 'RMSProp', 'width_shift_range': 0.15621363774394645, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2992239297459091, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:36:07.449063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.2351 - acc: 0.0946 - val_loss: 14.7693 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 1)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.15621363774394645, 'base_model': 'MobileNet', 'zoom_range': 0.03335897146502426, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 25, 'height_shift_range': 0.2992239297459091, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9174311926605505, 'info': {'runtime': 12.529710054397583, 'histories': {'val_acc': [0.08256880733944955], 'loss': [12.985943702802267], 'acc': [0.10273972602739725], 'val_loss': [14.76933547553666]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.11758321651974399, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.10070966715551875, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20470170513612515, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:36:20.028736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.0026 - acc: 0.0883 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 2)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10070966715551875, 'base_model': 'MobileNet', 'zoom_range': 0.11758321651974399, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.20470170513612515, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082565389642, 'info': {'runtime': 14.785730838775635, 'histories': {'val_acc': [0.11009174346103581], 'loss': [13.019884841082847], 'acc': [0.0958904109589041], 'val_loss': [14.343625926096506]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 3) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 4) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 3)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.21494069527672466, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.07031415802613059, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.26052005495992797, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:36:34.843001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.1543 - acc: 0.1062 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 3), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 3)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.07031415802613059, 'base_model': 'MobileNet', 'zoom_range': 0.21494069527672466, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.26052005495992797, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082561971945, 'info': {'runtime': 14.5344398021698, 'histories': {'val_acc': [0.11009174380280556], 'loss': [13.154342651367188], 'acc': [0.10625], 'val_loss': [14.343626066085395]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 3)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 4)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 4) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 4) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 5) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 4)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.286911158397518, 'rotation_range': 30, 'optimizer': 'RMSProp', 'width_shift_range': 0.037640477768603464, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.19183815915625374, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:36:49.418584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.2305 - acc: 0.0504 - val_loss: 14.9351 - val_acc: 0.0734
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 4), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 4) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 4) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 4)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.037640477768603464, 'base_model': 'MobileNet', 'zoom_range': 0.286911158397518, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 30, 'height_shift_range': 0.19183815915625374, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.926605504587156, 'info': {'runtime': 13.319486856460571, 'histories': {'val_acc': [0.07339449541284404], 'loss': [12.980984753125334], 'acc': [0.0547945205479452], 'val_loss': [14.935115639222872]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 4)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 5)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 5) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 6) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 5) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 5)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.20912891623240615, 'rotation_range': 27, 'optimizer': 'RMSProp', 'width_shift_range': 0.2345429104691896, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.19503664154640823, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:37:02.732421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 9s - loss: 13.2577 - acc: 0.1009 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 5), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 5) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 5) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 5) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 5)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2345429104691896, 'base_model': 'MobileNet', 'zoom_range': 0.20912891623240615, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 27, 'height_shift_range': 0.19503664154640823, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082561971945, 'info': {'runtime': 13.435479879379272, 'histories': {'val_acc': [0.11009174380280556], 'loss': [13.010491462603007], 'acc': [0.1095890410958904], 'val_loss': [14.343626346063177]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 5)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 6)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 6) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 6) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 6)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.17970575927850335, 'rotation_range': 8, 'optimizer': 'RMSProp', 'width_shift_range': 0.039372880631540395, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08427138156437648, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:37:16.206545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.0100 - acc: 0.0757 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 6), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 6) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 6) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 6) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 6)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.039372880631540395, 'base_model': 'MobileNet', 'zoom_range': 0.17970575927850335, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 8, 'height_shift_range': 0.08427138156437648, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082549668234, 'info': {'runtime': 13.086380958557129, 'histories': {'val_acc': [0.11009174503317666], 'loss': [11.654951173965244], 'acc': [0.0821917808219178], 'val_loss': [14.343625812355532]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 6)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 7)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 7) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 8) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 7)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2892001144443167, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.2870985207906671, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.25925836847713396, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:37:29.324541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 9s - loss: 9.5903 - acc: 0.0820 - val_loss: 2.3699 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 7), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 7)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2870985207906671, 'base_model': 'MobileNet', 'zoom_range': 0.2892001144443167, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.25925836847713396, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853191870068, 'info': {'runtime': 13.38224744796753, 'histories': {'val_acc': [0.1376146808129932], 'loss': [9.026192808804447], 'acc': [0.08904109589041095], 'val_loss': [2.3698588226913313]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 7)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 8)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 8) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 8)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2831500712306704, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.11553792182868505, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.10673317706594039, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:37:42.749710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 6.0493 - acc: 0.0820 - val_loss: 2.2954 - val_acc: 0.2202
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 8), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 8) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 8)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11553792182868505, 'base_model': 'MobileNet', 'zoom_range': 0.2831500712306704, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.10673317706594039, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.7798165134196982, 'info': {'runtime': 13.998685598373413, 'histories': {'val_acc': [0.22018348658030187], 'loss': [6.329326681894798], 'acc': [0.08904109589041095], 'val_loss': [2.2954342080912458]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 8)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 9) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 10) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.0016573244368102479, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:37:56.793318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.0105 - acc: 0.1135 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 9)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0016573244368102479, 'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853211009174, 'info': {'runtime': 13.3138747215271, 'histories': {'val_acc': [0.13761467889908258], 'loss': [13.943314447794876], 'acc': [0.1232876712328767], 'val_loss': [13.900008945290102]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 10)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 10) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 10) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 11) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 10)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.22809095389344372, 'rotation_range': 16, 'optimizer': 'RMSProp', 'width_shift_range': 0.0037594038013924022, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.17538212958163682, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:38:10.139803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 14.0299 - acc: 0.0441 - val_loss: 14.4915 - val_acc: 0.1009
/home/wilhelmb/.local/lib/python3.5/site-packages/matplotlib/pyplot.py:528: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 10), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 10) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 10) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 10) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 10)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0037594038013924022, 'base_model': 'MobileNet', 'zoom_range': 0.22809095389344372, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 16, 'height_shift_range': 0.17538212958163682, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825674402605, 'info': {'runtime': 13.104490041732788, 'histories': {'val_acc': [0.10091743255973956], 'loss': [13.849465304858064], 'acc': [0.04794520547945205], 'val_loss': [14.491498737160219]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 10)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 11)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 11) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 11) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 12) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 11)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0024520947335602726, 'rotation_range': 21, 'optimizer': 'RMSProp', 'width_shift_range': 0.10191886665617374, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11298832790106196, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:38:23.285700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.1700 - acc: 0.1659 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 11), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 11) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 11) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 11)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10191886665617374, 'base_model': 'MobileNet', 'zoom_range': 0.0024520947335602726, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 21, 'height_shift_range': 0.11298832790106196, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 13.759176015853882, 'histories': {'val_acc': [0.0917431196078248], 'loss': [12.525314762167735], 'acc': [0.136986301369863], 'val_loss': [14.639370769535729]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 11)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 12)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 12) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 13) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 12)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.08604319910868594, 'rotation_range': 13, 'optimizer': 'RMSProp', 'width_shift_range': 0.0634226513793555, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.015345808165384521, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:38:37.077642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 10.5991 - acc: 0.0820 - val_loss: 2.4668 - val_acc: 0.1284
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 12), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 12) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 12) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 12)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0634226513793555, 'base_model': 'MobileNet', 'zoom_range': 0.08604319910868594, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 13, 'height_shift_range': 0.015345808165384521, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8715596323439834, 'info': {'runtime': 13.145697832107544, 'histories': {'val_acc': [0.12844036765601657], 'loss': [10.725095618261049], 'acc': [0.08904109589041095], 'val_loss': [2.4668499439134512]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 12)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 13)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 13) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 14) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 13)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06820092188942994, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.192308306823341, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21691925104091167, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:38:50.270123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.1082 - acc: 0.1072 - val_loss: 13.6043 - val_acc: 0.1560
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 13), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 13) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 13)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.192308306823341, 'base_model': 'MobileNet', 'zoom_range': 0.06820092188942994, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.21691925104091167, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8440366965641669, 'info': {'runtime': 12.657438516616821, 'histories': {'val_acc': [0.1559633034358331], 'loss': [12.848070614958463], 'acc': [0.11643835616438356], 'val_loss': [13.604264101850877]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 13)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 14)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 14) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 15) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 14)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.01643039131198417, 'rotation_range': 22, 'optimizer': 'RMSProp', 'width_shift_range': 0.11270778363117744, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1941747457255058, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:39:02.968720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.5762 - acc: 0.0625 - val_loss: 14.9351 - val_acc: 0.0734
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 14), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 14) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 14) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 14)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11270778363117744, 'base_model': 'MobileNet', 'zoom_range': 0.01643039131198417, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 22, 'height_shift_range': 0.1941747457255058, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9266055042453862, 'info': {'runtime': 12.75429391860962, 'histories': {'val_acc': [0.07339449575461379], 'loss': [13.576184606552124], 'acc': [0.0625], 'val_loss': [14.935115665470788]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 14)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 15)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 15) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 15) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 16) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 15)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.17135563264410716, 'rotation_range': 17, 'optimizer': 'RMSProp', 'width_shift_range': 0.21119687738448972, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.22054941427252722, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:39:15.765805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.3451 - acc: 0.0883 - val_loss: 15.0830 - val_acc: 0.0642
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 15), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 15) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 15) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 15)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21119687738448972, 'base_model': 'MobileNet', 'zoom_range': 0.17135563264410716, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 17, 'height_shift_range': 0.22054941427252722, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.935779815830222, 'info': {'runtime': 13.719754695892334, 'histories': {'val_acc': [0.06422018416977804], 'loss': [13.105483277203286], 'acc': [0.0958904109589041], 'val_loss': [15.082988030319914]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 15)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 16)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 16) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 16) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 17) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 16)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.26286903122583827, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.28498521401692745, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2328438546173066, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:39:29.528164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.1830 - acc: 0.1343 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 16), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 16) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 16) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 16) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 16)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.28498521401692745, 'base_model': 'MobileNet', 'zoom_range': 0.26286903122583827, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.2328438546173066, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 12.588245391845703, 'histories': {'val_acc': [0.0917431196078248], 'loss': [12.539338516862426], 'acc': [0.10273972602739725], 'val_loss': [14.639370769535729]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 16)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 17)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 17) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 17) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 18) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 17)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.12462703367746998, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.00807731323845926, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.23473308673019236, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:39:42.149677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.5431 - acc: 0.0693 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 17), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 17) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 17) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 17) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 17)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.00807731323845926, 'base_model': 'MobileNet', 'zoom_range': 0.12462703367746998, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.23473308673019236, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568800504054, 'info': {'runtime': 13.043007612228394, 'histories': {'val_acc': [0.09174311994959455], 'loss': [13.656529831559691], 'acc': [0.07534246575342465], 'val_loss': [14.639370515805865]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 17)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 18)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 18) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 18) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 19) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 18)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.02022201430896606, 'rotation_range': 8, 'optimizer': 'RMSProp', 'width_shift_range': 0.07728331571856725, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.24796269534834067, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:39:55.239790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.2871 - acc: 0.0946 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 18), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 18) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 18) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 18) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 18)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.07728331571856725, 'base_model': 'MobileNet', 'zoom_range': 0.02022201430896606, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 8, 'height_shift_range': 0.24796269534834067, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082549668234, 'info': {'runtime': 12.96132493019104, 'histories': {'val_acc': [0.11009174503317666], 'loss': [13.04246123849529], 'acc': [0.10273972602739725], 'val_loss': [14.343626092333313]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 18)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 19)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 19) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 20) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 19)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.19956006504962495, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.18472340643110186, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08962149295842833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:40:08.236464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.8244 - acc: 0.1135 - val_loss: 13.4564 - val_acc: 0.1651
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 19), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 19) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 19)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.18472340643110186, 'base_model': 'MobileNet', 'zoom_range': 0.19956006504962495, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.08962149295842833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8348623849793312, 'info': {'runtime': 13.267812252044678, 'histories': {'val_acc': [0.16513761502066884], 'loss': [12.539791211689987], 'acc': [0.1232876712328767], 'val_loss': [13.456391850742724]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 19)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 20)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 20) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 21) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 20)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.08997505136600327, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:40:21.545811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.1906 - acc: 0.1313 - val_loss: 13.7162 - val_acc: 0.1468
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 20), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 20) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 20)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08997505136600327, 'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8532110084907725, 'info': {'runtime': 13.502701759338379, 'histories': {'val_acc': [0.14678899150922758], 'loss': [12.19057559967041], 'acc': [0.13125], 'val_loss': [13.716217819703829]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 20)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 21)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 21) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 21) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 22) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 21)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.023241694225583597, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.0387782701950154, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.23887799383939276, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:40:35.093115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 11.9270 - acc: 0.1500 - val_loss: 14.6391 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 21), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 21) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 21) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 21) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 21)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0387782701950154, 'base_model': 'MobileNet', 'zoom_range': 0.023241694225583597, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.23887799383939276, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.908256880733945, 'info': {'runtime': 13.75886583328247, 'histories': {'val_acc': [0.09174311926605505], 'loss': [11.926958775520324], 'acc': [0.15], 'val_loss': [14.639079732632418]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 21)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 22)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 22) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 23) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 22) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 22)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.11606908783247312, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.16207434500795112, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20356610496270305, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:40:48.890875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.7291 - acc: 0.0750 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 22), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 22) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 22) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 22)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.16207434500795112, 'base_model': 'MobileNet', 'zoom_range': 0.11606908783247312, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.20356610496270305, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825681237999, 'info': {'runtime': 12.944940328598022, 'histories': {'val_acc': [0.10091743187620006], 'loss': [13.729141139984131], 'acc': [0.075], 'val_loss': [14.49149829094563]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 22)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 23)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 23) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 23) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 24) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 23)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1301221129616232, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.04054930041539948, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.19754006888175035, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:41:01.880440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.4593 - acc: 0.0693 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 23), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 23) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 23) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 23) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 23)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.04054930041539948, 'base_model': 'MobileNet', 'zoom_range': 0.1301221129616232, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.19754006888175035, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825681237999, 'info': {'runtime': 13.49109435081482, 'histories': {'val_acc': [0.10091743187620006], 'loss': [13.2294989807965], 'acc': [0.07534246575342465], 'val_loss': [14.49149829094563]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 23)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 24)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 24) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 24) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 25) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 24)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.10760502067562971, 'rotation_range': 22, 'optimizer': 'RMSProp', 'width_shift_range': 0.28219602476542816, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.051096081849754046, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:41:15.403114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.4221 - acc: 0.0693 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 24), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 24) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 24) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 24) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 24)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.28219602476542816, 'base_model': 'MobileNet', 'zoom_range': 0.10760502067562971, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 22, 'height_shift_range': 0.051096081849754046, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825668934288, 'info': {'runtime': 13.31159234046936, 'histories': {'val_acc': [0.10091743310657117], 'loss': [13.189131854331656], 'acc': [0.07534246575342465], 'val_loss': [14.491498317193548]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 24)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 25)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 25) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 25) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 26) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 25)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.009020954098778622, 'rotation_range': 12, 'optimizer': 'RMSProp', 'width_shift_range': 0.23800772836013298, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.036708247344704424, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:41:28.752967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.2130 - acc: 0.0883 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 25), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 25) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 25) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 25) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 25)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.23800772836013298, 'base_model': 'MobileNet', 'zoom_range': 0.009020954098778622, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 12, 'height_shift_range': 0.036708247344704424, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 13.357191324234009, 'histories': {'val_acc': [0.0917431196078248], 'loss': [12.961925114670844], 'acc': [0.0958904109589041], 'val_loss': [14.639370655794757]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 25)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 26)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 26) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 27) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 26)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1736972161831841, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.15721740660049613, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1079514475176631, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:41:42.249401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 14.0070 - acc: 0.0567 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 26), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 26) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 26)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.15721740660049613, 'base_model': 'MobileNet', 'zoom_range': 0.1736972161831841, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.1079514475176631, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339442705889, 'info': {'runtime': 13.711554050445557, 'histories': {'val_acc': [0.11926605572941107], 'loss': [13.824595568931265], 'acc': [0.06164383561643835], 'val_loss': [14.195753561247379]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 26)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 27)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 27) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 28) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 27) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 27) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 27)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.16331064083923394, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.2472384430591542, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2580719526544959, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:41:55.899496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 8.8871 - acc: 0.1217 - val_loss: 2.3489 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 27), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 27) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 27) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 27) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 27)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2472384430591542, 'base_model': 'MobileNet', 'zoom_range': 0.16331064083923394, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.2580719526544959, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853197338385, 'info': {'runtime': 13.082578659057617, 'histories': {'val_acc': [0.13761468026616158], 'loss': [8.958635356328259], 'acc': [0.08904109589041095], 'val_loss': [2.3488909848239445]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 27)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 28)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 28) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 29) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 28) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 28) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 28)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1322686349549106, 'rotation_range': 30, 'optimizer': 'RMSProp', 'width_shift_range': 0.23420636925437918, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20267574783239153, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:42:09.036183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 11.9772 - acc: 0.0946 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 28), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 28) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 28) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 28) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 28)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.23420636925437918, 'base_model': 'MobileNet', 'zoom_range': 0.1322686349549106, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 30, 'height_shift_range': 0.20267574783239153, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853191870068, 'info': {'runtime': 13.13967514038086, 'histories': {'val_acc': [0.1376146808129932], 'loss': [11.61937857327396], 'acc': [0.10273972602739725], 'val_loss': [13.900008857797046]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 28)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 29)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 29) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 29) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 30) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 29) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 29)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.22462839720660702, 'rotation_range': 8, 'optimizer': 'RMSProp', 'width_shift_range': 0.1749181371556131, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.10507662054717247, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:42:22.223339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.6098 - acc: 0.1280 - val_loss: 14.9351 - val_acc: 0.0734
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 29), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 29) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 29) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 29) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 29)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1749181371556131, 'base_model': 'MobileNet', 'zoom_range': 0.22462839720660702, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 8, 'height_shift_range': 0.10507662054717247, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.926605504587156, 'info': {'runtime': 12.589514970779419, 'histories': {'val_acc': [0.07339449541284404], 'loss': [13.003114334524494], 'acc': [0.0958904109589041], 'val_loss': [14.935115639222872]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 29)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 30)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 30) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 30) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 31) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 30) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 30)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2670786079914451, 'rotation_range': 18, 'optimizer': 'RMSProp', 'width_shift_range': 0.0500254284180322, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1784146464345955, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:42:34.834763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 8.4988 - acc: 0.1187 - val_loss: 2.2743 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 30), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 30) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 30) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 30) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 30)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0500254284180322, 'base_model': 'MobileNet', 'zoom_range': 0.2670786079914451, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 18, 'height_shift_range': 0.1784146464345955, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853211009174, 'info': {'runtime': 13.893618822097778, 'histories': {'val_acc': [0.13761467889908258], 'loss': [8.49877438545227], 'acc': [0.11875], 'val_loss': [2.274275132275503]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 30)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 31)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 31) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 31) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 32) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 31) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 31)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.17952951849073365, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.17450111906738017, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20821749562304545, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:42:48.775251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 9s - loss: 12.5776 - acc: 0.1028 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 31), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 31) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 31) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 31) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 31)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.17450111906738017, 'base_model': 'MobileNet', 'zoom_range': 0.17952951849073365, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.20821749562304545, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082565389642, 'info': {'runtime': 13.802720308303833, 'histories': {'val_acc': [0.11009174346103581], 'loss': [12.968113050068894], 'acc': [0.0684931506849315], 'val_loss': [14.343626039837478]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 31)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 32)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 32) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 32) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 33) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 32) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 32)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.18694642490483945, 'rotation_range': 18, 'optimizer': 'RMSProp', 'width_shift_range': 0.12072766851550865, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11833614046626591, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:43:02.628262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.0395 - acc: 0.0820 - val_loss: 13.7521 - val_acc: 0.1468
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 32), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 32) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 32) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 32) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 32)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.12072766851550865, 'base_model': 'MobileNet', 'zoom_range': 0.18694642490483945, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 18, 'height_shift_range': 0.11833614046626591, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8532110084907725, 'info': {'runtime': 13.4247567653656, 'histories': {'val_acc': [0.14678899150922758], 'loss': [12.773472302580533], 'acc': [0.08904109589041095], 'val_loss': [13.75213621297014]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 32)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 33)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 33) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 33) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 34) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 33) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 33)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.011501011606773148, 'rotation_range': 2, 'optimizer': 'RMSProp', 'width_shift_range': 0.10676263674807718, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.16118366521362237, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:43:16.073069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 8.9078 - acc: 0.0883 - val_loss: 2.2479 - val_acc: 0.3945
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 33), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 33) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 33) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 33) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 33)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10676263674807718, 'base_model': 'MobileNet', 'zoom_range': 0.011501011606773148, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 2, 'height_shift_range': 0.16118366521362237, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.6055045827813105, 'info': {'runtime': 13.325216293334961, 'histories': {'val_acc': [0.3944954172186895], 'loss': [8.28470870240094], 'acc': [0.0958904109589041], 'val_loss': [2.2478712786228283]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 33)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 34)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 34) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 35) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 34) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 34) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 34)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.15225241804498887, 'rotation_range': 27, 'optimizer': 'RMSProp', 'width_shift_range': 0.12662375986373725, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20080875990019992, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:43:29.454165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.1291 - acc: 0.1072 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 34), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 34) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 34) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 34) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 34)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.12662375986373725, 'base_model': 'MobileNet', 'zoom_range': 0.15225241804498887, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 27, 'height_shift_range': 0.20080875990019992, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853207591476, 'info': {'runtime': 12.918012142181396, 'histories': {'val_acc': [0.13761467924085233], 'loss': [14.053825750742874], 'acc': [0.11643835616438356], 'val_loss': [13.900008805301212]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 34)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 35)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 35) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 35) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 36) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 35) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 35)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.16794523818112486, 'rotation_range': 2, 'optimizer': 'RMSProp', 'width_shift_range': 0.14803812647293313, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1294651864738166, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:43:42.395611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 9s - loss: 13.2811 - acc: 0.1062 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 35), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 35) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 35) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 35) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 35)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.14803812647293313, 'base_model': 'MobileNet', 'zoom_range': 0.16794523818112486, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 2, 'height_shift_range': 0.1294651864738166, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 13.718176364898682, 'histories': {'val_acc': [0.0917431196078248], 'loss': [13.281133079528809], 'acc': [0.10625], 'val_loss': [14.639371329491292]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 35)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 36)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 36) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 37) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 36) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 36) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 36)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.10605690054362028, 'rotation_range': 29, 'optimizer': 'RMSProp', 'width_shift_range': 0.2418100107675313, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.052404174425762784, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:43:56.163476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.9506 - acc: 0.1261 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 36), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 36) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 36) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 36) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 36)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2418100107675313, 'base_model': 'MobileNet', 'zoom_range': 0.10605690054362028, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 29, 'height_shift_range': 0.052404174425762784, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339430402178, 'info': {'runtime': 13.341820001602173, 'histories': {'val_acc': [0.11926605695978217], 'loss': [12.676917402711632], 'acc': [0.136986301369863], 'val_loss': [14.195753587495297]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 36)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 37)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 37) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 38) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 37) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 37) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 37)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.11664742297932779, 'rotation_range': 2, 'optimizer': 'RMSProp', 'width_shift_range': 0.05102765528366125, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1350063486803364, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:44:09.543913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.4560 - acc: 0.0757 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 37), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 37) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 37) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 37) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 37)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.05102765528366125, 'base_model': 'MobileNet', 'zoom_range': 0.11664742297932779, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 2, 'height_shift_range': 0.1350063486803364, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9174311923187807, 'info': {'runtime': 12.731588125228882, 'histories': {'val_acc': [0.0825688076812193], 'loss': [14.411332842421858], 'acc': [0.0821917808219178], 'val_loss': [14.787243554351527]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 37)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 38)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 38) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 39) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 38) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 38) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 38)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.27018782562527527, 'rotation_range': 21, 'optimizer': 'RMSProp', 'width_shift_range': 0.18029874995660997, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.17337040776375992, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:44:22.314438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.4055 - acc: 0.0504 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 38), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 38) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 38) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 38) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 38)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.18029874995660997, 'base_model': 'MobileNet', 'zoom_range': 0.27018782562527527, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 21, 'height_shift_range': 0.17337040776375992, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339442705889, 'info': {'runtime': 12.84596300125122, 'histories': {'val_acc': [0.11926605572941107], 'loss': [13.171046217826948], 'acc': [0.0547945205479452], 'val_loss': [14.195753727484187]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 38)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 39)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 39) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 40) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 39) on hpbandster.run_0.worker.tfpool20.19325140106390476544
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 39)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06671035764987453, 'rotation_range': 29, 'optimizer': 'RMSProp', 'width_shift_range': 0.10424498149525974, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.13628009945988093, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
2018-02-07 18:44:35.208664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.5895 - acc: 0.1343 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 39), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 39) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 39)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10424498149525974, 'base_model': 'MobileNet', 'zoom_range': 0.06671035764987453, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 29, 'height_shift_range': 0.13628009945988093, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339446123587, 'info': {'runtime': 14.591755628585815, 'histories': {'val_acc': [0.11926605538764132], 'loss': [12.98105104002234], 'acc': [0.10273972602739725], 'val_loss': [14.19575342125849]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 39)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 40)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 40) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 41) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 40) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 40) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 40)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1462127156317999, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.22431353736636975, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21861940757471376, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:44:49.832769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.0950 - acc: 0.1072 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 40), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 40) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 40) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 40) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 40)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.22431353736636975, 'base_model': 'MobileNet', 'zoom_range': 0.1462127156317999, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.21861940757471376, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853167262646, 'info': {'runtime': 13.072734832763672, 'histories': {'val_acc': [0.13761468327373538], 'loss': [12.833786820712154], 'acc': [0.11643835616438356], 'val_loss': [13.90000846407829]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 40)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 41)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 41) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 41) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 42) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 41) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 41)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.20803214509893758, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.15964293793521547, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.05084793945539209, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:45:02.762599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 11.7871 - acc: 0.1000 - val_loss: 2.2868 - val_acc: 0.1651
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 41), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 41) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 41) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 41) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 41)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.15964293793521547, 'base_model': 'MobileNet', 'zoom_range': 0.20803214509893758, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.05084793945539209, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8348623834071903, 'info': {'runtime': 12.636024475097656, 'histories': {'val_acc': [0.1651376165928097], 'loss': [11.787081003189087], 'acc': [0.1], 'val_loss': [2.2867689613902242]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 41)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 42)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 42) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 42) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 43) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 42)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.04541364089078729, 'rotation_range': 17, 'optimizer': 'RMSProp', 'width_shift_range': 0.14607169417938207, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1434785068301523, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:45:15.629051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 6.4318 - acc: 0.0820 - val_loss: 2.2965 - val_acc: 0.1927
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 42), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 42) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 42)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.14607169417938207, 'base_model': 'MobileNet', 'zoom_range': 0.04541364089078729, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 17, 'height_shift_range': 0.1434785068301523, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8073394457134632, 'info': {'runtime': 12.936971187591553, 'histories': {'val_acc': [0.19266055428653683], 'loss': [6.795276935786417], 'acc': [0.08904109589041095], 'val_loss': [2.296511077005929]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 42)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 43)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 43) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 43) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 44) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 43)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1349044831819766, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.2774973257972868, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.03934840609731639, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
DEBUG:hpbandster:DISPATCHER: job (0, 0, 43) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
2018-02-07 18:45:28.596413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.2192 - acc: 0.1469 - val_loss: 14.0479 - val_acc: 0.1284
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 43), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 43) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 43) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 43) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 43)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2774973257972868, 'base_model': 'MobileNet', 'zoom_range': 0.1349044831819766, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.03934840609731639, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8715596326857532, 'info': {'runtime': 13.063047885894775, 'histories': {'val_acc': [0.12844036731424682], 'loss': [12.578681370983386], 'acc': [0.11643835616438356], 'val_loss': [14.047881196398254]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 43)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 44)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 44) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 44) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 45) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 44) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 44)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.01942704018474427, 'rotation_range': 0, 'optimizer': 'RMSProp', 'width_shift_range': 0.020295389480898762, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.19109542669243468, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:45:41.710264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 9s - loss: 13.7433 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 44), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 44) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 44) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 44) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 44)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.020295389480898762, 'base_model': 'MobileNet', 'zoom_range': 0.01942704018474427, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 0, 'height_shift_range': 0.19109542669243468, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825688073394, 'info': {'runtime': 13.597164392471313, 'histories': {'val_acc': [0.10091743119266056], 'loss': [13.538022080512896], 'acc': [0.0958904109589041], 'val_loss': [14.491498124708823]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 44)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 45)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 45) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 45) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 46) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 45) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 45)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.19242211474111973, 'rotation_range': 21, 'optimizer': 'RMSProp', 'width_shift_range': 0.009502224088888777, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.16325138786117618, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:45:55.345800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.7115 - acc: 0.0883 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 45), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 45) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 45) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 45) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 45)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.009502224088888777, 'base_model': 'MobileNet', 'zoom_range': 0.19242211474111973, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 21, 'height_shift_range': 0.16325138786117618, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568788200344, 'info': {'runtime': 12.957046270370483, 'histories': {'val_acc': [0.09174312117996566], 'loss': [13.503489977692904], 'acc': [0.0958904109589041], 'val_loss': [14.639370542053783]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 45)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 46)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 46) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 47) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 46) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 46) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 46)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1516452182471034, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.21870566926729457, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08312298434245204, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:46:08.348713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.9241 - acc: 0.0315 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 46), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 46) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 46) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 46) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 46)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21870566926729457, 'base_model': 'MobileNet', 'zoom_range': 0.1516452182471034, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.08312298434245204, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825684655697, 'info': {'runtime': 13.18686294555664, 'histories': {'val_acc': [0.10091743153443031], 'loss': [13.734526856304848], 'acc': [0.03424657534246575], 'val_loss': [14.491498430934522]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 46)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 47)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 47) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 47) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 48) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 47) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 47)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0034596733664872814, 'rotation_range': 30, 'optimizer': 'RMSProp', 'width_shift_range': 0.24925130004164747, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08734735554984838, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:46:21.566463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.6602 - acc: 0.1343 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 47), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 47) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 47) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 47) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 47)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.24925130004164747, 'base_model': 'MobileNet', 'zoom_range': 0.0034596733664872814, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 30, 'height_shift_range': 0.08734735554984838, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082549668234, 'info': {'runtime': 13.427921295166016, 'histories': {'val_acc': [0.11009174503317666], 'loss': [13.057861955198524], 'acc': [0.10273972602739725], 'val_loss': [14.343625812355532]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 47)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 48)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 48) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 48) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 49) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 48) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 48)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0688502377839523, 'rotation_range': 25, 'optimizer': 'RMSProp', 'width_shift_range': 0.009599239230055966, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.007792065057449049, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:46:35.031639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 10s - loss: 12.7520 - acc: 0.0883 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 48), trying to register it.
DEBUG:hpbandster:DISPATCHER: job (0, 0, 48) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 48) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 48)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.009599239230055966, 'base_model': 'MobileNet', 'zoom_range': 0.0688502377839523, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 25, 'height_shift_range': 0.007792065057449049, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9174311923187807, 'info': {'runtime': 15.775935411453247, 'histories': {'val_acc': [0.0825688076812193], 'loss': [12.46106432562005], 'acc': [0.0958904109589041], 'val_loss': [14.787243274373745]}}}
exception: None

INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 48) with dispatcher
DEBUG:hpbandster:job_callback for (0, 0, 48)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 49)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 49) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 49) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 50) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 49)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.011777038546923035, 'rotation_range': 16, 'optimizer': 'RMSProp', 'width_shift_range': 0.11205385960091242, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.25550630720707174, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:46:50.860429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.7678 - acc: 0.1343 - val_loss: 14.0479 - val_acc: 0.1284
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 49), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 49) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 49)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11205385960091242, 'base_model': 'MobileNet', 'zoom_range': 0.011777038546923035, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 16, 'height_shift_range': 0.25550630720707174, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8715596330275229, 'info': {'runtime': 12.839462280273438, 'histories': {'val_acc': [0.12844036697247707], 'loss': [13.174678959258616], 'acc': [0.10273972602739725], 'val_loss': [14.047881450128118]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 49)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 50)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 50) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 50) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 51) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 50) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 50)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.27107368851502095, 'rotation_range': 15, 'optimizer': 'RMSProp', 'width_shift_range': 0.06324833172328818, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.18223744860128344, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:47:03.739403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.9065 - acc: 0.0820 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 50), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 50) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 50) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 50) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 50)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.06324833172328818, 'base_model': 'MobileNet', 'zoom_range': 0.27107368851502095, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 15, 'height_shift_range': 0.18223744860128344, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853204173779, 'info': {'runtime': 13.40213418006897, 'histories': {'val_acc': [0.13761467958262208], 'loss': [12.628994876391268], 'acc': [0.08904109589041095], 'val_loss': [13.900008831549128]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 50)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 51)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 51) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 52) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 51) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 51) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 51)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.08049394612852068, 'rotation_range': 3, 'optimizer': 'RMSProp', 'width_shift_range': 0.009350487374865102, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2302834993331358, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:47:16.971344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.0267 - acc: 0.1313 - val_loss: 13.4564 - val_acc: 0.1651
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 51), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 51) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 51) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 51) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 51)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.009350487374865102, 'base_model': 'MobileNet', 'zoom_range': 0.08049394612852068, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 3, 'height_shift_range': 0.2302834993331358, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8348623809464482, 'info': {'runtime': 12.655544757843018, 'histories': {'val_acc': [0.1651376190535519], 'loss': [13.026668667793274], 'acc': [0.13125], 'val_loss': [13.456391509519804]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 51)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 52)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 52) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 52) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 53) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 52) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 52)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.13807723297533528, 'rotation_range': 15, 'optimizer': 'RMSProp', 'width_shift_range': 0.1813783403886645, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.14056822500607694, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:47:29.888014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.0097 - acc: 0.1785 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 52), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 52) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 52) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 52) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 52)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1813783403886645, 'base_model': 'MobileNet', 'zoom_range': 0.13807723297533528, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 15, 'height_shift_range': 0.14056822500607694, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082549668234, 'info': {'runtime': 13.501183271408081, 'histories': {'val_acc': [0.11009174503317666], 'loss': [12.351098308824513], 'acc': [0.1506849315068493], 'val_loss': [14.343625812355532]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 52)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 53)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 53) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 54) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 53) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 53) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 53)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.22396750754202002, 'rotation_range': 8, 'optimizer': 'RMSProp', 'width_shift_range': 0.24956424966492688, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.16811238061695136, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:47:43.420415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.7368 - acc: 0.0567 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 53), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 53) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 53) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 53) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 53)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.24956424966492688, 'base_model': 'MobileNet', 'zoom_range': 0.22396750754202002, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 8, 'height_shift_range': 0.16811238061695136, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9174311926605505, 'info': {'runtime': 12.724704265594482, 'histories': {'val_acc': [0.08256880733944955], 'loss': [14.680772415579181], 'acc': [0.06164383561643835], 'val_loss': [14.787243134384855]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 53)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 54)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 54) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 54) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 55) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 54) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 54)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.29834588384162414, 'rotation_range': 2, 'optimizer': 'RMSProp', 'width_shift_range': 0.039904902531420094, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.034857645300040936, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:47:55.979914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.3778 - acc: 0.1072 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 54), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 54) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 54) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 54) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 54)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.039904902531420094, 'base_model': 'MobileNet', 'zoom_range': 0.29834588384162414, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 2, 'height_shift_range': 0.034857645300040936, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339430402178, 'info': {'runtime': 13.179084062576294, 'histories': {'val_acc': [0.11926605695978217], 'loss': [12.054552809832847], 'acc': [0.11643835616438356], 'val_loss': [14.195753587495297]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 54)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 55)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 55) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 56) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 55) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 55) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 55)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.17075940278883792, 'rotation_range': 22, 'optimizer': 'RMSProp', 'width_shift_range': 0.20751787121134033, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.22070196769552575, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:48:09.195865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 12.7681 - acc: 0.1324 - val_loss: 13.7521 - val_acc: 0.1468
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 55), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 55) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 55) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 55) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 55)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.20751787121134033, 'base_model': 'MobileNet', 'zoom_range': 0.17075940278883792, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 22, 'height_shift_range': 0.22070196769552575, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8532110084907725, 'info': {'runtime': 12.727457761764526, 'histories': {'val_acc': [0.14678899150922758], 'loss': [12.478573158995745], 'acc': [0.14383561643835616], 'val_loss': [13.752136606688893]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 55)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 56)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 56) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 56) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 57) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 56) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 56)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.26594751726082533, 'rotation_range': 18, 'optimizer': 'RMSProp', 'width_shift_range': 0.009800521005655672, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.002696358741526661, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:48:22.181085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.4317 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 56), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 56) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 56) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 56) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 56)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.009800521005655672, 'base_model': 'MobileNet', 'zoom_range': 0.26594751726082533, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 18, 'height_shift_range': 0.002696358741526661, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825688073394, 'info': {'runtime': 13.122032165527344, 'histories': {'val_acc': [0.10091743119266056], 'loss': [14.384673157783403], 'acc': [0.0958904109589041], 'val_loss': [14.491498684664386]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 56)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 57)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 57) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 57) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 58) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 57) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 57)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2750238241053945, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.09554569885887464, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.17083443172772642, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:48:35.338683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.2150 - acc: 0.0757 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 57), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 57) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 57) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 57) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 57)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.09554569885887464, 'base_model': 'MobileNet', 'zoom_range': 0.2750238241053945, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.17083443172772642, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853211009174, 'info': {'runtime': 13.140492916107178, 'histories': {'val_acc': [0.13761467889908258], 'loss': [12.964087447074995], 'acc': [0.0821917808219178], 'val_loss': [13.90000866531232]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 57)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 58)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 58) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 59) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 58) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 58) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 58)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2655753280543303, 'rotation_range': 8, 'optimizer': 'RMSProp', 'width_shift_range': 0.18675424278803238, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.09173852850019378, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:48:48.514517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.2905 - acc: 0.1028 - val_loss: 14.9273 - val_acc: 0.0734
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 58), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 58) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 58) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 58) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 58)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.18675424278803238, 'base_model': 'MobileNet', 'zoom_range': 0.2655753280543303, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 8, 'height_shift_range': 0.09173852850019378, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.926605504587156, 'info': {'runtime': 13.430115222930908, 'histories': {'val_acc': [0.07339449541284404], 'loss': [13.742630788724716], 'acc': [0.0684931506849315], 'val_loss': [14.927274021533652]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 58)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 59)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 59) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 59) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 60) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 59) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 59)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.03418526232801191, 'rotation_range': 14, 'optimizer': 'RMSProp', 'width_shift_range': 0.1286270560298707, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.004390430698869485, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:49:01.773393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.4558 - acc: 0.0757 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 59), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 59) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 59) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 59) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 59)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1286270560298707, 'base_model': 'MobileNet', 'zoom_range': 0.03418526232801191, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 14, 'height_shift_range': 0.004390430698869485, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082561971945, 'info': {'runtime': 12.933818578720093, 'histories': {'val_acc': [0.11009174380280556], 'loss': [13.225762563209011], 'acc': [0.0821917808219178], 'val_loss': [14.343626066085395]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 59)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 60)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 60) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 61) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 60) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 60) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 60)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.22037940129546013, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.06496439802893961, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.035719877813451414, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:49:14.749948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.7002 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 60), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 60) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 60) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 60) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 60)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.06496439802893961, 'base_model': 'MobileNet', 'zoom_range': 0.22037940129546013, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.035719877813451414, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825684655697, 'info': {'runtime': 12.831796169281006, 'histories': {'val_acc': [0.10091743153443031], 'loss': [13.491219246224182], 'acc': [0.08904109589041095], 'val_loss': [14.491498430934522]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 60)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 61)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 61) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 62) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 61) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 61) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 61)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.12486654860146486, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.2226453965105465, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1420243599771951, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:49:27.617873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 8.0018 - acc: 0.0883 - val_loss: 2.2428 - val_acc: 0.1284
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 61), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 61) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 61) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 61) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 61)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2226453965105465, 'base_model': 'MobileNet', 'zoom_range': 0.12486654860146486, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.1420243599771951, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8715596330275229, 'info': {'runtime': 12.654239416122437, 'histories': {'val_acc': [0.12844036697247707], 'loss': [8.407080166960416], 'acc': [0.0958904109589041], 'val_loss': [2.2428284150744795]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 61)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 62)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 62) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 63) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 62) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 62) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 62)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.27050372773315295, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.08795432729739967, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.23350410037833833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:49:40.544260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.2000 - acc: 0.0883 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 62), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 62) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 62) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 62) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 62)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08795432729739967, 'base_model': 'MobileNet', 'zoom_range': 0.27050372773315295, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.23350410037833833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.908256880733945, 'info': {'runtime': 13.562886238098145, 'histories': {'val_acc': [0.09174311926605505], 'loss': [12.947767100922048], 'acc': [0.0958904109589041], 'val_loss': [14.63937090952462]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 62)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 63)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 63) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 63) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 63)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0950242529129579, 'rotation_range': 22, 'optimizer': 'RMSProp', 'width_shift_range': 0.002023560492388432, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.0790602594222798, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:49:54.150549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/1
 - 8s - loss: 13.2383 - acc: 0.0883 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 63), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 63) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 63)
args: ()
kwargs: {'budget': 1.0, 'working_directory': '.', 'config': {'width_shift_range': 0.002023560492388432, 'base_model': 'MobileNet', 'zoom_range': 0.0950242529129579, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 22, 'height_shift_range': 0.0790602594222798, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853207591476, 'info': {'runtime': 13.244168043136597, 'histories': {'val_acc': [0.13761467924085233], 'loss': [12.989414789905286], 'acc': [0.0958904109589041], 'val_loss': [13.9000092515158]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 63)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 0) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.14301167412200663, 'rotation_range': 26, 'optimizer': 'RMSProp', 'width_shift_range': 0.2404575165575404, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20932192731203267, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:50:07.431800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 6.9801 - acc: 0.1198 - val_loss: 2.1964 - val_acc: 0.2294
Epoch 2/2
 - 4s - loss: 2.4478 - acc: 0.1891 - val_loss: 2.7746 - val_acc: 0.1468
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 0)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2404575165575404, 'base_model': 'MobileNet', 'zoom_range': 0.14301167412200663, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 26, 'height_shift_range': 0.20932192731203267, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8532110088325422, 'info': {'runtime': 16.853378534317017, 'histories': {'val_acc': [0.2293578000790482, 0.14678899116745783], 'loss': [7.3837492302672505, 2.3237822153796888], 'acc': [0.13013698630136986, 0.2054794520547945], 'val_loss': [2.196394854729329, 2.7746075752678268]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 8) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.0016573244368102479, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:50:24.328369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 5.6915 - acc: 0.1324 - val_loss: 2.2935 - val_acc: 0.1101
Epoch 2/2
 - 4s - loss: 2.0828 - acc: 0.3569 - val_loss: 2.1137 - val_acc: 0.2752
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 9)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0016573244368102479, 'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.7247706402879243, 'info': {'runtime': 18.3598051071167, 'histories': {'val_acc': [0.11009174311926606, 0.27522935971207574], 'loss': [5.972925179625211, 2.0949635260725676], 'acc': [0.14383561643835616, 0.3013698630136986], 'val_loss': [2.2934566900270794, 2.113698906854752]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 8)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 8) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 57) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 8)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2831500712306704, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.11553792182868505, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.10673317706594039, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:50:42.488814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 7.7979 - acc: 0.1198 - val_loss: 2.3630 - val_acc: 0.1284
Epoch 2/2
 - 4s - loss: 1.9955 - acc: 0.3000 - val_loss: 2.4145 - val_acc: 0.2477
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 8), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 8) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 8)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11553792182868505, 'base_model': 'MobileNet', 'zoom_range': 0.2831500712306704, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.10673317706594039, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.7522935776398816, 'info': {'runtime': 17.39808940887451, 'histories': {'val_acc': [0.12844036765601657, 0.2477064223601184], 'loss': [7.07887824594158, 1.9954585552215576], 'acc': [0.13013698630136986, 0.3], 'val_loss': [2.3630204506970327, 2.4144778492253853]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 8)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 57)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 57) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 43) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 57) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 57) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 57)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2750238241053945, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.09554569885887464, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.17083443172772642, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:50:59.931881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 12.5557 - acc: 0.1009 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 2/2
 - 5s - loss: 14.1033 - acc: 0.1250 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 57), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 57) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 57) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 57) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 57)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.09554569885887464, 'base_model': 'MobileNet', 'zoom_range': 0.2750238241053945, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.17083443172772642, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.908256880733945, 'info': {'runtime': 17.459232568740845, 'histories': {'val_acc': [0.09174311926605505, 0.09174311926605505], 'loss': [12.247796202359135, 14.103333568572998], 'acc': [0.1095890410958904, 0.125], 'val_loss': [14.63937090952462, 14.63937090952462]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 57)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 43)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 43) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 42) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 43) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 43) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 43)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1349044831819766, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.2774973257972868, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.03934840609731639, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:51:17.429635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.4759 - acc: 0.0875 - val_loss: 14.7776 - val_acc: 0.0826
Epoch 2/2
 - 4s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 43), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 43) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 43) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 43) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 43)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2774973257972868, 'base_model': 'MobileNet', 'zoom_range': 0.1349044831819766, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.03934840609731639, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825681237999, 'info': {'runtime': 17.600223541259766, 'histories': {'val_acc': [0.08256880802298905, 0.10091743187620006], 'loss': [13.47585654258728, 14.572524501852794], 'acc': [0.0875, 0.0958904109589041], 'val_loss': [14.777577067733905, 14.49149829094563]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 43)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 42)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 42) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 42) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 42)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.04541364089078729, 'rotation_range': 17, 'optimizer': 'RMSProp', 'width_shift_range': 0.14607169417938207, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1434785068301523, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:51:35.062755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 11.4230 - acc: 0.2119 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 2/2
 - 4s - loss: 12.9053 - acc: 0.1993 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 42), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 42) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 42)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.14607169417938207, 'base_model': 'MobileNet', 'zoom_range': 0.04541364089078729, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 17, 'height_shift_range': 0.1434785068301523, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853211009174, 'info': {'runtime': 17.48462176322937, 'histories': {'val_acc': [0.14678899116745783, 0.13761467889908258], 'loss': [12.410171562678194, 14.020534987319005], 'acc': [0.14383561643835616, 0.13013698630136986], 'val_loss': [13.752136860418757, 13.900008945290102]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 42)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 7)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 41) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 7)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2892001144443167, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.2870985207906671, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.25925836847713396, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
2018-02-07 18:51:52.597473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 12.3694 - acc: 0.1261 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 2/2
 - 4s - loss: 14.1874 - acc: 0.1198 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 7), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 7)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2870985207906671, 'base_model': 'MobileNet', 'zoom_range': 0.2892001144443167, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.25925836847713396, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853207591476, 'info': {'runtime': 16.40006995201111, 'histories': {'val_acc': [0.14678899150922758, 0.13761467924085233], 'loss': [12.045466409970636, 14.020534985686002], 'acc': [0.136986301369863, 0.13013698630136986], 'val_loss': [13.75213621297014, 13.900009085278992]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 7)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 41)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 41) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 20) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 41) on hpbandster.run_0.worker.tfpool20.19325140106390476544
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 41)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.20803214509893758, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.15964293793521547, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.05084793945539209, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
DEBUG:hpbandster:DISPATCHER: job (0, 0, 41) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
2018-02-07 18:52:09.039410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 9s - loss: 13.3506 - acc: 0.0630 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 2/2
 - 4s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 41), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 41) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 41) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 41) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 41)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.15964293793521547, 'base_model': 'MobileNet', 'zoom_range': 0.20803214509893758, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.05084793945539209, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825681237999, 'info': {'runtime': 18.12506103515625, 'histories': {'val_acc': [0.07339449575461379, 0.10091743187620006], 'loss': [13.11147509535698, 14.793320433734214], 'acc': [0.0684931506849315, 0.0821917808219178], 'val_loss': [14.935116059189543, 14.491498570923412]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 41)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 20)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 20) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 40) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 20)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.08997505136600327, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
2018-02-07 18:52:27.197791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.1012 - acc: 0.1198 - val_loss: 13.3085 - val_acc: 0.1743
Epoch 2/2
 - 5s - loss: 14.0026 - acc: 0.1313 - val_loss: 13.4564 - val_acc: 0.1651
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 20), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 20) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 20)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08997505136600327, 'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8348623849793312, 'info': {'runtime': 17.613902807235718, 'histories': {'val_acc': [0.1743119279725836, 0.16513761502066884], 'loss': [12.840458125284274, 14.002595329284668], 'acc': [0.13013698630136986, 0.13125], 'val_loss': [13.308519258411652, 13.456391737001752]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 20)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 40)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 40) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 19) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 40) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 40) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 40)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1462127156317999, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.22431353736636975, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21861940757471376, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:52:44.849999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.0313 - acc: 0.1261 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/2
 - 4s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.0479 - val_acc: 0.1284
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 40), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 40) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 40) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 40) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 40)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.22431353736636975, 'base_model': 'MobileNet', 'zoom_range': 0.1462127156317999, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.21861940757471376, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8715596316604439, 'info': {'runtime': 18.882084369659424, 'histories': {'val_acc': [0.0825688076812193, 0.12844036833955608], 'loss': [12.764569792028976, 14.462126640424337], 'acc': [0.136986301369863, 0.10273972602739725], 'val_loss': [14.787243274373745, 14.04788094266839]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 40)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 19)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 19) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 55) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 19)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.19956006504962495, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.18472340643110186, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08962149295842833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:53:03.779629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 6.9208 - acc: 0.0693 - val_loss: 2.2051 - val_acc: 0.2202
Epoch 2/2
 - 5s - loss: 2.0041 - acc: 0.3125 - val_loss: 2.1349 - val_acc: 0.3028
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 19), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 19) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 19)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.18472340643110186, 'base_model': 'MobileNet', 'zoom_range': 0.19956006504962495, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.08962149295842833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.6972477025941971, 'info': {'runtime': 17.790093421936035, 'histories': {'val_acc': [0.22018348692207163, 0.3027522974058029], 'loss': [7.300811284208951, 2.004052698612213], 'acc': [0.07534246575342465, 0.3125], 'val_loss': [2.2051034542398713, 2.1349362145870106]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 19)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 55)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 55) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 54) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 55) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 55) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 55)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.17075940278883792, 'rotation_range': 22, 'optimizer': 'RMSProp', 'width_shift_range': 0.20751787121134033, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.22070196769552575, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:53:21.611582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.7020 - acc: 0.0757 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 2/2
 - 4s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 55), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 55) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 55) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 55) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 55)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.20751787121134033, 'base_model': 'MobileNet', 'zoom_range': 0.17075940278883792, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 22, 'height_shift_range': 0.22070196769552575, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568800504054, 'info': {'runtime': 16.70815420150757, 'histories': {'val_acc': [0.06422018382800829, 0.09174311994959455], 'loss': [13.493241297055597, 14.462126535912082], 'acc': [0.0821917808219178, 0.10273972602739725], 'val_loss': [15.082988284049778, 14.639370515805865]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 55)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 54)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 54) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 39) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 54) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 54) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 54)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.29834588384162414, 'rotation_range': 2, 'optimizer': 'RMSProp', 'width_shift_range': 0.039904902531420094, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.034857645300040936, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:53:38.361514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 8.6291 - acc: 0.1513 - val_loss: 2.2229 - val_acc: 0.1835
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 2/2
 - 4s - loss: 2.2257 - acc: 0.1891 - val_loss: 2.2892 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 54), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 54) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 54) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 54) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 54)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.039904902531420094, 'base_model': 'MobileNet', 'zoom_range': 0.29834588384162414, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 2, 'height_shift_range': 0.034857645300040936, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853207591476, 'info': {'runtime': 16.570873975753784, 'histories': {'val_acc': [0.18348624044602072, 0.13761467924085233], 'loss': [9.032243473889077, 2.2103003541084183], 'acc': [0.1643835616438356, 0.2054794520547945], 'val_loss': [2.222852735344423, 2.28915525138925]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 54)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 39)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 39) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 52) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 39) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 39)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06671035764987453, 'rotation_range': 29, 'optimizer': 'RMSProp', 'width_shift_range': 0.10424498149525974, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.13628009945988093, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:53:54.979913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 9s - loss: 13.6029 - acc: 0.0750 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/2
 - 4s - loss: 13.7065 - acc: 0.1496 - val_loss: 14.0479 - val_acc: 0.1284
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 39), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 39) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 39)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10424498149525974, 'base_model': 'MobileNet', 'zoom_range': 0.06671035764987453, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 29, 'height_shift_range': 0.13628009945988093, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8715596323439834, 'info': {'runtime': 17.72641658782959, 'histories': {'val_acc': [0.11009174346103581, 0.12844036765601657], 'loss': [13.60289912223816, 14.774920492461234], 'acc': [0.075, 0.08333333333333333], 'val_loss': [14.343626206074285, 14.047881616364926]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 39)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 52)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 52) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 38) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 52) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 52) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 52)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.13807723297533528, 'rotation_range': 15, 'optimizer': 'RMSProp', 'width_shift_range': 0.1813783403886645, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.14056822500607694, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:54:12.736667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.7027 - acc: 0.0757 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/2
 - 4s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 52), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 52) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 52) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 52) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 52)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1813783403886645, 'base_model': 'MobileNet', 'zoom_range': 0.13807723297533528, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 15, 'height_shift_range': 0.14056822500607694, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.908256880733945, 'info': {'runtime': 16.617250204086304, 'histories': {'val_acc': [0.08256880802298905, 0.09174311926605505], 'loss': [13.49394129400384, 14.903718190650418], 'acc': [0.0821917808219178, 0.07534246575342465], 'val_loss': [14.787243186880689, 14.639370629546839]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 52)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 38)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 38) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 51) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 38) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 38) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 38)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.27018782562527527, 'rotation_range': 21, 'optimizer': 'RMSProp', 'width_shift_range': 0.18029874995660997, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.17337040776375992, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:54:29.717757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.5337 - acc: 0.0693 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 2/2
 - 4s - loss: 14.3906 - acc: 0.1072 - val_loss: 15.0830 - val_acc: 0.0642
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 38), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 38) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 38) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 38) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 38)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.18029874995660997, 'base_model': 'MobileNet', 'zoom_range': 0.27018782562527527, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 21, 'height_shift_range': 0.17337040776375992, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9357798165137614, 'info': {'runtime': 17.559794425964355, 'histories': {'val_acc': [0.07339449541284404, 0.06422018348623854], 'loss': [13.310385560336178, 14.24133081305517], 'acc': [0.07534246575342465, 0.11643835616438356], 'val_loss': [14.935115919200653, 15.082988144060888]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 38)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 51)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 51) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 30) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 51) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 51) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 51)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.08049394612852068, 'rotation_range': 3, 'optimizer': 'RMSProp', 'width_shift_range': 0.009350487374865102, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2302834993331358, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:54:47.000242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 12.4621 - acc: 0.1450 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 2/2
 - 5s - loss: 13.5777 - acc: 0.1576 - val_loss: 13.6043 - val_acc: 0.1560
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 51), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 51) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 51) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 51) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 51)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.009350487374865102, 'base_model': 'MobileNet', 'zoom_range': 0.08049394612852068, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 3, 'height_shift_range': 0.2302834993331358, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8440366965641669, 'info': {'runtime': 17.264753580093384, 'histories': {'val_acc': [0.1559633034358331, 0.1559633034358331], 'loss': [12.146198194320888, 13.358147399066246], 'acc': [0.15753424657534246, 0.17123287671232876], 'val_loss': [13.604264101850877, 13.604264381828658]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 51)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 30)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 30) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 30) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 30) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 30)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2670786079914451, 'rotation_range': 18, 'optimizer': 'RMSProp', 'width_shift_range': 0.0500254284180322, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1784146464345955, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:55:04.622466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.1923 - acc: 0.1009 - val_loss: 14.7760 - val_acc: 0.0826
Epoch 2/2
 - 4s - loss: 15.3052 - acc: 0.0504 - val_loss: 14.9173 - val_acc: 0.0734
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 30), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 30) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 30) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 30) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 30)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0500254284180322, 'base_model': 'MobileNet', 'zoom_range': 0.2670786079914451, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 18, 'height_shift_range': 0.1784146464345955, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.926605504587156, 'info': {'runtime': 17.981733322143555, 'histories': {'val_acc': [0.08256880733944955, 0.07339449541284404], 'loss': [12.939472956200168, 15.234911983960295], 'acc': [0.1095890410958904, 0.0547945205479452], 'val_loss': [14.775980188212264, 14.917265935775337]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 30)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 50) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1615748165616192, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.10979178369723078, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11195357320430643, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:55:22.328315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 7.8967 - acc: 0.0757 - val_loss: 2.6136 - val_acc: 0.2569
Epoch 2/2
 - 4s - loss: 2.2006 - acc: 0.2774 - val_loss: 1.8895 - val_acc: 0.3211
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 0)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10979178369723078, 'base_model': 'MobileNet', 'zoom_range': 0.1615748165616192, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.11195357320430643, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.6788990806548967, 'info': {'runtime': 16.82435941696167, 'histories': {'val_acc': [0.25688073462849365, 0.32110091934510326], 'loss': [7.186244990727673, 2.137758542413581], 'acc': [0.0821917808219178, 0.3013698630136986], 'val_loss': [2.6135543464520654, 1.8895497365829048]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 50)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 50) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 36) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 50) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 50) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 50)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.27107368851502095, 'rotation_range': 15, 'optimizer': 'RMSProp', 'width_shift_range': 0.06324833172328818, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.18223744860128344, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:55:39.520365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.2778 - acc: 0.0883 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 2/2
 - 5s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.9351 - val_acc: 0.0734
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 50), trying to register it.
DEBUG:hpbandster:DISPATCHER: job (0, 0, 50) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 50) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 50)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.06324833172328818, 'base_model': 'MobileNet', 'zoom_range': 0.27107368851502095, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 15, 'height_shift_range': 0.18223744860128344, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9266055026732454, 'info': {'runtime': 17.925208806991577, 'histories': {'val_acc': [0.0917431196078248, 0.07339449732675465], 'loss': [13.032361357179406, 14.351728674483626], 'acc': [0.0958904109589041, 0.1095890410958904], 'val_loss': [14.639370655794757, 14.935115831707595]}}}
exception: None

INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 50) with dispatcher
DEBUG:hpbandster:job_callback for (0, 0, 50)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 36)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 36) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 49) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 36) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 36) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 36)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.10605690054362028, 'rotation_range': 29, 'optimizer': 'RMSProp', 'width_shift_range': 0.2418100107675313, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.052404174425762784, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:55:57.438439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.1728 - acc: 0.0946 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 2/2
 - 4s - loss: 14.8987 - acc: 0.0757 - val_loss: 15.2309 - val_acc: 0.0550
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 36), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 36) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 36) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 36) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 36)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2418100107675313, 'base_model': 'MobileNet', 'zoom_range': 0.10605690054362028, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 29, 'height_shift_range': 0.052404174425762784, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9449541280985972, 'info': {'runtime': 17.112799406051636, 'histories': {'val_acc': [0.11926605695978217, 0.05504587190140278], 'loss': [12.91828615371495, 14.793320433734214], 'acc': [0.10273972602739725, 0.0821917808219178], 'val_loss': [14.195753307517515, 15.230860508910013]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 36)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 49)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 49) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 28) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 49) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 49)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.011777038546923035, 'rotation_range': 16, 'optimizer': 'RMSProp', 'width_shift_range': 0.11205385960091242, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.25550630720707174, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:56:14.590107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.1806 - acc: 0.0946 - val_loss: 13.4564 - val_acc: 0.1651
Epoch 2/2
 - 4s - loss: 13.6793 - acc: 0.1513 - val_loss: 13.6043 - val_acc: 0.1560
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 49), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 49) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 49)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11205385960091242, 'base_model': 'MobileNet', 'zoom_range': 0.011777038546923035, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 16, 'height_shift_range': 0.25550630720707174, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8440366965641669, 'info': {'runtime': 17.772422790527344, 'histories': {'val_acc': [0.1651376160459781, 0.1559633034358331], 'loss': [12.926739836392338, 13.468545574031465], 'acc': [0.10273972602739725, 0.1643835616438356], 'val_loss': [13.456391483271888, 13.604264101850877]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 49)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 28)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 28) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 34) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 28) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 28) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 28)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1322686349549106, 'rotation_range': 30, 'optimizer': 'RMSProp', 'width_shift_range': 0.23420636925437918, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20267574783239153, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:56:32.404830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 12.6022 - acc: 0.1072 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 2/2
 - 5s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 28), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 28) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 28) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 28) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 28)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.23420636925437918, 'base_model': 'MobileNet', 'zoom_range': 0.1322686349549106, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 30, 'height_shift_range': 0.20267574783239153, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 18.14795422554016, 'histories': {'val_acc': [0.1467889927395987, 0.0917431196078248], 'loss': [12.298407332537925, 14.462126535912082], 'acc': [0.11643835616438356, 0.10273972602739725], 'val_loss': [13.752136072981248, 14.639370935772536]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 28)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 34)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 34) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 27) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 34) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 34) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 34)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.15225241804498887, 'rotation_range': 27, 'optimizer': 'RMSProp', 'width_shift_range': 0.12662375986373725, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20080875990019992, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:56:50.598797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 9s - loss: 5.9671 - acc: 0.0757 - val_loss: 2.2712 - val_acc: 0.1560
Epoch 2/2
 - 4s - loss: 2.1092 - acc: 0.2080 - val_loss: 2.3829 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 34), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 34) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 34) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 34) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 34)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.12662375986373725, 'base_model': 'MobileNet', 'zoom_range': 0.15225241804498887, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 27, 'height_shift_range': 0.20080875990019992, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339442705889, 'info': {'runtime': 18.73244857788086, 'histories': {'val_acc': [0.1559633034358331, 0.11926605572941107], 'loss': [6.298807297667412, 2.1089288959764456], 'acc': [0.0821917808219178, 0.22602739726027396], 'val_loss': [2.271213234017748, 2.3829128676598224]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 34)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 27)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 27) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 13) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 27) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 27) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 27)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.16331064083923394, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.2472384430591542, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2580719526544959, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:57:09.083099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 12.6682 - acc: 0.1135 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/2
 - 5s - loss: 14.6070 - acc: 0.0938 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 27), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 27) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 27) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 27) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 27)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2472384430591542, 'base_model': 'MobileNet', 'zoom_range': 0.16331064083923394, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.2580719526544959, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825688073394, 'info': {'runtime': 16.661942958831787, 'histories': {'val_acc': [0.11009174380280556, 0.10091743119266056], 'loss': [12.370105246974997, 14.607024002075196], 'acc': [0.1232876712328767, 0.09375], 'val_loss': [14.343626066085395, 14.491498684664386]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 27)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 13)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 13) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 63) to dispatcher
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 13)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06820092188942994, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.192308306823341, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21691925104091167, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:57:26.131049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 6.0280 - acc: 0.1450 - val_loss: 2.2763 - val_acc: 0.1651
Epoch 2/2
 - 4s - loss: 2.2149 - acc: 0.2270 - val_loss: 2.2898 - val_acc: 0.1468
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 13), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 13) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 13)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.192308306823341, 'base_model': 'MobileNet', 'zoom_range': 0.06820092188942994, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.21691925104091167, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8532110088325422, 'info': {'runtime': 17.483994007110596, 'histories': {'val_acc': [0.1651376165928097, 0.14678899116745783], 'loss': [6.343245016385431, 2.1819883633966315], 'acc': [0.15753424657534246, 0.2465753424657534], 'val_loss': [2.27630237701836, 2.2897736676242375]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 13)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 63)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 63) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 33) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 63) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 63)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0950242529129579, 'rotation_range': 22, 'optimizer': 'RMSProp', 'width_shift_range': 0.002023560492388432, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.0790602594222798, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:57:43.597341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 7.8436 - acc: 0.1009 - val_loss: 2.4858 - val_acc: 0.1101
Epoch 2/2
 - 4s - loss: 2.2214 - acc: 0.2774 - val_loss: 1.8701 - val_acc: 0.3578
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 63), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 63) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 63)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.002023560492388432, 'base_model': 'MobileNet', 'zoom_range': 0.0950242529129579, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 22, 'height_shift_range': 0.0790602594222798, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.6422018334953064, 'info': {'runtime': 17.233014822006226, 'histories': {'val_acc': [0.11009174311926606, 0.3577981665046937], 'loss': [8.294388715534994, 2.2126355105883455], 'acc': [0.1095890410958904, 0.3013698630136986], 'val_loss': [2.4857975933529914, 1.8701321772479136]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 63)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 33)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 33) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 26) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 33) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 33) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 33)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.011501011606773148, 'rotation_range': 2, 'optimizer': 'RMSProp', 'width_shift_range': 0.10676263674807718, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.16118366521362237, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:58:00.889509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 9s - loss: 12.8533 - acc: 0.1187 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/2
 - 4s - loss: 13.9842 - acc: 0.1324 - val_loss: 13.4564 - val_acc: 0.1651
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 33), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 33) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 33) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 33) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 33)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10676263674807718, 'base_model': 'MobileNet', 'zoom_range': 0.011501011606773148, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 2, 'height_shift_range': 0.16118366521362237, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8348623834071903, 'info': {'runtime': 17.74128031730652, 'histories': {'val_acc': [0.11009174346103581, 0.1651376165928097], 'loss': [12.853289937973022, 13.799739158316834], 'acc': [0.11875, 0.14383561643835616], 'val_loss': [14.343626206074285, 13.45639190323856]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 33)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 26)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 26) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 12) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 26) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 26)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1736972161831841, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.15721740660049613, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1079514475176631, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:58:18.667205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 12.8404 - acc: 0.1154 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 2/2
 - 4s - loss: 14.2576 - acc: 0.1154 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 26), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 26) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 26) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 26)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.15721740660049613, 'base_model': 'MobileNet', 'zoom_range': 0.1736972161831841, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.1079514475176631, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.908256880733945, 'info': {'runtime': 17.83960199356079, 'histories': {'val_acc': [0.0917431196078248, 0.09174311926605505], 'loss': [13.25145019897043, 14.793320276965833], 'acc': [0.0821917808219178, 0.0821917808219178], 'val_loss': [14.639370769535729, 14.639370629546839]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 26)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 12)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 12) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 32) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 12)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.08604319910868594, 'rotation_range': 13, 'optimizer': 'RMSProp', 'width_shift_range': 0.0634226513793555, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.015345808165384521, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:58:36.541458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.5896 - acc: 0.0693 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/2
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 12), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 12) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 12) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 12)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0634226513793555, 'base_model': 'MobileNet', 'zoom_range': 0.08604319910868594, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 13, 'height_shift_range': 0.015345808165384521, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825684655697, 'info': {'runtime': 18.753643035888672, 'histories': {'val_acc': [0.08256880733944955, 0.10091743153443031], 'loss': [13.3711307212098, 14.682922467793503], 'acc': [0.07534246575342465, 0.08904109589041095], 'val_loss': [14.787242854407074, 14.491498824653275]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 12)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 32)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 32) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 61) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 32) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 32) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 32)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.18694642490483945, 'rotation_range': 18, 'optimizer': 'RMSProp', 'width_shift_range': 0.12072766851550865, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11833614046626591, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:58:55.346484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.5505 - acc: 0.0693 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/2
 - 5s - loss: 14.9092 - acc: 0.0750 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 32), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 32) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 32) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 32) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 32)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.12072766851550865, 'base_model': 'MobileNet', 'zoom_range': 0.18694642490483945, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 18, 'height_shift_range': 0.11833614046626591, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825684655697, 'info': {'runtime': 18.80864930152893, 'histories': {'val_acc': [0.10091743187620006, 0.10091743153443031], 'loss': [13.328629219368713, 14.909238052368163], 'acc': [0.07534246575342465, 0.075], 'val_loss': [14.491498570923412, 14.491498430934522]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 32)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 61)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 61) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 47) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 61) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 61) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 61)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.12486654860146486, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.2226453965105465, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1420243599771951, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:59:13.886958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 5.9462 - acc: 0.1135 - val_loss: 2.1134 - val_acc: 0.2385
Epoch 2/2
 - 4s - loss: 2.2792 - acc: 0.2585 - val_loss: 1.9446 - val_acc: 0.2936
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 61), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 61) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 61) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 61) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 61)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2226453965105465, 'base_model': 'MobileNet', 'zoom_range': 0.12486654860146486, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.1420243599771951, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.7064220164347133, 'info': {'runtime': 17.97881817817688, 'histories': {'val_acc': [0.23853211009174313, 0.29357798356528675], 'loss': [5.23680289804119, 2.230603864748184], 'acc': [0.1232876712328767, 0.2808219178082192], 'val_loss': [2.113410424748692, 1.9445875675306408]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 61)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 47)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 47) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 47) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 47) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 47)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0034596733664872814, 'rotation_range': 30, 'optimizer': 'RMSProp', 'width_shift_range': 0.24925130004164747, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08734735554984838, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:59:31.916050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 12.6432 - acc: 0.1217 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/2
 - 4s - loss: 14.2576 - acc: 0.1154 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 47), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 47) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 47) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 47) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 47)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.24925130004164747, 'base_model': 'MobileNet', 'zoom_range': 0.0034596733664872814, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 30, 'height_shift_range': 0.08734735554984838, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 17.76806402206421, 'histories': {'val_acc': [0.08256880802298905, 0.0917431196078248], 'loss': [13.039359497697387, 14.793320276965833], 'acc': [0.08904109589041095, 0.0821917808219178], 'val_loss': [14.78724346685847, 14.639370935772536]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 47)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.12868459232692314, 'rotation_range': 1, 'optimizer': 'RMSProp', 'width_shift_range': 0.22767536467020139, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.02338123654391112, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 18:59:49.729285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.2244 - acc: 0.0757 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 2/2
 - 4s - loss: 13.6479 - acc: 0.1533 - val_loss: 14.0479 - val_acc: 0.1284
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 1)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.22767536467020139, 'base_model': 'MobileNet', 'zoom_range': 0.12868459232692314, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 1, 'height_shift_range': 0.02338123654391112, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8715596326857532, 'info': {'runtime': 16.966766834259033, 'histories': {'val_acc': [0.13761467889908258, 0.12844036731424682], 'loss': [13.465517031003351, 14.130932899370585], 'acc': [0.0821917808219178, 0.1232876712328767], 'val_loss': [13.900008945290102, 14.047881196398254]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 8) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.0016573244368102479, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:00:07.094901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 8s - loss: 9.0902 - acc: 0.1072 - val_loss: 2.6102 - val_acc: 0.0917
Epoch 2/4
 - 4s - loss: 2.4119 - acc: 0.3065 - val_loss: 1.9124 - val_acc: 0.3028
Epoch 3/4
 - 4s - loss: 1.8624 - acc: 0.3846 - val_loss: 3.7704 - val_acc: 0.1376
Epoch 4/4
 - 4s - loss: 1.9004 - acc: 0.4161 - val_loss: 1.6686 - val_acc: 0.5138
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 9)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0016573244368102479, 'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.48623852828227054, 'info': {'runtime': 26.526643991470337, 'histories': {'val_acc': [0.0917431196078248, 0.3027522949450607, 0.13761467889908258, 0.5137614717177295], 'loss': [8.482819831534608, 2.4901138870683437, 1.833840977655698, 1.8706910185617944], 'acc': [0.11643835616438356, 0.2465753424657534, 0.4178082191780822, 0.4520547945205479], 'val_loss': [2.610202771808029, 1.9123619346443665, 3.770419203906978, 1.6685572293920254]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 8)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 8) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 42) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 8) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 8)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2831500712306704, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.11553792182868505, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.10673317706594039, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:00:33.602562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 8s - loss: 13.3239 - acc: 0.0946 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/4
 - 5s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/4
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 4/4
 - 4s - loss: 15.1940 - acc: 0.0573 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 8), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 8) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 8) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 8)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11553792182868505, 'base_model': 'MobileNet', 'zoom_range': 0.2831500712306704, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.10673317706594039, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 26.881280422210693, 'histories': {'val_acc': [0.11009174311926606, 0.10091743187620006, 0.10091743310657117, 0.0917431196078248], 'loss': [13.082414026129735, 14.506285762786865, 14.68292236328125, 15.019134174693715], 'acc': [0.10273972602739725, 0.1, 0.08904109589041095, 0.06818181818181818], 'val_loss': [14.34362645980415, 14.491498850901193, 14.491498317193548, 14.639370375816975]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 8)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 42)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 42) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 42) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 42)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.04541364089078729, 'rotation_range': 17, 'optimizer': 'RMSProp', 'width_shift_range': 0.14607169417938207, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1434785068301523, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:01:00.543544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 9s - loss: 6.8412 - acc: 0.1198 - val_loss: 2.3012 - val_acc: 0.2110
Epoch 2/4
 - 4s - loss: 2.2489 - acc: 0.2667 - val_loss: 1.8818 - val_acc: 0.5505
Epoch 3/4
 - 4s - loss: 2.3550 - acc: 0.2207 - val_loss: 1.8826 - val_acc: 0.3211
Epoch 4/4
 - 4s - loss: 2.0842 - acc: 0.4307 - val_loss: 1.7007 - val_acc: 0.4587
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 42), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 42) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 42)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.14607169417938207, 'base_model': 'MobileNet', 'zoom_range': 0.04541364089078729, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 17, 'height_shift_range': 0.1434785068301523, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.5412844023026457, 'info': {'runtime': 27.224295616149902, 'histories': {'val_acc': [0.21100917622583723, 0.5504587188773199, 0.3211009218058455, 0.45871559769735426], 'loss': [7.159650456415464, 2.279003620147705, 2.3512788602750594, 2.1302007224461805], 'acc': [0.13013698630136986, 0.2465753424657534, 0.23972602739726026, 0.4246575342465753], 'val_loss': [2.301150700367919, 1.8818008932498618, 1.8826083404208542, 1.7007055610691735]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 42)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 7)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 20) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 7)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2892001144443167, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.2870985207906671, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.25925836847713396, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:01:27.812862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 8s - loss: 8.7868 - acc: 0.0563 - val_loss: 2.2021 - val_acc: 0.2110
Epoch 2/4
 - 4s - loss: 2.2813 - acc: 0.3104 - val_loss: 2.1183 - val_acc: 0.2477
Epoch 3/4
 - 4s - loss: 2.1431 - acc: 0.3278 - val_loss: 2.0333 - val_acc: 0.2569
Epoch 4/4
 - 4s - loss: 2.2593 - acc: 0.3235 - val_loss: 1.5717 - val_acc: 0.5138
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 7), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 7)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2870985207906671, 'base_model': 'MobileNet', 'zoom_range': 0.2892001144443167, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.25925836847713396, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.4862385307430127, 'info': {'runtime': 26.887853384017944, 'histories': {'val_acc': [0.21100917622583723, 0.24770642201834864, 0.25688073531203315, 0.5137614692569873], 'loss': [8.786781883239746, 2.355239593621456, 2.0687538107780563, 2.305057252923103], 'acc': [0.05625, 0.22727272727272727, 0.3561643835616438, 0.3082191780821918], 'val_loss': [2.202145482422015, 2.1182913692719345, 2.0333412896602527, 1.5716767967294116]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 7)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 20)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 20) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 40) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 20)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.08997505136600327, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:01:54.737025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 8s - loss: 12.0366 - acc: 0.0883 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 2/4
 - 4s - loss: 13.8825 - acc: 0.1387 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 3/4
 - 6s - loss: 13.5996 - acc: 0.1562 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 4/4
 - 4s - loss: 13.3431 - acc: 0.1722 - val_loss: 13.4564 - val_acc: 0.1651
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 20), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 20) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 20)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08997505136600327, 'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8348623846375613, 'info': {'runtime': 29.718206882476807, 'histories': {'val_acc': [0.12844036697247707, 0.1467889921927671, 0.11926605695978217, 0.1651376153624386], 'loss': [11.683858453410945, 13.689341192376125, 13.59964303970337, 13.79973921057296], 'acc': [0.0958904109589041, 0.1506849315068493, 0.15625, 0.14383561643835616], 'val_loss': [14.047881450128118, 13.752136492947919, 14.195753587495297, 13.456391483271888]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 20)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 40)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 40) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 19) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 40) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 40) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 40)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1462127156317999, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.22431353736636975, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21861940757471376, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:02:24.176864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 9s - loss: 13.2495 - acc: 0.0875 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 2/4
 - 4s - loss: 15.1940 - acc: 0.0573 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 3/4
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 4/4
 - 5s - loss: 15.5084 - acc: 0.0378 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 40), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 40) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 40) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 40) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 40)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.22431353736636975, 'base_model': 'MobileNet', 'zoom_range': 0.1462127156317999, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.21861940757471376, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568800504054, 'info': {'runtime': 28.945308446884155, 'histories': {'val_acc': [0.07339449609638354, 0.07339449609638354, 0.10091743119266056, 0.09174311994959455], 'loss': [13.24945571422577, 15.019134290290602, 14.68292236328125, 15.45570770681721], 'acc': [0.0875, 0.06818181818181818, 0.08904109589041095, 0.0410958904109589], 'val_loss': [14.935115525481898, 14.935115525481898, 14.491498404686604, 14.639371075761428]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 40)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 19)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 19) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 54) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 19)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.19956006504962495, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.18472340643110186, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08962149295842833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:02:53.174789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 8s - loss: 13.0022 - acc: 0.0946 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 2/4
 - 4s - loss: 4.3311 - acc: 0.1135 - val_loss: 2.0274 - val_acc: 0.2752
Epoch 3/4
 - 4s - loss: 2.2187 - acc: 0.3191 - val_loss: 1.7107 - val_acc: 0.4220
Epoch 4/4
 - 4s - loss: 1.7994 - acc: 0.3909 - val_loss: 1.8272 - val_acc: 0.3303
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 19), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 19) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 19)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.18472340643110186, 'base_model': 'MobileNet', 'zoom_range': 0.19956006504962495, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.08962149295842833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.6697247692751228, 'info': {'runtime': 25.7920823097229, 'histories': {'val_acc': [0.12844036731424682, 0.2752293616259864, 0.4220183519048428, 0.3302752307248772], 'loss': [12.732905845119529, 4.455820704159671, 2.267532381292892, 1.6928143044040627], 'acc': [0.10273972602739725, 0.1232876712328767, 0.2602739726027397, 0.4246575342465753], 'val_loss': [14.047881590117008, 2.0274403171801785, 1.7106597434490098, 1.8271887411765002]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 19)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 54)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 54) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 39) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 54) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 54) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 54)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.29834588384162414, 'rotation_range': 2, 'optimizer': 'RMSProp', 'width_shift_range': 0.039904902531420094, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.034857645300040936, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:03:19.381917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 8s - loss: 12.8189 - acc: 0.1261 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/4
 - 4s - loss: 13.5463 - acc: 0.1596 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 3/4
 - 5s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 4/4
 - 5s - loss: 14.4055 - acc: 0.1062 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 54), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 54) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 54) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 54) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 54)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.039904902531420094, 'base_model': 'MobileNet', 'zoom_range': 0.29834588384162414, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 2, 'height_shift_range': 0.034857645300040936, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339446123587, 'info': {'runtime': 27.161447048187256, 'histories': {'val_acc': [0.10091743153443031, 0.10091743153443031, 0.10091743187620006, 0.11926605538764132], 'loss': [12.533830590444069, 14.020535142454383, 14.572524449596667, 14.405547523498536], 'acc': [0.136986301369863, 0.13013698630136986, 0.0958904109589041, 0.10625], 'val_loss': [14.491498264697714, 14.491498430934522, 14.49149829094563, 14.195754094955024]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 54)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 39)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 39) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 51) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 39) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 39)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06671035764987453, 'rotation_range': 29, 'optimizer': 'RMSProp', 'width_shift_range': 0.10424498149525974, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.13628009945988093, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:03:46.532154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 8s - loss: 11.4410 - acc: 0.1072 - val_loss: 2.4616 - val_acc: 0.0826
Epoch 2/4
 - 4s - loss: 2.3463 - acc: 0.1639 - val_loss: 2.3859 - val_acc: 0.2018
Epoch 3/4
 - 5s - loss: 1.8610 - acc: 0.3250 - val_loss: 2.3008 - val_acc: 0.2385
Epoch 4/4
 - 4s - loss: 2.1132 - acc: 0.2930 - val_loss: 1.8278 - val_acc: 0.3394
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 39), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 39) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 39)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10424498149525974, 'base_model': 'MobileNet', 'zoom_range': 0.06671035764987453, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 29, 'height_shift_range': 0.13628009945988093, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.6605504568016858, 'info': {'runtime': 27.042720556259155, 'histories': {'val_acc': [0.0825688076812193, 0.20183486306886061, 0.23853211145882214, 0.3394495431983143], 'loss': [11.036800332265358, 2.3521434705551356, 1.8609960079193115, 2.047418849034743], 'acc': [0.11643835616438356, 0.1780821917808219, 0.325, 0.3484848484848485], 'val_loss': [2.461624617970318, 2.3858622410975463, 2.3007766609891838, 1.8277758633324859]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 39)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 51)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 51) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 51) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 51) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 51)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.08049394612852068, 'rotation_range': 3, 'optimizer': 'RMSProp', 'width_shift_range': 0.009350487374865102, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2302834993331358, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:04:13.626959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 9s - loss: 12.5374 - acc: 0.1072 - val_loss: 13.0128 - val_acc: 0.1927
Epoch 2/4
 - 4s - loss: 14.2890 - acc: 0.1135 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 3/4
 - 4s - loss: 12.7334 - acc: 0.2100 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 4/4
 - 5s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 51), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 51) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 51) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 51) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 51)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.009350487374865102, 'base_model': 'MobileNet', 'zoom_range': 0.08049394612852068, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 3, 'height_shift_range': 0.2302834993331358, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339442705889, 'info': {'runtime': 26.541106939315796, 'histories': {'val_acc': [0.1926605511422551, 0.1559633034358331, 0.11926605504587157, 0.11926605572941107], 'loss': [12.227996930684128, 14.130932847114458, 13.137351832977712, 14.506285476684571], 'acc': [0.11643835616438356, 0.1232876712328767, 0.18493150684931506, 0.1], 'val_loss': [13.012774082498813, 13.604264268087684, 14.195753954966134, 14.195753561247379]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 51)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 49) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1615748165616192, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.10979178369723078, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11195357320430643, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:04:39.879050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 8s - loss: 13.8787 - acc: 0.0630 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 2/4
 - 4s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 3/4
 - 5s - loss: 14.7078 - acc: 0.0875 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 4/4
 - 4s - loss: 15.0913 - acc: 0.0637 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 0)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10979178369723078, 'base_model': 'MobileNet', 'zoom_range': 0.1615748165616192, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.11195357320430643, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082568807339, 'info': {'runtime': 26.57552742958069, 'histories': {'val_acc': [0.10091743119266056, 0.08256880733944955, 0.06422018348623854, 0.11009174311926606], 'loss': [13.685150120356312, 14.572524606365047, 14.707762050628663, 14.897027333577475], 'acc': [0.0684931506849315, 0.0958904109589041, 0.0875, 0.07575757575757576], 'val_loss': [14.491498684664386, 14.787243134384855, 15.082988144060888, 14.34362617982637]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 49)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 49) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 13) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 49) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 49)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.011777038546923035, 'rotation_range': 16, 'optimizer': 'RMSProp', 'width_shift_range': 0.11205385960091242, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.25550630720707174, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:05:06.494280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 10s - loss: 12.8893 - acc: 0.1375 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 2/4
 - 5s - loss: 13.8825 - acc: 0.1387 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 3/4
 - 4s - loss: 14.4752 - acc: 0.1019 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 4/4
 - 5s - loss: 13.5996 - acc: 0.1562 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 49), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 49) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 49)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11205385960091242, 'base_model': 'MobileNet', 'zoom_range': 0.011777038546923035, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 16, 'height_shift_range': 0.25550630720707174, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853197338385, 'info': {'runtime': 28.030210971832275, 'histories': {'val_acc': [0.1559633034358331, 0.1467889921927671, 0.11009174380280556, 0.13761468026616158], 'loss': [12.889323949813843, 13.68934108786387, 14.164386749267578, 13.599642848968506], 'acc': [0.1375, 0.1506849315068493, 0.12121212121212122, 0.15625], 'val_loss': [13.604263821873095, 13.7521367729257, 14.343625786107614, 13.900008717808154]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 49)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 13)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 13) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 63) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 13) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 13)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06820092188942994, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.192308306823341, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21691925104091167, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:05:34.947478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 8s - loss: 13.2298 - acc: 0.1009 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 2/4
 - 5s - loss: 14.1033 - acc: 0.1250 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/4
 - 4s - loss: 14.5779 - acc: 0.0956 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 4/4
 - 4s - loss: 14.0858 - acc: 0.1261 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 13), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 13) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 13) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 13)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.192308306823341, 'base_model': 'MobileNet', 'zoom_range': 0.06820092188942994, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.21691925104091167, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082565389642, 'info': {'runtime': 26.604002952575684, 'histories': {'val_acc': [0.09174311926605505, 0.11009174380280556, 0.11009174380280556, 0.11009174346103581], 'loss': [14.164269391804526, 14.10333318710327, 14.286493590383818, 13.910137124257545], 'acc': [0.1095890410958904, 0.125, 0.11363636363636363, 0.136986301369863], 'val_loss': [14.63937090952462, 14.343626066085395, 14.343625952344421, 14.343625759859698]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 13)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 63)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 63) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 33) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 63) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 63)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0950242529129579, 'rotation_range': 22, 'optimizer': 'RMSProp', 'width_shift_range': 0.002023560492388432, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.0790602594222798, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:06:01.561556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 9s - loss: 12.9763 - acc: 0.1072 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/4
 - 4s - loss: 13.9528 - acc: 0.1343 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 3/4
 - 5s - loss: 14.1033 - acc: 0.1250 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 4/4
 - 4s - loss: 14.4922 - acc: 0.1009 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 63), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 63) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 63)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.002023560492388432, 'base_model': 'MobileNet', 'zoom_range': 0.0950242529129579, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 22, 'height_shift_range': 0.0790602594222798, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853204173779, 'info': {'runtime': 29.212966442108154, 'histories': {'val_acc': [0.11009174311926606, 0.12844036731424682, 0.10091743153443031, 0.13761467958262208], 'loss': [13.886199569048946, 14.462126692680464, 14.103333568572998, 14.351728674483626], 'acc': [0.11643835616438356, 0.10273972602739725, 0.125, 0.1095890410958904], 'val_loss': [14.343625899848588, 14.047881310139227, 14.491498544675494, 13.900008831549128]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 63)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 33)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 33) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 61) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 33) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 33) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 33)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.011501011606773148, 'rotation_range': 2, 'optimizer': 'RMSProp', 'width_shift_range': 0.10676263674807718, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.16118366521362237, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:06:30.469098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 8s - loss: 13.9855 - acc: 0.0567 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/4
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 15.0830 - val_acc: 0.0642
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/4
 - 8s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 4/4
 - 5s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 33), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 33) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 33) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 33) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 33)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10676263674807718, 'base_model': 'MobileNet', 'zoom_range': 0.011501011606773148, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 2, 'height_shift_range': 0.16118366521362237, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825681237999, 'info': {'runtime': 31.363262176513672, 'histories': {'val_acc': [0.08256880733944955, 0.06422018348623854, 0.11926605538764132, 0.10091743187620006], 'loss': [13.801187175593965, 14.682922572305758, 14.682922467793503, 14.351728674483626], 'acc': [0.06164383561643835, 0.08904109589041095, 0.08904109589041095, 0.1095890410958904], 'val_loss': [14.787243414362637, 15.082987864083107, 14.195753814977243, 14.491498177204656]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 33)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 61)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 61) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 61) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 61) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 61)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.12486654860146486, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.2226453965105465, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1420243599771951, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:07:01.877510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 9s - loss: 13.4415 - acc: 0.0875 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 2/4
 - 4s - loss: 14.3725 - acc: 0.1083 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 3/4
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 4/4
 - 4s - loss: 13.7496 - acc: 0.1469 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 61), trying to register it.
DEBUG:hpbandster:DISPATCHER: job (0, 0, 61) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 61) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 61)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2226453965105465, 'base_model': 'MobileNet', 'zoom_range': 0.12486654860146486, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.1420243599771951, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 27.933890104293823, 'histories': {'val_acc': [0.11926605538764132, 0.0825688076812193, 0.10091743153443031, 0.0917431196078248], 'loss': [13.441465854644775, 14.042279908151338, 14.68292236328125, 14.241330760799043], 'acc': [0.0875, 0.12878787878787878, 0.08904109589041095, 0.11643835616438356], 'val_loss': [14.195754094955024, 14.787243554351527, 14.491498710912301, 14.63937104951351]}}}
exception: None

INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 61) with dispatcher
DEBUG:hpbandster:job_callback for (0, 0, 61)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.13070844626277076, 'rotation_range': 11, 'optimizer': 'RMSProp', 'width_shift_range': 0.28809388168018457, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.07922358039346385, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:07:30.248988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 8s - loss: 13.4084 - acc: 0.0757 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/2
 - 4s - loss: 14.1560 - acc: 0.1217 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 2), trying to register it.
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 2)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.28809388168018457, 'base_model': 'MobileNet', 'zoom_range': 0.13070844626277076, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 11, 'height_shift_range': 0.07922358039346385, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082568807339, 'info': {'runtime': 17.957951068878174, 'histories': {'val_acc': [0.10091743153443031, 0.11009174311926606], 'loss': [13.459287656496649, 14.682922415537377], 'acc': [0.0821917808219178, 0.08904109589041095], 'val_loss': [14.491498710912301, 14.34362617982637]}}}
exception: None

INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 2) with dispatcher
DEBUG:hpbandster:job_callback for (1, 0, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 42) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.0016573244368102479, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:07:48.188268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 10s - loss: 12.8412 - acc: 0.1072 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 2/8
 - 4s - loss: 14.1874 - acc: 0.1198 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 3/8
 - 5s - loss: 14.1874 - acc: 0.1198 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 4/8
 - 5s - loss: 14.3048 - acc: 0.1125 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 5/8
 - 4s - loss: 13.8591 - acc: 0.1402 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 6/8
 - 5s - loss: 13.5996 - acc: 0.1562 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 7/8
 - 5s - loss: 13.3431 - acc: 0.1722 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 8/8
 - 5s - loss: 6.3739 - acc: 0.1198 - val_loss: 2.2296 - val_acc: 0.2752
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 9)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0016573244368102479, 'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.7247706402879243, 'info': {'runtime': 48.707799673080444, 'histories': {'val_acc': [0.12844036731424682, 0.13761467889908258, 0.1376146808129932, 0.1559633034358331, 0.10091743153443031, 0.14678899082568808, 0.1559633034358331, 0.27522935971207574], 'loss': [12.558034766210268, 14.020534985686002, 14.020535090198255, 14.3048095703125, 13.431746049360795, 13.599642753601074, 13.799739106060708, 6.705565299073311], 'acc': [0.11643835616438356, 0.13013698630136986, 0.13013698630136986, 0.1125, 0.16666666666666666, 0.15625, 0.14383561643835616, 0.13013698630136986], 'val_loss': [14.04788187009479, 13.90000866531232, 13.900008857797046, 13.604263988109903, 14.491498544675494, 13.752136720429867, 13.604264101850877, 2.2295939309881367]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 42)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 42) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 42) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 42)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.04541364089078729, 'rotation_range': 17, 'optimizer': 'RMSProp', 'width_shift_range': 0.14607169417938207, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1434785068301523, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:08:36.959490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 9s - loss: 13.7059 - acc: 0.0630 - val_loss: 14.9351 - val_acc: 0.0734
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 2/8
 - 5s - loss: 14.7078 - acc: 0.0875 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 3/8
 - 4s - loss: 14.5779 - acc: 0.0956 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 4/8
 - 4s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 5/8
 - 5s - loss: 14.9092 - acc: 0.0750 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 6/8
 - 4s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 7/8
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 8/8
 - 4s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 42), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 42) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 42) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 42)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.14607169417938207, 'base_model': 'MobileNet', 'zoom_range': 0.04541364089078729, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 17, 'height_shift_range': 0.1434785068301523, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568800504054, 'info': {'runtime': 45.227559089660645, 'histories': {'val_acc': [0.07339449575461379, 0.07339449541284404, 0.06422018382800829, 0.11009174380280556, 0.0917431196078248, 0.10091743119266056, 0.10091743187620006, 0.09174311994959455], 'loss': [13.497454133752274, 14.70776195526123, 14.286493705980705, 14.351728674483626, 14.909238147735596, 14.793320329221961, 14.68292236328125, 14.903718086138163], 'acc': [0.0684931506849315, 0.0875, 0.11363636363636363, 0.1095890410958904, 0.075, 0.0821917808219178, 0.08904109589041095, 0.07534246575342465], 'val_loss': [14.935115385493008, 14.935115639222872, 15.082988170308804, 14.343626066085395, 14.639370655794757, 14.491498404686604, 14.491497897226877, 14.639370795783647]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 42)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 7)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 20) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 7)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2892001144443167, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.2870985207906671, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.25925836847713396, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:09:21.866680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 8s - loss: 13.2545 - acc: 0.0946 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 2/8
 - 4s - loss: 14.0544 - acc: 0.1280 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 3/8
 - 5s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 4/8
 - 4s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 5/8
 - 5s - loss: 14.5063 - acc: 0.1000 - val_loss: 15.0830 - val_acc: 0.0642
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 6/8
 - 4s - loss: 14.8859 - acc: 0.0764 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 7/8
 - 4s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 8/8
 - 5s - loss: 14.8085 - acc: 0.0813 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 7), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 7)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2870985207906671, 'base_model': 'MobileNet', 'zoom_range': 0.2892001144443167, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.25925836847713396, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 43.25986981391907, 'histories': {'val_acc': [0.07339449575461379, 0.06422018416977804, 0.11009174346103581, 0.10091743153443031, 0.06422018348623854, 0.0917431196078248, 0.10091743153443031, 0.0917431196078248], 'loss': [14.214915807933023, 14.572524449596667, 14.46212674493659, 14.793320224709706, 14.50628595352173, 14.652813766941879, 14.572524606365047, 14.808500003814697], 'acc': [0.10273972602739725, 0.0958904109589041, 0.10273972602739725, 0.0821917808219178, 0.1, 0.09090909090909091, 0.0958904109589041, 0.08125], 'val_loss': [14.935115779211761, 15.082988030319914, 14.34362631981526, 14.491498430934522, 15.082987864083107, 14.639370935772536, 14.491498264697714, 14.639370935772536]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 7)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 20)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 20) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 19) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 20)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.08997505136600327, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:10:05.171302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 8s - loss: 13.2874 - acc: 0.0938 - val_loss: 14.9206 - val_acc: 0.0734
Epoch 2/8
 - 4s - loss: 14.2576 - acc: 0.1154 - val_loss: 14.4616 - val_acc: 0.1009
Epoch 3/8
 - 4s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.6245 - val_acc: 0.0917
Epoch 4/8
 - 4s - loss: 15.2966 - acc: 0.0510 - val_loss: 14.8954 - val_acc: 0.0734
Epoch 5/8
 - 5s - loss: 14.8085 - acc: 0.0813 - val_loss: 14.8934 - val_acc: 0.0734
Epoch 6/8
 - 4s - loss: 14.2890 - acc: 0.1135 - val_loss: 14.4826 - val_acc: 0.1009
Epoch 7/8
 - 4s - loss: 14.8859 - acc: 0.0764 - val_loss: 14.7411 - val_acc: 0.0826
Epoch 8/8
 - 5s - loss: 14.7078 - acc: 0.0875 - val_loss: 14.1547 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 20), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 20) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 20)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08997505136600327, 'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339442705889, 'info': {'runtime': 43.94661855697632, 'histories': {'val_acc': [0.07339449732675465, 0.10091743187620006, 0.09174312117996566, 0.07339449541284404, 0.07339449677992305, 0.10091743187620006, 0.08256880733944955, 0.11926605572941107], 'loss': [13.287442445755005, 14.793320276965833, 14.793320224709706, 15.141240900213068, 14.808500003814697, 14.130932847114458, 14.652813998135654, 14.707761859893798], 'acc': [0.09375, 0.0821917808219178, 0.0821917808219178, 0.06060606060606061, 0.08125, 0.1232876712328767, 0.09090909090909091, 0.0875], 'val_loss': [14.920590584431219, 14.461629902550934, 14.624490002973364, 14.89536743864007, 14.893354249656747, 14.482591077822065, 14.741090757037522, 14.154678300980034]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 20)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 19)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 19) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 39) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 19)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.19956006504962495, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.18472340643110186, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08962149295842833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:10:49.561580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 8s - loss: 6.5383 - acc: 0.1687 - val_loss: 3.7247 - val_acc: 0.1468
Epoch 2/8
 - 4s - loss: 2.4618 - acc: 0.2691 - val_loss: 1.9292 - val_acc: 0.3303
Epoch 3/8
 - 4s - loss: 1.7704 - acc: 0.3341 - val_loss: 1.7666 - val_acc: 0.2844
Epoch 4/8
 - 5s - loss: 1.6497 - acc: 0.4748 - val_loss: 1.3920 - val_acc: 0.5138
Epoch 5/8
 - 5s - loss: 1.3585 - acc: 0.4811 - val_loss: 1.8468 - val_acc: 0.4220
Epoch 6/8
 - 4s - loss: 1.6579 - acc: 0.5063 - val_loss: 1.2151 - val_acc: 0.5596
Epoch 7/8
 - 5s - loss: 0.9151 - acc: 0.6688 - val_loss: 1.7080 - val_acc: 0.3670
Epoch 8/8
 - 4s - loss: 1.5631 - acc: 0.5737 - val_loss: 1.0631 - val_acc: 0.6422
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 19), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 19) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 19)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.18472340643110186, 'base_model': 'MobileNet', 'zoom_range': 0.19956006504962495, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.08962149295842833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.3577981629502882, 'info': {'runtime': 44.83759641647339, 'histories': {'val_acc': [0.14678899150922758, 0.3302752307248772, 0.28440367109184966, 0.5137614711708979, 0.42201834999093224, 0.5596330297102622, 0.36697248089204143, 0.6422018370497118], 'loss': [6.538270115852356, 2.2971125642458596, 1.7334464935407246, 1.6885740234427256, 1.3781253654662877, 1.7111257935223514, 0.9151303499937058, 1.4526287202965724], 'acc': [0.16875, 0.2727272727272727, 0.363013698630137, 0.4726027397260274, 0.4794520547945205, 0.5068493150684932, 0.66875, 0.6232876712328768], 'val_loss': [3.7247053286351197, 1.929187610608722, 1.7666191803205997, 1.3919501676471955, 1.8468419783705965, 1.21509659727779, 1.7079784979514026, 1.0630885231385536]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 19)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 39)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 39) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 49) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 39) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 39)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06671035764987453, 'rotation_range': 29, 'optimizer': 'RMSProp', 'width_shift_range': 0.10424498149525974, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.13628009945988093, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:11:34.414881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 8s - loss: 11.3155 - acc: 0.1911 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 2/8
 - 4s - loss: 13.5463 - acc: 0.1596 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/8
 - 5s - loss: 13.2415 - acc: 0.1785 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 4/8
 - 4s - loss: 14.2890 - acc: 0.1135 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 5/8
 - 4s - loss: 13.5777 - acc: 0.1576 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 6/8
 - 5s - loss: 14.3048 - acc: 0.1125 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 7/8
 - 4s - loss: 13.7564 - acc: 0.1465 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 8/8
 - 5s - loss: 13.5996 - acc: 0.1562 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 39), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 39) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 39) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 39)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10424498149525974, 'base_model': 'MobileNet', 'zoom_range': 0.06671035764987453, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 29, 'height_shift_range': 0.13628009945988093, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339446123587, 'info': {'runtime': 45.232340812683105, 'histories': {'val_acc': [0.1467889927395987, 0.0917431196078248, 0.1467889927395987, 0.12844036888638768, 0.13761467924085233, 0.1559633046662042, 0.1559633034358331, 0.11926605538764132], 'loss': [11.596922260441191, 14.020535037942128, 13.689341244632251, 14.130932951626713, 13.3581475035785, 14.304809665679931, 13.309639323841441, 13.599643135070801], 'acc': [0.1643835616438356, 0.13013698630136986, 0.1506849315068493, 0.1232876712328767, 0.17123287671232876, 0.1125, 0.17424242424242425, 0.15625], 'val_loss': [13.75213691291459, 14.63937104951351, 13.75213663293681, 14.04788108265728, 13.900008805301212, 13.604263848121013, 13.604263988109903, 14.195753814977243]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 39)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 49)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 49) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 63) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 49) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 49)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.011777038546923035, 'rotation_range': 16, 'optimizer': 'RMSProp', 'width_shift_range': 0.11205385960091242, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.25550630720707174, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:12:19.319445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 8s - loss: 12.7939 - acc: 0.1154 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 2/8
 - 4s - loss: 9.4617 - acc: 0.1062 - val_loss: 2.2285 - val_acc: 0.1468
Epoch 3/8
 - 4s - loss: 2.1912 - acc: 0.2207 - val_loss: 2.5761 - val_acc: 0.1101
Epoch 4/8
 - 4s - loss: 2.5751 - acc: 0.2207 - val_loss: 2.2155 - val_acc: 0.1376
Epoch 5/8
 - 4s - loss: 1.9134 - acc: 0.3739 - val_loss: 1.7435 - val_acc: 0.3670
Epoch 6/8
 - 4s - loss: 1.8830 - acc: 0.4539 - val_loss: 1.2783 - val_acc: 0.7064
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 7/8
 - 5s - loss: 1.4621 - acc: 0.5375 - val_loss: 1.6726 - val_acc: 0.4404
Epoch 8/8
 - 4s - loss: 1.2750 - acc: 0.5548 - val_loss: 1.2174 - val_acc: 0.6055
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 49), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 49) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 49)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11205385960091242, 'base_model': 'MobileNet', 'zoom_range': 0.011777038546923035, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 16, 'height_shift_range': 0.25550630720707174, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.3944954084693839, 'info': {'runtime': 43.27539086341858, 'histories': {'val_acc': [0.0917431196078248, 0.14678899116745783, 0.11009174503317666, 0.1376146808129932, 0.3669724789781308, 0.7064220265510979, 0.44036697439097483, 0.6055045915306161], 'loss': [13.203066368625588, 9.461675691604615, 2.1369791782065612, 2.5910336710002326, 1.9399850058229002, 1.8500279928698684, 1.462117737531662, 1.2152602035705358], 'acc': [0.0821917808219178, 0.10625, 0.23972602739726026, 0.23972602739726026, 0.363013698630137, 0.49242424242424243, 0.5375, 0.6027397260273972], 'val_loss': [14.639370769535729, 2.2285172611201576, 2.5760718999652688, 2.215508615205047, 1.7435082601844718, 1.2782771937344053, 1.6726244720843955, 1.217371471431277]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 49)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 63)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 63) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 63) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 63)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0950242529129579, 'rotation_range': 22, 'optimizer': 'RMSProp', 'width_shift_range': 0.002023560492388432, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.0790602594222798, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:13:02.649318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 8s - loss: 13.3644 - acc: 0.0820 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 2/8
 - 5s - loss: 14.7078 - acc: 0.0875 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 3/8
 - 4s - loss: 14.9886 - acc: 0.0701 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 4/8
 - 6s - loss: 14.8085 - acc: 0.0813 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 5/8
 - 4s - loss: 15.6047 - acc: 0.0319 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 6/8
 - 5s - loss: 14.6070 - acc: 0.0938 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 7/8
 - 4s - loss: 15.0913 - acc: 0.0637 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 8/8
 - 5s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 63), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 63) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 63) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 63)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.002023560492388432, 'base_model': 'MobileNet', 'zoom_range': 0.0950242529129579, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 22, 'height_shift_range': 0.0790602594222798, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.908256880733945, 'info': {'runtime': 47.26313662528992, 'histories': {'val_acc': [0.0917431196078248, 0.0917431196078248, 0.11009174380280556, 0.08256880802298905, 0.10091743187620006, 0.10091743187620006, 0.11009174311926606, 0.09174311926605505], 'loss': [13.12639649273598, 14.707762050628663, 14.774920608058121, 14.80850009918213, 15.50756142356179, 14.6070237159729, 14.897027564771248, 14.506285858154296], 'acc': [0.08904109589041095, 0.0875, 0.08333333333333333, 0.08125, 0.03787878787878788, 0.09375, 0.07575757575757576, 0.1], 'val_loss': [14.639370769535729, 14.639370935772536, 14.343625672366642, 14.787243020643881, 14.49149829094563, 14.49149829094563, 14.34362617982637, 14.639371189502402]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 63)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 3) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 3)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.29884910693699573, 'rotation_range': 15, 'optimizer': 'RMSProp', 'width_shift_range': 0.17805225703642188, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.09414238126027155, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:13:50.373243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 9s - loss: 12.1661 - acc: 0.0883 - val_loss: 2.5503 - val_acc: 0.1284
Epoch 2/2
 - 4s - loss: 2.9199 - acc: 0.1576 - val_loss: 2.1331 - val_acc: 0.1651
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 3), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 3)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.17805225703642188, 'base_model': 'MobileNet', 'zoom_range': 0.29884910693699573, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 15, 'height_shift_range': 0.09414238126027155, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8348623846375613, 'info': {'runtime': 18.493594646453857, 'histories': {'val_acc': [0.12844036731424682, 0.1651376153624386], 'loss': [11.824594210271966, 3.0017072011346686], 'acc': [0.0958904109589041, 0.17123287671232876], 'val_loss': [2.5503283312561313, 2.133138017916898]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 3)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 20) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.0016573244368102479, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:14:08.488041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/16
 - 10s - loss: 6.9310 - acc: 0.1438 - val_loss: 2.6489 - val_acc: 0.1468
Epoch 2/16
 - 4s - loss: 2.2394 - acc: 0.2396 - val_loss: 2.0403 - val_acc: 0.2752
Epoch 3/16
 - 5s - loss: 1.8429 - acc: 0.3341 - val_loss: 2.1034 - val_acc: 0.2018
Epoch 4/16
 - 4s - loss: 1.7703 - acc: 0.5191 - val_loss: 3.3448 - val_acc: 0.1468
Epoch 5/16
 - 5s - loss: 1.6139 - acc: 0.4791 - val_loss: 3.3677 - val_acc: 0.2018
Epoch 6/16
 - 5s - loss: 2.3895 - acc: 0.5019 - val_loss: 2.8171 - val_acc: 0.3578
Epoch 7/16
 - 5s - loss: 0.9669 - acc: 0.6625 - val_loss: 1.1521 - val_acc: 0.6422
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 8/16
 - 5s - loss: 1.7245 - acc: 0.6241 - val_loss: 1.4153 - val_acc: 0.5046
Epoch 9/16
 - 4s - loss: 0.6743 - acc: 0.8215 - val_loss: 0.9495 - val_acc: 0.6514
Epoch 10/16
 - 4s - loss: 0.9965 - acc: 0.6765 - val_loss: 2.3191 - val_acc: 0.5138
Epoch 11/16
 - 4s - loss: 0.6137 - acc: 0.8341 - val_loss: 5.0909 - val_acc: 0.3945
Epoch 12/16
 - 4s - loss: 1.9202 - acc: 0.7017 - val_loss: 1.3785 - val_acc: 0.6239
Epoch 13/16
 - 4s - loss: 0.2475 - acc: 0.9307 - val_loss: 1.6622 - val_acc: 0.6514
Epoch 14/16
 - 4s - loss: 2.0183 - acc: 0.7250 - val_loss: 4.3220 - val_acc: 0.4771
Epoch 15/16
 - 5s - loss: 0.9708 - acc: 0.7774 - val_loss: 2.4861 - val_acc: 0.5321
Epoch 16/16
 - 5s - loss: 0.3387 - acc: 0.8812 - val_loss: 2.0092 - val_acc: 0.6239
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 9)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0016573244368102479, 'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.3761467878971625, 'info': {'runtime': 83.70648384094238, 'histories': {'val_acc': [0.14678899116745783, 0.2752293586184125, 0.20183486429923173, 0.14678899082568808, 0.20183486375240012, 0.3577981689654359, 0.6422018386902065, 0.5045871592442924, 0.6513761544446333, 0.5137614717177295, 0.3944954142111157, 0.6238532148369955, 0.6513761555382965, 0.47706422455813907, 0.532110096117772, 0.6238532121028375], 'loss': [6.930999350547791, 2.1759361959483527, 1.7522305854379314, 1.7032154762383662, 1.5457465420030567, 2.5458159650841803, 0.9669178187847137, 1.6626106745576206, 0.5949668182085638, 0.988921096880142, 0.5124176218085092, 1.915070757473985, 0.2503859853907807, 2.006613662798111, 0.9517408106476068, 0.33872049348428845], 'acc': [0.14375, 0.2602739726027397, 0.363013698630137, 0.5227272727272727, 0.5205479452054794, 0.4589041095890411, 0.6625, 0.678082191780822, 0.8493150684931506, 0.6917808219178082, 0.863013698630137, 0.7191780821917808, 0.9246575342465754, 0.7876712328767124, 0.8013698630136986, 0.88125], 'val_loss': [2.6489051372633066, 2.040274635367437, 2.103410609271548, 3.344817448099819, 3.3677229159468904, 2.8171458834901864, 1.152067326624459, 1.4152634756280742, 0.9494518706011116, 2.3190863919914317, 5.090903422154418, 1.3785371299183697, 1.66221772202658, 4.322019100189209, 2.4861169014502007, 2.0091648714258037]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 20)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 20) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 19) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 20)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.08997505136600327, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:15:32.231758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/16
 - 9s - loss: 13.7389 - acc: 0.0693 - val_loss: 14.6233 - val_acc: 0.0917
Epoch 2/16
 - 5s - loss: 14.0010 - acc: 0.1313 - val_loss: 14.6377 - val_acc: 0.0917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/16
 - 4s - loss: 8.0258 - acc: 0.1162 - val_loss: 2.2538 - val_acc: 0.1651
Epoch 4/16
 - 5s - loss: 2.0528 - acc: 0.2459 - val_loss: 2.6666 - val_acc: 0.1376
Epoch 5/16
 - 5s - loss: 2.1807 - acc: 0.2687 - val_loss: 1.8301 - val_acc: 0.3761
Epoch 6/16
 - 4s - loss: 2.0305 - acc: 0.3185 - val_loss: 2.0881 - val_acc: 0.3578
Epoch 7/16
 - 4s - loss: 1.6057 - acc: 0.4413 - val_loss: 5.3580 - val_acc: 0.0917
Epoch 8/16
 - 4s - loss: 2.1167 - acc: 0.4602 - val_loss: 1.2015 - val_acc: 0.5688
Epoch 9/16
 - 5s - loss: 1.0478 - acc: 0.6625 - val_loss: 1.3068 - val_acc: 0.5596
Epoch 10/16
 - 4s - loss: 1.4707 - acc: 0.5233 - val_loss: 1.8575 - val_acc: 0.3945
Epoch 11/16
 - 5s - loss: 0.9635 - acc: 0.7226 - val_loss: 0.9605 - val_acc: 0.6147
Epoch 12/16
 - 5s - loss: 0.9938 - acc: 0.7313 - val_loss: 4.3912 - val_acc: 0.2110
Epoch 13/16
 - 5s - loss: 1.1187 - acc: 0.7080 - val_loss: 0.8614 - val_acc: 0.7064
Epoch 14/16
 - 4s - loss: 1.0832 - acc: 0.6241 - val_loss: 0.8667 - val_acc: 0.7156
Epoch 15/16
 - 5s - loss: 0.6064 - acc: 0.7688 - val_loss: 0.9554 - val_acc: 0.6239
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 16/16
 - 4s - loss: 1.6839 - acc: 0.6195 - val_loss: 0.7217 - val_acc: 0.7431
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 20), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 20) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 20)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08997505136600327, 'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.2568807251956484, 'info': {'runtime': 82.8347373008728, 'histories': {'val_acc': [0.09174312063313406, 0.0917431196078248, 0.1651376153624386, 0.13761467889908258, 0.3761467933654785, 0.3577981684186043, 0.0917431196078248, 0.5688073408166203, 0.5596330302570938, 0.39449541667185795, 0.6146789009964794, 0.21100917499546612, 0.7064220270979296, 0.7155963384777034, 0.6238532208521431, 0.7431192748043516], 'loss': [13.533267974853516, 14.001017570495605, 8.516356565735556, 2.0103765905719913, 2.1806723833084107, 1.829591079191728, 1.487109951777001, 2.0391277874985785, 1.0478011548519135, 1.3861077876940167, 0.9454912159540881, 0.7224037647247314, 1.1180730404919141, 0.9610983378266635, 0.6064407885074615, 1.3459199594728875], 'acc': [0.07534246575342465, 0.13125, 0.09090909090909091, 0.2671232876712329, 0.26875, 0.3787878787878788, 0.4794520547945205, 0.5, 0.6625, 0.5684931506849316, 0.6986301369863014, 0.7945205479452054, 0.726027397260274, 0.678082191780822, 0.76875, 0.6893939393939394], 'val_loss': [14.623275091888708, 14.6376625113531, 2.253814622896527, 2.666633013191573, 1.8301410882844837, 2.088094658807877, 5.358019820047081, 1.2015496131477006, 1.3067877423872643, 1.8575224285825678, 0.9605173474058099, 4.3911866879244466, 0.8614441090767536, 0.8667102975582858, 0.9553591669152636, 0.72173025629936]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 20)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 19)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 19) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 49) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 19)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.19956006504962495, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.18472340643110186, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08962149295842833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:16:55.533444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/16
 - 8s - loss: 13.8006 - acc: 0.0630 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/16
 - 4s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 3/16
 - 4s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 4/16
 - 4s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 5/16
 - 5s - loss: 14.6070 - acc: 0.0938 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 6/16
 - 4s - loss: 14.5779 - acc: 0.0956 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 7/16
 - 5s - loss: 14.3048 - acc: 0.1125 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 8/16
 - 4s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 9/16
 - 4s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 10/16
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 11/16
 - 4s - loss: 13.9528 - acc: 0.1343 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 12/16
 - 4s - loss: 14.3593 - acc: 0.1091 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 13/16
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 14/16
 - 4s - loss: 13.8512 - acc: 0.1406 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 15/16
 - 5s - loss: 14.2041 - acc: 0.1187 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 16/16
 - 4s - loss: 14.8859 - acc: 0.0764 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 19), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 19) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 19)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.18472340643110186, 'base_model': 'MobileNet', 'zoom_range': 0.19956006504962495, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.08962149295842833, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339449541285, 'info': {'runtime': 78.19425106048584, 'histories': {'val_acc': [0.0825688076812193, 0.09174311926605505, 0.07339449575461379, 0.09174311994959455, 0.06422018348623854, 0.08256880802298905, 0.0825688076812193, 0.10091743153443031, 0.07339449609638354, 0.07339449541284404, 0.10091743153443031, 0.06422018382800829, 0.0917431196078248, 0.07339449609638354, 0.09174311926605505, 0.11926605504587157], 'loss': [13.600376625583596, 14.572524397340539, 14.351728778995879, 14.572524345084412, 14.607024002075196, 14.286493474786932, 14.304809665679931, 14.903718086138163, 14.793320120197453, 14.682922467793503, 14.462126692680464, 14.903718347418797, 14.682922467793503, 14.351728517715244, 14.204071617126464, 14.652813766941879], 'acc': [0.0684931506849315, 0.0958904109589041, 0.1095890410958904, 0.0958904109589041, 0.09375, 0.11363636363636363, 0.1125, 0.07534246575342465, 0.0821917808219178, 0.08904109589041095, 0.10273972602739725, 0.07534246575342465, 0.08904109589041095, 0.1095890410958904, 0.11875, 0.09090909090909091], 'val_loss': [14.787242994395966, 14.639371189502402, 14.935115665470788, 14.639370682042673, 15.082987864083107, 14.787243300621663, 14.787243274373745, 14.491498544675494, 14.935115411740924, 14.935115919200653, 14.491498264697714, 15.082988170308804, 14.63937104951351, 14.935115411740924, 14.639370629546839, 14.195753954966134]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 19)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 49)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 49) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 49) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 4) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 49)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.011777038546923035, 'rotation_range': 16, 'optimizer': 'RMSProp', 'width_shift_range': 0.11205385960091242, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.25550630720707174, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:18:13.342687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/16
 - 8s - loss: 13.3262 - acc: 0.1741 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 2/16
 - 5s - loss: 14.6070 - acc: 0.0938 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 3/16
 - 4s - loss: 14.7832 - acc: 0.0828 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 4/16
 - 5s - loss: 14.0026 - acc: 0.1313 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 5/16
 - 4s - loss: 14.5625 - acc: 0.0965 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 6/16
 - 4s - loss: 14.8859 - acc: 0.0764 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 7/16
 - 5s - loss: 14.8085 - acc: 0.0813 - val_loss: 15.0830 - val_acc: 0.0642
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 8/16
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 9/16
 - 4s - loss: 15.0913 - acc: 0.0637 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 10/16
 - 5s - loss: 14.6070 - acc: 0.0938 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 11/16
 - 4s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 12/16
 - 4s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 13/16
 - 4s - loss: 14.1560 - acc: 0.1217 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 14/16
 - 4s - loss: 15.0003 - acc: 0.0693 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 15/16
 - 4s - loss: 15.1019 - acc: 0.0630 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 16/16
 - 4s - loss: 14.5625 - acc: 0.0965 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 49), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 49) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 49) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 49)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11205385960091242, 'base_model': 'MobileNet', 'zoom_range': 0.011777038546923035, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 16, 'height_shift_range': 0.25550630720707174, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339449541285, 'info': {'runtime': 80.68321347236633, 'histories': {'val_acc': [0.0917431196078248, 0.0825688076812193, 0.11009174380280556, 0.10091743153443031, 0.0917431196078248, 0.11009174380280556, 0.06422018416977804, 0.08256880733944955, 0.11926605572941107, 0.08256880802298905, 0.11009174311926606, 0.0825688076812193, 0.08256880802298905, 0.06422018382800829, 0.07339449575461379, 0.11926605504587157], 'loss': [14.31698307272506, 14.607023906707763, 14.530707157019412, 14.0025954246521, 15.124514070275712, 14.652813998135654, 14.808499908447265, 14.68292236328125, 14.897027449174361, 14.607023906707763, 14.572524449596667, 14.572524345084412, 14.682922311025123, 14.90371829516267, 15.014115947566621, 15.124513861251204], 'acc': [0.10273972602739725, 0.09375, 0.09848484848484848, 0.13125, 0.06164383561643835, 0.09090909090909091, 0.08125, 0.08904109589041095, 0.07575757575757576, 0.09375, 0.0958904109589041, 0.0958904109589041, 0.08904109589041095, 0.07534246575342465, 0.0684931506849315, 0.06164383561643835], 'val_loss': [14.639370769535729, 14.787242994395966, 14.343626346063177, 14.491498430934522, 14.63937104951351, 14.343626066085395, 15.082988030319914, 14.787243134384855, 14.195753561247379, 14.787243580599444, 14.34362617982637, 14.787243274373745, 14.787243300621663, 15.082988004071996, 14.935115779211761, 14.195753954966134]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 49)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 4)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 4) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 4) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 4) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 4)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.08291454464288155, 'rotation_range': 21, 'optimizer': 'RMSProp', 'width_shift_range': 0.13083369324255772, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21435321170714566, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:19:34.081185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 9s - loss: 13.7109 - acc: 0.0693 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/2
 - 4s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 4), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 4) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 4) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 4)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.13083369324255772, 'base_model': 'MobileNet', 'zoom_range': 0.08291454464288155, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 21, 'height_shift_range': 0.21435321170714566, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825674402605, 'info': {'runtime': 19.102471828460693, 'histories': {'val_acc': [0.10091743153443031, 0.10091743255973956], 'loss': [13.502924618655689, 14.57252455410892], 'acc': [0.07534246575342465, 0.0958904109589041], 'val_loss': [14.491498710912301, 14.491498343441464]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 4)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 20) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 9)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.0016573244368102479, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:19:53.660650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/20
 - 9s - loss: 12.2552 - acc: 0.1406 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/20
 - 4s - loss: 13.8512 - acc: 0.1406 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 3/20
 - 4s - loss: 14.2890 - acc: 0.1135 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 4/20
 - 5s - loss: 14.1033 - acc: 0.1250 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 5/20
 - 4s - loss: 13.9842 - acc: 0.1324 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 6/20
 - 4s - loss: 14.5779 - acc: 0.0956 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 7/20
 - 5s - loss: 14.4055 - acc: 0.1062 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 8/20
 - 4s - loss: 13.7496 - acc: 0.1469 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 9/20
 - 4s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 10/20
 - 5s - loss: 14.3906 - acc: 0.1072 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 11/20
 - 5s - loss: 14.2890 - acc: 0.1135 - val_loss: 14.0479 - val_acc: 0.1284
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 12/20
 - 5s - loss: 13.9842 - acc: 0.1324 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 13/20
 - 5s - loss: 14.1874 - acc: 0.1198 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 14/20
 - 5s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 15/20
 - 5s - loss: 14.3048 - acc: 0.1125 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 16/20
 - 5s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 17/20
 - 5s - loss: 14.1874 - acc: 0.1198 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 18/20
 - 5s - loss: 14.3906 - acc: 0.1072 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 19/20
 - 5s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 20/20
 - 4s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.0479 - val_acc: 0.1284
{'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.0016573244368102479, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}

 ****** MobileNet unfrozen 2 top blocks, cut_off after layer 75 ******
Epoch 1/12
 - 8s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 2/12
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.0479 - val_acc: 0.1284
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/12
 - 5s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 4/12
 - 5s - loss: 14.2890 - acc: 0.1135 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 5/12
 - 5s - loss: 13.9019 - acc: 0.1375 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 6/12
 - 4s - loss: 14.6806 - acc: 0.0892 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 7/12
 - 5s - loss: 14.5063 - acc: 0.1000 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 8/12
 - 4s - loss: 14.2576 - acc: 0.1154 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 9/12
 - 4s - loss: 14.5779 - acc: 0.0956 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 10/12
 - 5s - loss: 14.2041 - acc: 0.1187 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 11/12
 - 5s - loss: 13.9528 - acc: 0.1343 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 12/12
 - 5s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 9)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0016573244368102479, 'base_model': 'MobileNet', 'zoom_range': 0.01721281438255071, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.12074575071866528, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082561971945, 'info': {'runtime': 168.13918447494507, 'histories': {'val_acc': [0.10091743187620006, 0.10091743153443031, 0.12844036765601657, 0.11926605695978217, 0.12844036888638768, 0.1467889927395987, 0.12844036833955608, 0.10091743119266056, 0.12844036765601657, 0.11926605572941107, 0.12844036765601657, 0.13761467924085233, 0.11926605695978217, 0.12844036765601657, 0.12844036731424682, 0.11926605572941107, 0.11926605572941107, 0.0917431196078248, 0.10091743187620006, 0.12844036697247707, 0.12844036765601657, 0.12844036765601657, 0.12844036888638768, 0.14678899116745783, 0.13761468026616158, 0.12844036833955608, 0.13761467958262208, 0.08256880802298905, 0.09174311926605505, 0.14678899082568808, 0.11926605572941107, 0.11009174380280556], 'loss': [12.614546815009966, 14.351728726739752, 14.130933056138966, 14.103333473205566, 13.799739262829089, 14.286493705980705, 14.405547714233398, 14.241330969823549, 14.351728674483626, 14.241330917567423, 14.130932742602205, 13.799739053804581, 14.020534881173749, 14.351728778995879, 14.304809665679931, 14.903718190650418, 14.020535090198255, 14.241330708542915, 14.572524345084412, 14.462126640424337, 14.351728674483626, 14.682922258768997, 14.462126535912082, 14.130933056138966, 13.901857376098633, 14.408600315903172, 14.506285762786865, 14.793320276965833, 14.286493590383818, 14.204071426391602, 14.462126588168209, 14.57252455410892], 'acc': [0.1095890410958904, 0.1095890410958904, 0.1232876712328767, 0.125, 0.14383561643835616, 0.11363636363636363, 0.10625, 0.11643835616438356, 0.1095890410958904, 0.11643835616438356, 0.1232876712328767, 0.14383561643835616, 0.13013698630136986, 0.1095890410958904, 0.1125, 0.07534246575342465, 0.13013698630136986, 0.11643835616438356, 0.0958904109589041, 0.10273972602739725, 0.1095890410958904, 0.08904109589041095, 0.10273972602739725, 0.1232876712328767, 0.1375, 0.10606060606060606, 0.1, 0.0821917808219178, 0.11363636363636363, 0.11875, 0.10273972602739725, 0.0958904109589041], 'val_loss': [14.491498570923412, 14.491498430934522, 14.04788122264617, 14.195753867473078, 14.047880802679499, 13.75213635295903, 14.04788122264617, 14.491498404686604, 14.047881336387144, 14.195753561247379, 14.047881336387144, 13.90000897153802, 14.195753867473078, 14.047881336387144, 14.047880916420473, 14.195753561247379, 14.195753561247379, 14.639370935772536, 14.491498457182438, 14.047881170150337, 14.047881336387144, 14.047881056409363, 14.04788108265728, 13.752136466700003, 13.900008717808154, 14.04788122264617, 13.900008551571347, 14.787243300621663, 14.63937090952462, 13.752136720429867, 14.195753561247379, 14.343625952344421]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 20)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 20) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 5) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 20)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.08997505136600327, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:22:41.823123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/20
 - 10s - loss: 8.1325 - acc: 0.1533 - val_loss: 2.2818 - val_acc: 0.1193
Epoch 2/20
 - 5s - loss: 2.4105 - acc: 0.1135 - val_loss: 1.9596 - val_acc: 0.3853
Epoch 3/20
 - 5s - loss: 1.9411 - acc: 0.3676 - val_loss: 1.7401 - val_acc: 0.4771
Epoch 4/20
 - 5s - loss: 1.8145 - acc: 0.4515 - val_loss: 1.7145 - val_acc: 0.3486
Epoch 5/20
 - 4s - loss: 1.5957 - acc: 0.4728 - val_loss: 1.5223 - val_acc: 0.4495
Epoch 6/20
 - 4s - loss: 1.3073 - acc: 0.5359 - val_loss: 2.2595 - val_acc: 0.2844
Epoch 7/20
 - 5s - loss: 2.3122 - acc: 0.4578 - val_loss: 2.0077 - val_acc: 0.4679
Epoch 8/20
 - 7s - loss: 0.9828 - acc: 0.7125 - val_loss: 1.3828 - val_acc: 0.5413
Epoch 9/20
 - 5s - loss: 1.4122 - acc: 0.5548 - val_loss: 1.2500 - val_acc: 0.6055
Epoch 10/20
 - 5s - loss: 0.7459 - acc: 0.7856 - val_loss: 1.4419 - val_acc: 0.5963
Epoch 11/20
 - 4s - loss: 1.8690 - acc: 0.5946 - val_loss: 0.9957 - val_acc: 0.6514
Epoch 12/20
 - 4s - loss: 0.6216 - acc: 0.7730 - val_loss: 2.1085 - val_acc: 0.6055
Epoch 13/20
 - 5s - loss: 1.1165 - acc: 0.6557 - val_loss: 0.9038 - val_acc: 0.7248
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 14/20
 - 4s - loss: 0.9308 - acc: 0.7207 - val_loss: 1.7666 - val_acc: 0.5872
Epoch 15/20
 - 4s - loss: 1.0954 - acc: 0.7270 - val_loss: 1.8866 - val_acc: 0.6055
Epoch 16/20
 - 4s - loss: 1.0879 - acc: 0.7061 - val_loss: 1.2208 - val_acc: 0.6422
Epoch 17/20
 - 5s - loss: 0.2840 - acc: 0.9187 - val_loss: 2.6518 - val_acc: 0.6330
Epoch 18/20
 - 4s - loss: 0.5256 - acc: 0.8487 - val_loss: 1.9520 - val_acc: 0.5963
Epoch 19/20
 - 4s - loss: 0.7760 - acc: 0.8392 - val_loss: 2.8268 - val_acc: 0.3853
Epoch 20/20
 - 5s - loss: 1.4034 - acc: 0.6746 - val_loss: 1.8040 - val_acc: 0.5963
{'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.08997505136600327, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}

 ****** MobileNet unfrozen 2 top blocks, cut_off after layer 75 ******
Epoch 1/12
 - 8s - loss: 0.5152 - acc: 0.8070 - val_loss: 1.6412 - val_acc: 0.5963
Epoch 2/12
 - 5s - loss: 0.2903 - acc: 0.9125 - val_loss: 1.3943 - val_acc: 0.6330
Epoch 3/12
 - 4s - loss: 0.4734 - acc: 0.8657 - val_loss: 1.6284 - val_acc: 0.5688
Epoch 4/12
 - 4s - loss: 0.7783 - acc: 0.7326 - val_loss: 1.3120 - val_acc: 0.6239
Epoch 5/12
 - 4s - loss: 0.4218 - acc: 0.8700 - val_loss: 1.3303 - val_acc: 0.6239
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 6/12
 - 5s - loss: 0.3230 - acc: 0.9062 - val_loss: 1.2663 - val_acc: 0.6330
Epoch 7/12
 - 5s - loss: 0.3461 - acc: 0.8846 - val_loss: 1.3822 - val_acc: 0.6330
Epoch 8/12
 - 5s - loss: 0.3484 - acc: 0.8763 - val_loss: 1.1654 - val_acc: 0.6789
Epoch 9/12
 - 5s - loss: 0.3215 - acc: 0.9307 - val_loss: 1.2718 - val_acc: 0.6330
Epoch 10/12
 - 5s - loss: 0.3886 - acc: 0.9098 - val_loss: 1.3130 - val_acc: 0.6239
Epoch 11/12
 - 4s - loss: 0.3828 - acc: 0.9035 - val_loss: 1.1353 - val_acc: 0.6789
Epoch 12/12
 - 5s - loss: 0.2405 - acc: 0.9375 - val_loss: 1.1297 - val_acc: 0.6881
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 20), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 20) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 20)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08997505136600327, 'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.3119266044109239, 'info': {'runtime': 165.58832216262817, 'histories': {'val_acc': [0.11926605538764132, 0.38532110474525244, 0.4770642289327919, 0.3486238545780882, 0.449541288231491, 0.28440367163868124, 0.46788991208470193, 0.5412844058570512, 0.6055045879762108, 0.5963302779635158, 0.6513761489763172, 0.6055045893432898, 0.7247706443891613, 0.5871559671305735, 0.605504595905269, 0.6422018370497118, 0.6330275251231062, 0.5963302774166842, 0.385321105292084, 0.5963302785103474, 0.5963302785103474, 0.6330275273104327, 0.5688073492925102, 0.6238532137433324, 0.6238532131965008, 0.6330275262167694, 0.6330275316850855, 0.678899091318113, 0.6330275256699378, 0.6238532137433324, 0.678899085849797, 0.6880733955890761], 'loss': [8.635473976396534, 2.389091566817401, 1.8838347735470289, 1.896399155871509, 1.4225328719779238, 1.1373271615537879, 2.4109068553741664, 0.9828355193138123, 1.2915984539136494, 0.8054670216388082, 1.9718557506391448, 0.6687803173514262, 1.01767216643242, 0.7650367625772136, 0.9885580637683608, 0.9265271114976439, 0.2840445838868618, 0.5613196602422897, 0.6988124078647657, 1.2941730308206114, 0.36782574490325093, 0.29026575163006785, 0.3583032113232025, 0.36470567322138586, 0.23249922304937284, 0.32297657132148744, 0.2573210699101017, 0.1844359040260315, 0.3087011934959725, 0.21724047889448192, 0.21978534441696454, 0.24048415618017316], 'acc': [0.1232876712328767, 0.1232876712328767, 0.3561643835616438, 0.4041095890410959, 0.5136986301369864, 0.5821917808219178, 0.410958904109589, 0.7125, 0.6027397260273972, 0.7671232876712328, 0.6027397260273972, 0.7534246575342466, 0.7123287671232876, 0.7397260273972602, 0.7465753424657534, 0.7671232876712328, 0.91875, 0.8356164383561644, 0.8560606060606061, 0.7328767123287672, 0.8767123287671232, 0.9125, 0.8972602739726028, 0.8712121212121212, 0.9452054794520548, 0.90625, 0.9178082191780822, 0.952054794520548, 0.9246575342465754, 0.9452054794520548, 0.9383561643835616, 0.9375], 'val_loss': [2.2818151657734442, 1.959563971659459, 1.7400772320021183, 1.714502754561398, 1.5223318447760485, 2.2594789015043766, 2.007673370728799, 1.3827899924112022, 1.2500323396210278, 1.4419317540772465, 0.9957246846015301, 2.1084764922430757, 0.9038219692510202, 1.7666051923681836, 1.886609678968377, 1.2208277435477721, 2.651805984864541, 1.952035370223019, 2.8268018556297374, 1.8039845720343632, 1.6412490726610935, 1.394283441228604, 1.628379807559722, 1.3120001324819863, 1.3303462485654638, 1.2663353178479255, 1.3822286949245208, 1.165368174194196, 1.2717515306735256, 1.313033421105201, 1.1352731809703582, 1.1296926272024803]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 20)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 5)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 5) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 0
DEBUG:hpbandster:HBMASTER: submitting job (0, 0, 20) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 5) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 5) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 5)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.22742362785509346, 'rotation_range': 11, 'optimizer': 'RMSProp', 'width_shift_range': 0.126446972001761, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.18079685339259402, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:25:27.481365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 9s - loss: 13.5769 - acc: 0.0757 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 2/2
 - 4s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 5), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 5) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 5) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 5) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 5)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.126446972001761, 'base_model': 'MobileNet', 'zoom_range': 0.22742362785509346, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 11, 'height_shift_range': 0.18079685339259402, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568800504054, 'info': {'runtime': 18.38173818588257, 'histories': {'val_acc': [0.0917431196078248, 0.09174311994959455], 'loss': [14.517269777925048, 14.572524345084412], 'acc': [0.0821917808219178, 0.0958904109589041], 'val_loss': [14.63937104951351, 14.639370795783647]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 5)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: trying to submit job (0, 0, 20)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (0, 0, 20) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 6) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (0, 0, 20)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.08997505136600327, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:25:45.496595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/20
 - 8s - loss: 13.3377 - acc: 0.0883 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/20
 - 4s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 3/20
 - 5s - loss: 14.8085 - acc: 0.0813 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 4/20
 - 5s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 5/20
 - 4s - loss: 15.1019 - acc: 0.0630 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 6/20
 - 5s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 7/20
 - 5s - loss: 14.3906 - acc: 0.1072 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 8/20
 - 5s - loss: 15.1019 - acc: 0.0630 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 9/20
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 10/20
 - 6s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 11/20
 - 4s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 12/20
 - 5s - loss: 14.7078 - acc: 0.0875 - val_loss: 14.9351 - val_acc: 0.0734
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 13/20
 - 4s - loss: 14.9886 - acc: 0.0701 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 14/20
 - 6s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 15/20
 - 5s - loss: 14.8085 - acc: 0.0813 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 16/20
 - 4s - loss: 15.1940 - acc: 0.0573 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 17/20
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 18/20
 - 5s - loss: 15.1107 - acc: 0.0625 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 19/20
 - 4s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 20/20
 - 5s - loss: 15.2035 - acc: 0.0567 - val_loss: 14.6394 - val_acc: 0.0917
{'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.08997505136600327, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}

 ****** MobileNet unfrozen 2 top blocks, cut_off after layer 75 ******
Epoch 1/44
 - 8s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/44
 - 5s - loss: 15.3052 - acc: 0.0504 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 3/44
 - 4s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 4/44
 - 5s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 5/44
 - 4s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 6/44
 - 5s - loss: 14.4055 - acc: 0.1062 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 7/44
 - 4s - loss: 15.1019 - acc: 0.0630 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 8/44
 - 4s - loss: 15.2035 - acc: 0.0567 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 9/44
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 10/44
 - 5s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 11/44
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 12/44
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 13/44
 - 5s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 14/44
 - 6s - loss: 14.8085 - acc: 0.0813 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 15/44
 - 5s - loss: 15.0913 - acc: 0.0637 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 16/44
 - 5s - loss: 14.8085 - acc: 0.0813 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 17/44
 - 5s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 18/44
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 19/44
 - 4s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 20/44
 - 5s - loss: 14.2576 - acc: 0.1154 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 21/44
 - 5s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 22/44
 - 5s - loss: 14.8987 - acc: 0.0757 - val_loss: 15.2309 - val_acc: 0.0550
Epoch 23/44
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 24/44
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 25/44
 - 5s - loss: 13.5463 - acc: 0.1596 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 26/44
 - 6s - loss: 15.1019 - acc: 0.0630 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 27/44
 - 6s - loss: 13.9528 - acc: 0.1343 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 28/44
 - 5s - loss: 15.1019 - acc: 0.0630 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 29/44
 - 5s - loss: 14.7078 - acc: 0.0875 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 30/44
 - 5s - loss: 14.3906 - acc: 0.1072 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 31/44
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 32/44
 - 6s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 33/44
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 34/44
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 35/44
 - 6s - loss: 14.4609 - acc: 0.1028 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 36/44
 - 5s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 37/44
 - 5s - loss: 14.8085 - acc: 0.0813 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 38/44
 - 4s - loss: 14.7832 - acc: 0.0828 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 39/44
 - 5s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 40/44
 - 5s - loss: 14.6070 - acc: 0.0938 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 41/44
 - 5s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 42/44
 - 7s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 43/44
 - 7s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 44/44
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (0, 0, 20), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (0, 0, 20) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (0, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (0, 0, 20)
args: ()
kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08997505136600327, 'base_model': 'MobileNet', 'zoom_range': 0.24167782556010792, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.030694318674259757, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082568807339, 'info': {'runtime': 329.8606297969818, 'histories': {'val_acc': [0.08256880925336016, 0.10091743119266056, 0.10091743153443031, 0.0917431196078248, 0.08256880733944955, 0.09174311926605505, 0.0917431196078248, 0.06422018348623854, 0.0917431196078248, 0.09174311926605505, 0.0825688076812193, 0.07339449609638354, 0.10091743153443031, 0.07339449609638354, 0.10091743153443031, 0.0917431196078248, 0.10091743153443031, 0.08256880733944955, 0.08256880733944955, 0.0917431196078248, 0.0825688076812193, 0.06422018348623854, 0.10091743153443031, 0.10091743119266056, 0.09174311926605505, 0.0917431196078248, 0.11926605572941107, 0.09174311926605505, 0.0825688076812193, 0.07339449541284404, 0.10091743153443031, 0.08256880733944955, 0.09174311926605505, 0.07339449732675465, 0.11009174503317666, 0.07339449541284404, 0.09174311926605505, 0.09174312063313406, 0.07339449575461379, 0.10091743556731338, 0.0917431196078248, 0.05504587155963303, 0.0917431196078248, 0.08256880802298905, 0.0917431196078248, 0.10091743119266056, 0.0917431196078248, 0.0825688076812193, 0.11009174448634507, 0.08256880802298905, 0.10091743153443031, 0.11009174380280556, 0.08256880733944955, 0.07339449575461379, 0.07339449609638354, 0.09174311926605505, 0.06422018348623854, 0.11009174380280556, 0.09174311926605505, 0.09174311994959455, 0.08256880802298905, 0.08256880802298905, 0.0917431196078248, 0.11009174311926606], 'loss': [14.287603711428707, 14.90371829516267, 14.80850009918213, 14.462126640424337, 15.014115947566621, 14.793320433734214, 14.241330708542915, 15.014116052078874, 14.68292236328125, 14.793320329221961, 14.572524606365047, 14.707762050628663, 14.774920723655008, 14.572524449596667, 14.808500194549561, 15.019134290290602, 14.682922258768997, 15.110714340209961, 14.793320329221961, 15.124514018019585, 14.462126640424337, 15.234911983960295, 14.903718190650418, 14.793320329221961, 14.572524397340539, 14.405547523498536, 15.014116156591127, 15.124514122531838, 14.572524606365047, 14.462126535912082, 14.682922258768997, 14.572524397340539, 14.572524449596667, 14.808500003814697, 14.897027449174361, 14.808500003814697, 14.46212674493659, 14.682922467793503, 14.351728674483626, 14.793320381478088, 14.462126640424337, 14.793320433734214, 14.572524710877302, 14.682922467793503, 14.020534933429875, 15.014116052078874, 14.462126692680464, 15.014116052078874, 14.707762050628663, 14.241330708542915, 14.572524501852794, 14.903718190650418, 14.572524710877302, 14.682922676818011, 15.014116208847256, 14.46212674493659, 14.808500003814697, 14.530707157019412, 14.903718190650418, 14.607023906707763, 14.793320329221961, 14.462126535912082, 14.793320329221961, 14.68292236328125], 'acc': [0.0958904109589041, 0.07534246575342465, 0.08125, 0.10273972602739725, 0.0684931506849315, 0.0821917808219178, 0.11643835616438356, 0.0684931506849315, 0.08904109589041095, 0.0821917808219178, 0.0958904109589041, 0.0875, 0.08333333333333333, 0.0958904109589041, 0.08125, 0.06818181818181818, 0.08904109589041095, 0.0625, 0.0821917808219178, 0.06164383561643835, 0.10273972602739725, 0.0547945205479452, 0.07534246575342465, 0.0821917808219178, 0.0958904109589041, 0.10625, 0.0684931506849315, 0.06164383561643835, 0.0958904109589041, 0.10273972602739725, 0.08904109589041095, 0.0958904109589041, 0.0958904109589041, 0.08125, 0.07575757575757576, 0.08125, 0.10273972602739725, 0.08904109589041095, 0.1095890410958904, 0.0821917808219178, 0.10273972602739725, 0.0821917808219178, 0.0958904109589041, 0.08904109589041095, 0.13013698630136986, 0.0684931506849315, 0.10273972602739725, 0.0684931506849315, 0.0875, 0.11643835616438356, 0.0958904109589041, 0.07534246575342465, 0.0958904109589041, 0.08904109589041095, 0.0684931506849315, 0.10273972602739725, 0.08125, 0.09848484848484848, 0.07534246575342465, 0.09375, 0.0821917808219178, 0.10273972602739725, 0.0821917808219178, 0.08904109589041095], 'val_loss': [14.78724332686958, 14.491498684664386, 14.491498430934522, 14.639370769535729, 14.787243694340416, 14.639371189502402, 14.63937104951351, 15.082987864083107, 14.639370655794757, 14.63937090952462, 14.787243274373745, 14.935115525481898, 14.49149815095674, 14.935115805459679, 14.491498430934522, 14.639370935772536, 14.491498544675494, 14.787243134384855, 14.787243134384855, 14.639370769535729, 14.787243274373745, 15.082988144060888, 14.491498544675494, 14.491498684664386, 14.63937090952462, 14.639370769535729, 14.195753727484187, 14.639370629546839, 14.787243554351527, 14.93511535924509, 14.49149815095674, 14.787243414362637, 14.639370629546839, 14.935115551729815, 14.343626092333313, 14.935115639222872, 14.63937090952462, 14.639370682042673, 14.935115385493008, 14.491498483430355, 14.639370769535729, 15.230860368921123, 14.63937104951351, 14.787243186880689, 14.639370769535729, 14.491498684664386, 14.63937104951351, 14.787242994395966, 14.343626232322203, 14.787242906902907, 14.491498544675494, 14.343626346063177, 14.787243134384855, 14.935115665470788, 14.935115525481898, 14.63937090952462, 15.082988144060888, 14.343626232322203, 14.63937090952462, 14.639371075761428, 14.787243186880689, 14.787243020643881, 14.63937104951351, 14.34362617982637]}}}
exception: None

DEBUG:hpbandster:job_callback for (0, 0, 20)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 6)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 6) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 6) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 6) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 6)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.027576520032396277, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.13471264429449517, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2592858319648443, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:31:15.413750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 12s - loss: 12.5620 - acc: 0.1406 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/2
 - 6s - loss: 15.0100 - acc: 0.0687 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 6), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 6) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 6) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 6) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 6)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.13471264429449517, 'base_model': 'MobileNet', 'zoom_range': 0.027576520032396277, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.2592858319648443, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825684655697, 'info': {'runtime': 23.96252751350403, 'histories': {'val_acc': [0.11009174503317666, 0.10091743153443031], 'loss': [12.951124256604338, 15.00997610092163], 'acc': [0.1095890410958904, 0.06875], 'val_loss': [14.343625812355532, 14.491498264697714]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 6)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 7)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 8) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 7)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06067962302679979, 'rotation_range': 3, 'optimizer': 'RMSProp', 'width_shift_range': 0.020479886604250652, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.15272492403502907, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:31:39.888021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 11s - loss: 12.0633 - acc: 0.1596 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 2/2
 - 4s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 7), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 7)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.020479886604250652, 'base_model': 'MobileNet', 'zoom_range': 0.06067962302679979, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 3, 'height_shift_range': 0.15272492403502907, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825684655697, 'info': {'runtime': 24.70736074447632, 'histories': {'val_acc': [0.0917431196078248, 0.10091743153443031], 'loss': [12.409335253989859, 14.572524501852794], 'acc': [0.13013698630136986, 0.0958904109589041], 'val_loss': [14.639370935772536, 14.491498544675494]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 7)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 8)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 8) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 8) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 8) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 8)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.03218849010970149, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.28683502552581397, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2315598959393055, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:32:04.173514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 11s - loss: 13.5053 - acc: 0.0820 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 2/2
 - 5s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 8), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 8) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 8) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 8) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 8)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.28683502552581397, 'base_model': 'MobileNet', 'zoom_range': 0.03218849010970149, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.2315598959393055, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568800504054, 'info': {'runtime': 22.526917695999146, 'histories': {'val_acc': [0.06422018348623854, 0.09174311994959455], 'loss': [13.27954545739579, 14.793320329221961], 'acc': [0.08904109589041095, 0.0821917808219178], 'val_loss': [15.082987864083107, 14.639370795783647]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 8)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 10) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.10340454376382442, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.20524188789474698, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1140943526997985, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:32:27.198907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 15s - loss: 12.5703 - acc: 0.1250 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 2/2
 - 4s - loss: 14.4752 - acc: 0.1019 - val_loss: 13.7521 - val_acc: 0.1468
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 9)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.20524188789474698, 'base_model': 'MobileNet', 'zoom_range': 0.10340454376382442, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.1140943526997985, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8532110078072329, 'info': {'runtime': 26.934533834457397, 'histories': {'val_acc': [0.12844036731424682, 0.1467889921927671], 'loss': [12.570343732833862, 14.164386749267578], 'acc': [0.125, 0.12121212121212122], 'val_loss': [14.047881196398254, 13.752136492947919]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 10)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 10) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 10) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 11) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 10) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 10)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1436815210618747, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.21104483246046915, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.05256752553004263, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:32:54.123410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 11s - loss: 6.0361 - acc: 0.0946 - val_loss: 2.0963 - val_acc: 0.2385
Epoch 2/2
 - 5s - loss: 2.0414 - acc: 0.2437 - val_loss: 2.2068 - val_acc: 0.2844
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 10), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 10) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 10) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 10) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 10)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21104483246046915, 'base_model': 'MobileNet', 'zoom_range': 0.1436815210618747, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.05256752553004263, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.7155963299334596, 'info': {'runtime': 25.228010892868042, 'histories': {'val_acc': [0.23853211200565372, 0.2844036700665404], 'loss': [5.386613179559577, 2.0413999795913695], 'acc': [0.10273972602739725, 0.24375], 'val_loss': [2.0963301527390787, 2.2067928576688156]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 10)
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 11)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 11) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 12) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 11) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 11) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 11)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.28858608951159775, 'rotation_range': 21, 'optimizer': 'RMSProp', 'width_shift_range': 0.09823159527922372, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.046826075169878266, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:33:18.994450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 12s - loss: 13.8021 - acc: 0.0567 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/2
 - 5s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 11), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 11) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 11) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 11) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 11)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.09823159527922372, 'base_model': 'MobileNet', 'zoom_range': 0.28858608951159775, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 21, 'height_shift_range': 0.046826075169878266, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825688073394, 'info': {'runtime': 22.2918438911438, 'histories': {'val_acc': [0.11009174380280556, 0.10091743119266056], 'loss': [13.601950553998556, 14.90371829516267], 'acc': [0.06164383561643835, 0.07534246575342465], 'val_loss': [14.343625672366642, 14.491498404686604]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 11)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 12)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 12) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 13) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 12)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0407398762639929, 'rotation_range': 13, 'optimizer': 'RMSProp', 'width_shift_range': 0.1984552572785443, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.24526274023440595, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:33:41.791209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 11s - loss: 13.0771 - acc: 0.1009 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 2/2
 - 5s - loss: 14.0858 - acc: 0.1261 - val_loss: 13.7521 - val_acc: 0.1468
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 12), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 12) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 12)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1984552572785443, 'base_model': 'MobileNet', 'zoom_range': 0.0407398762639929, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 13, 'height_shift_range': 0.24526274023440595, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8532110088325422, 'info': {'runtime': 23.421421766281128, 'histories': {'val_acc': [0.14678899116745783, 0.14678899116745783], 'loss': [12.814254734614124, 13.910137124257545], 'acc': [0.1095890410958904, 0.136986301369863], 'val_loss': [13.752136746677783, 13.752137140396538]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 12)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 13)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 13) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 13) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 14) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 13) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 13)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.08330127437034963, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.13242785893202821, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1537484767805632, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:34:05.187113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 10s - loss: 12.9164 - acc: 0.1028 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/2
 - 4s - loss: 14.2576 - acc: 0.1154 - val_loss: 15.0830 - val_acc: 0.0642
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 13), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 13) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 13) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 13) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 13)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.13242785893202821, 'base_model': 'MobileNet', 'zoom_range': 0.08330127437034963, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.1537484767805632, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9357798165137614, 'info': {'runtime': 21.445480346679688, 'histories': {'val_acc': [0.08256880802298905, 0.06422018348623854], 'loss': [13.336178871050272, 14.79332048599034], 'acc': [0.0684931506849315, 0.0821917808219178], 'val_loss': [14.787243300621663, 15.082987864083107]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 13)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 14)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 14) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 15) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 14)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.054949645659345354, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.26716847752572814, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2796118284202028, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:34:26.271117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 16s - loss: 13.0436 - acc: 0.0946 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 2/2
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 14), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 14) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 14)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.26716847752572814, 'base_model': 'MobileNet', 'zoom_range': 0.054949645659345354, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.2796118284202028, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339442705889, 'info': {'runtime': 39.66195726394653, 'histories': {'val_acc': [0.10091743153443031, 0.11926605572941107], 'loss': [12.777933773929126, 14.682922467793503], 'acc': [0.10273972602739725, 0.08904109589041095], 'val_loss': [14.491498430934522, 14.195753561247379]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 14)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 15)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 15) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 15) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 16) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 15) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 15)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1846201829154883, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.14433006298527634, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.13074497487237965, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:35:05.976751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 16s - loss: 12.8366 - acc: 0.1135 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/2
 - 6s - loss: 13.8011 - acc: 0.1438 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 15), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 15) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 15) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 15) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 15)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.14433006298527634, 'base_model': 'MobileNet', 'zoom_range': 0.1846201829154883, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.13074497487237965, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853197338385, 'info': {'runtime': 33.19228935241699, 'histories': {'val_acc': [0.11009174380280556, 0.13761468026616158], 'loss': [12.552983009651916, 13.801119232177735], 'acc': [0.1232876712328767, 0.14375], 'val_loss': [14.343626066085395, 13.900008997785935]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 15)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 16)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 16) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 16) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 17) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 16) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 16)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.27420149130847365, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.26927155149760446, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.23017788584333415, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:35:39.212187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 13s - loss: 12.7758 - acc: 0.1198 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 2/2
 - 5s - loss: 13.9842 - acc: 0.1324 - val_loss: 13.4564 - val_acc: 0.1651
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 16), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 16) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 16) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 16) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 16)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.26927155149760446, 'base_model': 'MobileNet', 'zoom_range': 0.27420149130847365, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.23017788584333415, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8348623834071903, 'info': {'runtime': 26.847270011901855, 'histories': {'val_acc': [0.12844036731424682, 0.1651376165928097], 'loss': [12.486906861605709, 13.799739158316834], 'acc': [0.13013698630136986, 0.14383561643835616], 'val_loss': [14.047881030161447, 13.45639218321634]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 16)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 17)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 17) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 17) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 18) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 17) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 17)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.015996910934847362, 'rotation_range': 18, 'optimizer': 'RMSProp', 'width_shift_range': 0.11038919062135473, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.07511308253732742, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:36:06.105889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 16s - loss: 13.1109 - acc: 0.1009 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/2
 - 6s - loss: 14.0858 - acc: 0.1261 - val_loss: 13.6043 - val_acc: 0.1560
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 17), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 17) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 17) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 17) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 17)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11038919062135473, 'base_model': 'MobileNet', 'zoom_range': 0.015996910934847362, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 18, 'height_shift_range': 0.07511308253732742, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.844036696427459, 'info': {'runtime': 34.71222996711731, 'histories': {'val_acc': [0.10091743119266056, 0.15596330357254098], 'loss': [12.85103129034173, 13.91013701974529], 'acc': [0.1095890410958904, 0.136986301369863], 'val_loss': [14.491498404686604, 13.604263734380039]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 17)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 18)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 18) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 19) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 18) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 18) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 18)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.15680103983869512, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.2389503048700109, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.28643119740902073, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:36:41.334070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 13s - loss: 13.7074 - acc: 0.1091 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 2/2
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 18), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 18) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 18) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 18) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 18)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2389503048700109, 'base_model': 'MobileNet', 'zoom_range': 0.15680103983869512, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.28643119740902073, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825668934288, 'info': {'runtime': 29.101521968841553, 'histories': {'val_acc': [0.06422018348623854, 0.10091743310657117], 'loss': [14.720113538715937, 14.68292236328125], 'acc': [0.07534246575342465, 0.08904109589041095], 'val_loss': [15.082988144060888, 14.49149859717133]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 18)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 19)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 19) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 20) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 19) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 19)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.11015208910422, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.10175963795004203, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.23288763901072626, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:37:10.002557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 13s - loss: 12.7961 - acc: 0.1324 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 2/2
 - 5s - loss: 13.2415 - acc: 0.1785 - val_loss: 14.0479 - val_acc: 0.1284
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 19), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 19) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 19) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 19)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10175963795004203, 'base_model': 'MobileNet', 'zoom_range': 0.11015208910422, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.23288763901072626, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8715596323439834, 'info': {'runtime': 31.940865755081177, 'histories': {'val_acc': [0.12844036888638768, 0.12844036765601657], 'loss': [12.5090399964215, 13.689341349144504], 'acc': [0.14383561643835616, 0.1506849315068493], 'val_loss': [14.047881642612841, 14.047881336387144]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 19)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 20)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 20) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 21) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 20)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2167855553950428, 'rotation_range': 10, 'optimizer': 'RMSProp', 'width_shift_range': 0.0740128489706842, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.26515553021218213, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
DEBUG:hpbandster:DISPATCHER: job (1, 0, 20) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
2018-02-07 19:37:41.989018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 17s - loss: 13.2688 - acc: 0.0750 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 2/2
 - 5s - loss: 14.7832 - acc: 0.0828 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 20), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 20) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 20) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 20) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 20)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.0740128489706842, 'base_model': 'MobileNet', 'zoom_range': 0.2167855553950428, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 10, 'height_shift_range': 0.26515553021218213, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9174311923187807, 'info': {'runtime': 33.09193968772888, 'histories': {'val_acc': [0.09174311926605505, 0.0825688076812193], 'loss': [13.268751120567321, 14.530707157019412], 'acc': [0.075, 0.09848484848484848], 'val_loss': [14.63937090952462, 14.787243274373745]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 20)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 21)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 21) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 22) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 21) on hpbandster.run_0.worker.tfpool20.19325140106390476544
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 21)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.03218892286583146, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.21629165317056206, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.07816227044651974, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
2018-02-07 19:38:15.600230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 13s - loss: 10.9676 - acc: 0.0883 - val_loss: 2.3941 - val_acc: 0.1376
Epoch 2/2
 - 5s - loss: 2.2527 - acc: 0.1702 - val_loss: 2.2578 - val_acc: 0.2385
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 21), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 21) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 21)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21629165317056206, 'base_model': 'MobileNet', 'zoom_range': 0.03218892286583146, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.07816227044651974, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.7614678879943463, 'info': {'runtime': 26.966552019119263, 'histories': {'val_acc': [0.13761467924085233, 0.23853211200565372], 'loss': [10.522484949190323, 2.2291045058263492], 'acc': [0.0958904109589041, 0.18493150684931506], 'val_loss': [2.3941488440977325, 2.2577837760295343]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 21)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 22)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 22) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 22) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 23) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 22) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 22)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.08228540947333497, 'rotation_range': 5, 'optimizer': 'RMSProp', 'width_shift_range': 0.03544923168327222, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21227302358043665, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:38:42.130600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 12s - loss: 12.9506 - acc: 0.1343 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/2
 - 7s - loss: 13.9528 - acc: 0.1343 - val_loss: 14.9351 - val_acc: 0.0734
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 22), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 22) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 22) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 22) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 22)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.03544923168327222, 'base_model': 'MobileNet', 'zoom_range': 0.08228540947333497, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 5, 'height_shift_range': 0.21227302358043665, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9266055042453862, 'info': {'runtime': 30.762388944625854, 'histories': {'val_acc': [0.08256880733944955, 0.07339449575461379], 'loss': [13.373289082148304, 14.462126483655956], 'acc': [0.10273972602739725, 0.10273972602739725], 'val_loss': [14.787243414362637, 14.93511549923398]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 22)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 23)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 23) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 24) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 23) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 23) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 23)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2652458386028668, 'rotation_range': 12, 'optimizer': 'RMSProp', 'width_shift_range': 0.11960852736855256, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11091521664587521, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:39:13.426784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 17s - loss: 13.5386 - acc: 0.0813 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/2
 - 5s - loss: 14.7832 - acc: 0.0828 - val_loss: 15.0830 - val_acc: 0.0642
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 23), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 23) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 23) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 23) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 23)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11960852736855256, 'base_model': 'MobileNet', 'zoom_range': 0.2652458386028668, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 12, 'height_shift_range': 0.11091521664587521, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9357798165137614, 'info': {'runtime': 34.12708497047424, 'histories': {'val_acc': [0.0825688076812193, 0.06422018348623854], 'loss': [13.538558864593506, 14.530707272616299], 'acc': [0.08125, 0.09848484848484848], 'val_loss': [14.787243274373745, 15.082988144060888]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 23)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 24)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 24) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 24) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 25) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 24) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 24)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.006289230421602698, 'rotation_range': 26, 'optimizer': 'RMSProp', 'width_shift_range': 0.11745106398586556, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.276747046503611, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:39:47.106989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 12s - loss: 12.6505 - acc: 0.1198 - val_loss: 14.6276 - val_acc: 0.0917
Epoch 2/2
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.6261 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 24), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 24) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 24) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 24) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 24)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11745106398586556, 'base_model': 'MobileNet', 'zoom_range': 0.006289230421602698, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 26, 'height_shift_range': 0.276747046503611, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 27.214119911193848, 'histories': {'val_acc': [0.0917431196078248, 0.0917431196078248], 'loss': [12.350871778514287, 14.682922467793503], 'acc': [0.13013698630136986, 0.08904109589041095], 'val_loss': [14.627615622424205, 14.626081904140088]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 24)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 25)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 25) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 26) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 25) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 25) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 25)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.07188767479831099, 'rotation_range': 1, 'optimizer': 'RMSProp', 'width_shift_range': 0.13966978152500661, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.19708870890906902, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:40:14.367977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 15s - loss: 13.2968 - acc: 0.0693 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/2
 - 4s - loss: 14.3906 - acc: 0.1072 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 25), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 25) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 25) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 25) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 25)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.13966978152500661, 'base_model': 'MobileNet', 'zoom_range': 0.07188767479831099, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 1, 'height_shift_range': 0.19708870890906902, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825688073394, 'info': {'runtime': 30.787685871124268, 'histories': {'val_acc': [0.10091743187620006, 0.10091743119266056], 'loss': [13.052990377765813, 14.24133081305517], 'acc': [0.07534246575342465, 0.11643835616438356], 'val_loss': [14.491498457182438, 14.491498684664386]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 25)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 26)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 26) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 26) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 27) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 26) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 26)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24267164938303276, 'rotation_range': 5, 'optimizer': 'RMSProp', 'width_shift_range': 0.27037026875639975, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.110180090036293, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:40:45.692804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 12s - loss: 13.5845 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/2
 - 5s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 26), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 26) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 26) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 26) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 26)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.27037026875639975, 'base_model': 'MobileNet', 'zoom_range': 0.24267164938303276, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 5, 'height_shift_range': 0.110180090036293, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339442705889, 'info': {'runtime': 24.908975839614868, 'histories': {'val_acc': [0.10091743310657117, 0.11926605572941107], 'loss': [13.365535579315603, 14.351728674483626], 'acc': [0.08904109589041095, 0.1095890410958904], 'val_loss': [14.491498317193548, 14.19575384122516]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 26)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 27)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 27) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 28) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 27) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 27) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 27)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.009982172063269045, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.08280598981877625, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20745675094320562, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:41:10.158011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 17s - loss: 13.2300 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/2
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.9351 - val_acc: 0.0734
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 27), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 27) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 27) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 27) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 27)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08280598981877625, 'base_model': 'MobileNet', 'zoom_range': 0.009982172063269045, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.20745675094320562, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9266055039036165, 'info': {'runtime': 32.953245878219604, 'histories': {'val_acc': [0.10091743153443031, 0.07339449609638354], 'loss': [12.980437631476414, 14.572524501852794], 'acc': [0.0958904109589041, 0.0958904109589041], 'val_loss': [14.491498544675494, 14.935115805459679]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 27)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 28)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 28) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 28) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 29) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 28) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 28)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.10989683167092655, 'rotation_range': 25, 'optimizer': 'RMSProp', 'width_shift_range': 0.025773723589332796, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1900102213900997, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:41:43.647952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 13s - loss: 13.2984 - acc: 0.0883 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 2/2
 - 5s - loss: 14.1560 - acc: 0.1217 - val_loss: 14.9351 - val_acc: 0.0734
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 28), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 28) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 28) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 28) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 28)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.025773723589332796, 'base_model': 'MobileNet', 'zoom_range': 0.10989683167092655, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 25, 'height_shift_range': 0.1900102213900997, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.926605504587156, 'info': {'runtime': 30.101287364959717, 'histories': {'val_acc': [0.07339449575461379, 0.07339449541284404], 'loss': [13.054752663390277, 14.682922415537377], 'acc': [0.0958904109589041, 0.08904109589041095], 'val_loss': [14.93511549923398, 14.935115919200653]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 28)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 29)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 29) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 30) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 29) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 29) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 29)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.17989720676694357, 'rotation_range': 14, 'optimizer': 'RMSProp', 'width_shift_range': 0.27351144247526776, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11217222161293501, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:42:13.286030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 14s - loss: 7.4380 - acc: 0.1009 - val_loss: 3.4025 - val_acc: 0.0917
Epoch 2/2
 - 6s - loss: 2.3630 - acc: 0.1954 - val_loss: 2.1150 - val_acc: 0.2385
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 29), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 29) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 29) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 29) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 29)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.27351144247526776, 'base_model': 'MobileNet', 'zoom_range': 0.17989720676694357, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 14, 'height_shift_range': 0.11217222161293501, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.7614678885411779, 'info': {'runtime': 30.31045174598694, 'histories': {'val_acc': [0.0917431196078248, 0.23853211145882214], 'loss': [7.860287558542539, 2.2928621801611495], 'acc': [0.1095890410958904, 0.21232876712328766], 'val_loss': [3.402450242173781, 2.1150243960389306]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 29)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 30)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 30) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 31) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 30) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 30) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 30)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.03207522061844541, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.04236020348636536, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20082689757130254, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:42:43.639670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 15s - loss: 13.4012 - acc: 0.1280 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/2
 - 4s - loss: 13.8512 - acc: 0.1406 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 30), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 30) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 30) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 30) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 30)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.04236020348636536, 'base_model': 'MobileNet', 'zoom_range': 0.03207522061844541, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.20082689757130254, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9174311923187807, 'info': {'runtime': 29.552051305770874, 'histories': {'val_acc': [0.10091743187620006, 0.0825688076812193], 'loss': [14.398992309831593, 14.351728517715244], 'acc': [0.0958904109589041, 0.1095890410958904], 'val_loss': [14.491498570923412, 14.787243160632773]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 30)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 31)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 31) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 31) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 31) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 31)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.05895325685018531, 'rotation_range': 2, 'optimizer': 'RMSProp', 'width_shift_range': 0.05258061322293593, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.22442201011498686, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:43:13.738914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/2
 - 13s - loss: 13.7113 - acc: 0.0693 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/2
 - 5s - loss: 15.1019 - acc: 0.0630 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 31), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 31) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 31) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 31) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 31)
args: ()
kwargs: {'budget': 2.0, 'working_directory': '.', 'config': {'width_shift_range': 0.05258061322293593, 'base_model': 'MobileNet', 'zoom_range': 0.05895325685018531, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 2, 'height_shift_range': 0.22442201011498686, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9174311923187807, 'info': {'runtime': 30.10404396057129, 'histories': {'val_acc': [0.0825688076812193, 0.0825688076812193], 'loss': [13.503328271108131, 15.014116156591127], 'acc': [0.07534246575342465, 0.0684931506849315], 'val_loss': [14.787243274373745, 14.787243160632773]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 31)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 0) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 0, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.03860841190969875, 'rotation_range': 26, 'optimizer': 'RMSProp', 'width_shift_range': 0.053446624942323, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08236166711735655, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:43:43.376946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 15s - loss: 13.2726 - acc: 0.0757 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/4
 - 7s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 3/4
 - 6s - loss: 13.0069 - acc: 0.1930 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 4/4
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 15.2309 - val_acc: 0.0550
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 0)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.053446624942323, 'base_model': 'MobileNet', 'zoom_range': 0.03860841190969875, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 26, 'height_shift_range': 0.08236166711735655, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9449541280985972, 'info': {'runtime': 39.64776039123535, 'histories': {'val_acc': [0.10091743153443031, 0.09174312063313406, 0.07339449541284404, 0.05504587190140278], 'loss': [13.026719916356752, 14.682922572305758, 14.130932848747463, 14.682922572305758], 'acc': [0.0821917808219178, 0.08904109589041095, 0.1232876712328767, 0.08904109589041095], 'val_loss': [14.491498430934522, 14.639370682042673, 14.93511535924509, 15.230860508910013]}}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 3) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 10) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 3) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 3)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.29884910693699573, 'rotation_range': 15, 'optimizer': 'RMSProp', 'width_shift_range': 0.17805225703642188, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.09414238126027155, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:44:23.584432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 13.6418 - acc: 0.0757 - val_loss: 15.2309 - val_acc: 0.0550
Epoch 2/4
 - 5s - loss: 15.1019 - acc: 0.0630 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/4
 - 6s - loss: 15.0100 - acc: 0.0687 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 4/4
 - 5s - loss: 13.3984 - acc: 0.1687 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 3), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 3)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.17805225703642188, 'base_model': 'MobileNet', 'zoom_range': 0.29884910693699573, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 15, 'height_shift_range': 0.09414238126027155, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825674402605, 'info': {'runtime': 41.69395565986633, 'histories': {'val_acc': [0.05504587155963303, 0.10091743119266056, 0.08256880802298905, 0.10091743255973956], 'loss': [14.607753165780682, 15.014115843054366, 15.009976196289063, 14.408600431500059], 'acc': [0.0821917808219178, 0.0684931506849315, 0.06875, 0.10606060606060606], 'val_loss': [15.230860648898904, 14.491498684664386, 14.787242906902907, 14.491498457182438]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 3)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 10)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 10) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 10) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 10) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 10)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1436815210618747, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.21104483246046915, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.05256752553004263, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:45:04.806764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 16s - loss: 13.2870 - acc: 0.1009 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/4
 - 5s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 3/4
 - 7s - loss: 14.4055 - acc: 0.1062 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 4/4
 - 7s - loss: 12.9053 - acc: 0.1993 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 10), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 10) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 10) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 10) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 10)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21104483246046915, 'base_model': 'MobileNet', 'zoom_range': 0.1436815210618747, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.05256752553004263, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825684655697, 'info': {'runtime': 42.74569845199585, 'histories': {'val_acc': [0.11009174380280556, 0.0917431196078248, 0.07339449575461379, 0.10091743153443031], 'loss': [13.042349697792368, 14.351728674483626, 14.405547618865967, 14.020534987319005], 'acc': [0.1095890410958904, 0.1095890410958904, 0.10625, 0.13013698630136986], 'val_loss': [14.343626232322203, 14.639371329491292, 14.935115665470788, 14.491498430934522]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 10)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.14301167412200663, 'rotation_range': 26, 'optimizer': 'RMSProp', 'width_shift_range': 0.2404575165575404, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20932192731203267, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:45:48.106760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 13s - loss: 13.4064 - acc: 0.0757 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/4
 - 5s - loss: 14.2576 - acc: 0.1154 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 3/4
 - 6s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 4/4
 - 5s - loss: 14.5779 - acc: 0.0956 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 0)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2404575165575404, 'base_model': 'MobileNet', 'zoom_range': 0.14301167412200663, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 26, 'height_shift_range': 0.20932192731203267, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568800504054, 'info': {'runtime': 41.774919748306274, 'histories': {'val_acc': [0.10091743310657117, 0.10091743187620006, 0.07339449575461379, 0.09174311994959455], 'loss': [13.467632398213425, 14.793320276965833, 14.506285762786865, 14.286493590383818], 'acc': [0.0821917808219178, 0.0821917808219178, 0.1, 0.11363636363636363], 'val_loss': [14.491498317193548, 14.49149829094563, 14.935115779211761, 14.639370402064893]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.12868459232692314, 'rotation_range': 1, 'optimizer': 'RMSProp', 'width_shift_range': 0.22767536467020139, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.02338123654391112, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:46:29.396385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 11s - loss: 13.5305 - acc: 0.0820 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 2/4
 - 6s - loss: 15.2035 - acc: 0.0567 - val_loss: 14.0479 - val_acc: 0.1284
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/4
 - 6s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 4/4
 - 6s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 1)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.22767536467020139, 'base_model': 'MobileNet', 'zoom_range': 0.12868459232692314, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 1, 'height_shift_range': 0.02338123654391112, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825688073394, 'info': {'runtime': 37.72996473312378, 'histories': {'val_acc': [0.09174311926605505, 0.12844036731424682, 0.07339449609638354, 0.10091743119266056], 'loss': [14.49508018363012, 15.12451391350733, 14.903718086138163, 14.68292236328125], 'acc': [0.08904109589041095, 0.06164383561643835, 0.07534246575342465, 0.08904109589041095], 'val_loss': [14.63937090952462, 14.047881310139227, 14.935115805459679, 14.491498404686604]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 21) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.10340454376382442, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.20524188789474698, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1140943526997985, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:47:07.188278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 13s - loss: 12.6307 - acc: 0.1072 - val_loss: 13.3085 - val_acc: 0.1743
Epoch 2/4
 - 5s - loss: 13.9842 - acc: 0.1324 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 3/4
 - 6s - loss: 13.7004 - acc: 0.1500 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 4/4
 - 5s - loss: 14.0858 - acc: 0.1261 - val_loss: 13.6043 - val_acc: 0.1560
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 9)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.20524188789474698, 'base_model': 'MobileNet', 'zoom_range': 0.10340454376382442, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.1140943526997985, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8440366953337958, 'info': {'runtime': 36.193907499313354, 'histories': {'val_acc': [0.1743119285194152, 0.13761467924085233, 0.14678899082568808, 0.1559633046662042], 'loss': [12.329283779614592, 13.799739158316834, 13.700380992889404, 13.910137124257545], 'acc': [0.11643835616438356, 0.14383561643835616, 0.15, 0.136986301369863], 'val_loss': [13.308519118422762, 13.900009085278992, 13.752136720429867, 13.604263848121013]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 21)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 21) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 14) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 21) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 21)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.03218892286583146, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.21629165317056206, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.07816227044651974, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:47:43.938925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 12.8082 - acc: 0.1009 - val_loss: 13.3085 - val_acc: 0.1743
Epoch 2/4
 - 5s - loss: 14.1874 - acc: 0.1198 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 3/4
 - 7s - loss: 14.1874 - acc: 0.1198 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 4/4
 - 6s - loss: 13.8825 - acc: 0.1387 - val_loss: 14.0479 - val_acc: 0.1284
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 21), trying to register it.
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 21)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21629165317056206, 'base_model': 'MobileNet', 'zoom_range': 0.03218892286583146, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.07816227044651974, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8715596326857532, 'info': {'runtime': 40.64430856704712, 'histories': {'val_acc': [0.1743119285194152, 0.12844036731424682, 0.13761467889908258, 0.12844036731424682], 'loss': [12.522197671132545, 14.020534985686002, 14.020534985686002, 13.689341296888378], 'acc': [0.1095890410958904, 0.13013698630136986, 0.13013698630136986, 0.1506849315068493], 'val_loss': [13.308519398400543, 14.047881476376034, 13.900008945290102, 14.047881196398254]}}}
exception: None

INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 21) with dispatcher
DEBUG:hpbandster:job_callback for (1, 0, 21)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 14)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 14) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 29) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 14)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.054949645659345354, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.26716847752572814, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2796118284202028, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:48:24.106388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 8.4920 - acc: 0.0757 - val_loss: 2.3996 - val_acc: 0.1009
Epoch 2/4
 - 5s - loss: 2.2440 - acc: 0.1513 - val_loss: 4.6216 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/4
 - 6s - loss: 2.4636 - acc: 0.2313 - val_loss: 3.0691 - val_acc: 0.0917
Epoch 4/4
 - 5s - loss: 1.9521 - acc: 0.3026 - val_loss: 2.2896 - val_acc: 0.2202
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 14), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 14) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 14)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.26716847752572814, 'base_model': 'MobileNet', 'zoom_range': 0.054949645659345354, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.2796118284202028, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.7798165123943889, 'info': {'runtime': 39.06614923477173, 'histories': {'val_acc': [0.10091743187620006, 0.10091743310657117, 0.09174311926605505, 0.22018348760561113], 'loss': [7.832905651771859, 2.2762394816908116, 2.4636008501052857, 1.9024068884653589], 'acc': [0.0821917808219178, 0.1643835616438356, 0.23125, 0.3287671232876712], 'val_loss': [2.3995642180836527, 4.621552049566846, 3.069137619176042, 2.289577921596142]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 14)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 29)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 29) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 15) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 29) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 29) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 29)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.17989720676694357, 'rotation_range': 14, 'optimizer': 'RMSProp', 'width_shift_range': 0.27351144247526776, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11217222161293501, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:49:03.724556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 13s - loss: 13.4960 - acc: 0.0693 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/4
 - 6s - loss: 14.6070 - acc: 0.0938 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 3/4
 - 5s - loss: 15.0913 - acc: 0.0637 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 4/4
 - 6s - loss: 15.0100 - acc: 0.0687 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 29), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 29) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 29) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 29) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 29)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.27351144247526776, 'base_model': 'MobileNet', 'zoom_range': 0.17989720676694357, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 14, 'height_shift_range': 0.11217222161293501, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9174311923187807, 'info': {'runtime': 40.122398376464844, 'histories': {'val_acc': [0.10091743187620006, 0.10091743153443031, 0.10091743187620006, 0.0825688076812193], 'loss': [13.269377826011343, 14.607023906707763, 14.897027217980588, 15.009976196289063], 'acc': [0.07534246575342465, 0.09375, 0.07575757575757576, 0.06875], 'val_loss': [14.491497897226877, 14.491498710912301, 14.49149829094563, 14.787243274373745]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 29)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 15)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 15) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 18) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 15) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 15) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 15)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1846201829154883, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.14433006298527634, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.13074497487237965, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:49:43.376625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 11.8236 - acc: 0.1596 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 2/4
 - 6s - loss: 12.9366 - acc: 0.1974 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 3/4
 - 5s - loss: 13.3745 - acc: 0.1702 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 4/4
 - 6s - loss: 13.7809 - acc: 0.1450 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 15), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 15) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 15) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 15) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 15)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.14433006298527634, 'base_model': 'MobileNet', 'zoom_range': 0.1846201829154883, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.13074497487237965, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339430402178, 'info': {'runtime': 40.47304320335388, 'histories': {'val_acc': [0.1559633046662042, 0.14678899150922758, 0.14678899082568808, 0.11926605695978217], 'loss': [12.14889756294146, 13.358147764859135, 13.137351676209333, 13.578943121923158], 'acc': [0.13013698630136986, 0.17123287671232876, 0.18493150684931506, 0.15753424657534246], 'val_loss': [13.604263848121013, 13.75213621297014, 13.752136440452086, 14.195753587495297]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 15)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 18)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 18) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 12) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 18) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 18) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 18)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.15680103983869512, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.2389503048700109, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.28643119740902073, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:50:23.905208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 13.5592 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/4
 - 4s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/4
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 4/4
 - 5s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 18), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 18) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 18) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 18) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 18)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2389503048700109, 'base_model': 'MobileNet', 'zoom_range': 0.15680103983869512, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.28643119740902073, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082555136549, 'info': {'runtime': 38.244301080703735, 'histories': {'val_acc': [0.10091743153443031, 0.0917431196078248, 0.09174311926605505, 0.11009174448634507], 'loss': [13.338037647613108, 14.46212674493659, 14.68292236328125, 14.506285858154296], 'acc': [0.0958904109589041, 0.10273972602739725, 0.08904109589041095, 0.1], 'val_loss': [14.491498824653275, 14.639370935772536, 14.639370629546839, 14.343625672366642]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 18)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 12)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 12) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 19) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 12)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0407398762639929, 'rotation_range': 13, 'optimizer': 'RMSProp', 'width_shift_range': 0.1984552572785443, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.24526274023440595, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:51:02.191251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 10.9385 - acc: 0.1974 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 2/4
 - 5s - loss: 13.4447 - acc: 0.1659 - val_loss: 13.4564 - val_acc: 0.1651
Epoch 3/4
 - 6s - loss: 13.8825 - acc: 0.1387 - val_loss: 13.3085 - val_acc: 0.1743
Epoch 4/4
 - 5s - loss: 13.7496 - acc: 0.1469 - val_loss: 13.7521 - val_acc: 0.1468
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 12), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 12) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 12)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1984552572785443, 'base_model': 'MobileNet', 'zoom_range': 0.0407398762639929, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 13, 'height_shift_range': 0.24526274023440595, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8532110084907725, 'info': {'runtime': 40.43991780281067, 'histories': {'val_acc': [0.12844036765601657, 0.1651376153624386, 0.1743119285194152, 0.14678899150922758], 'loss': [11.187298918423588, 13.910137072001419, 13.689341505912886, 14.241330656286788], 'acc': [0.17123287671232876, 0.136986301369863, 0.1506849315068493, 0.11643835616438356], 'val_loss': [14.047881336387144, 13.45639204322745, 13.308519678378325, 13.752136326711112]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 12)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 19)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 19) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 26) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 19) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 19)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.11015208910422, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.10175963795004203, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.23288763901072626, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:51:42.677252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 12.9982 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/4
 - 6s - loss: 14.2890 - acc: 0.1135 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 3/4
 - 5s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 4/4
 - 5s - loss: 13.3982 - acc: 0.1687 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 19), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 19) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 19) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 19)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10175963795004203, 'base_model': 'MobileNet', 'zoom_range': 0.11015208910422, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.23288763901072626, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339442705889, 'info': {'runtime': 39.887452125549316, 'histories': {'val_acc': [0.10091743153443031, 0.12844036731424682, 0.11009174448634507, 0.11926605572941107], 'loss': [12.728529838666525, 14.130933056138966, 14.462126640424337, 13.398166942596436], 'acc': [0.0958904109589041, 0.1232876712328767, 0.10273972602739725, 0.16875], 'val_loss': [14.491498264697714, 14.047881310139227, 14.343625952344421, 14.19575384122516]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 19)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 26)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 26) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 16) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 26) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 26) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 26)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24267164938303276, 'rotation_range': 5, 'optimizer': 'RMSProp', 'width_shift_range': 0.27037026875639975, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.110180090036293, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:52:22.594784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 6.5221 - acc: 0.1261 - val_loss: 2.3099 - val_acc: 0.1376
Epoch 2/4
 - 4s - loss: 2.2328 - acc: 0.2396 - val_loss: 1.7863 - val_acc: 0.4037
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 3/4
 - 5s - loss: 2.0437 - acc: 0.3739 - val_loss: 1.6307 - val_acc: 0.3578
Epoch 4/4
 - 5s - loss: 1.6679 - acc: 0.4000 - val_loss: 1.7815 - val_acc: 0.3119
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 26), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 26) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 26) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 26) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 26)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.27037026875639975, 'base_model': 'MobileNet', 'zoom_range': 0.24267164938303276, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 5, 'height_shift_range': 0.110180090036293, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.6880733931283338, 'info': {'runtime': 39.337990045547485, 'histories': {'val_acc': [0.13761467924085233, 0.40366972750480024, 0.3577981658211542, 0.3119266068716662], 'loss': [6.784559547084651, 2.176921596265819, 2.0450595568304193, 1.6679071187973022], 'acc': [0.136986301369863, 0.2602739726027397, 0.363013698630137, 0.4], 'val_loss': [2.309857862805008, 1.786330671485411, 1.6307321163492465, 1.7814693439991103]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 26)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 16)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 16) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 16) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 16) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 16)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.27420149130847365, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.26927155149760446, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.23017788584333415, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:53:02.005361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 12.8770 - acc: 0.1280 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/4
 - 4s - loss: 14.2576 - acc: 0.1154 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 3/4
 - 6s - loss: 13.9528 - acc: 0.1343 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 4/4
 - 6s - loss: 14.6070 - acc: 0.0938 - val_loss: 15.0830 - val_acc: 0.0642
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 16), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 16) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 16) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 16) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 16)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.26927155149760446, 'base_model': 'MobileNet', 'zoom_range': 0.27420149130847365, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.23017788584333415, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9357798165137614, 'info': {'runtime': 41.69456696510315, 'histories': {'val_acc': [0.11009174346103581, 0.07339449575461379, 0.09174312117996566, 0.06422018348623854], 'loss': [13.293399941431334, 14.793320276965833, 14.462126588168209, 14.607023906707763], 'acc': [0.0958904109589041, 0.0821917808219178, 0.10273972602739725, 0.09375], 'val_loss': [14.343626039837478, 14.935115779211761, 14.639370542053783, 15.082988144060888]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 16)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 17) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.13070844626277076, 'rotation_range': 11, 'optimizer': 'RMSProp', 'width_shift_range': 0.28809388168018457, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.07922358039346385, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:53:43.733339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 13.2036 - acc: 0.0946 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/4
 - 4s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 3/4
 - 9s - loss: 15.0100 - acc: 0.0687 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 4/4
 - 8s - loss: 14.6806 - acc: 0.0892 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 2)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.28809388168018457, 'base_model': 'MobileNet', 'zoom_range': 0.13070844626277076, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 11, 'height_shift_range': 0.07922358039346385, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339442705889, 'info': {'runtime': 48.03795027732849, 'histories': {'val_acc': [0.10091743153443031, 0.0917431196078248, 0.07339449541284404, 0.11926605572941107], 'loss': [12.951681947054928, 14.46212674493659, 15.00997610092163, 14.408600315903172], 'acc': [0.10273972602739725, 0.10273972602739725, 0.06875, 0.10606060606060606], 'val_loss': [14.491498430934522, 14.639370769535729, 14.93511535924509, 14.19575384122516]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 17)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 17) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 17) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 17) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 17)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.015996910934847362, 'rotation_range': 18, 'optimizer': 'RMSProp', 'width_shift_range': 0.11038919062135473, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.07511308253732742, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:54:31.818959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 14s - loss: 13.4013 - acc: 0.0820 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 2/4
 - 6s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 3/4
 - 5s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 4/4
 - 7s - loss: 14.8085 - acc: 0.0813 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 17), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 17) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 17) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 17) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 17)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11038919062135473, 'base_model': 'MobileNet', 'zoom_range': 0.015996910934847362, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 18, 'height_shift_range': 0.07511308253732742, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9174311923187807, 'info': {'runtime': 42.787116050720215, 'histories': {'val_acc': [0.06422018382800829, 0.11009174346103581, 0.07339449609638354, 0.0825688076812193], 'loss': [13.166487079777129, 14.46212674493659, 14.90371829516267, 14.80850009918213], 'acc': [0.08904109589041095, 0.10273972602739725, 0.07534246575342465, 0.08125], 'val_loss': [15.08298856402756, 14.343626039837478, 14.935115805459679, 14.787242994395966]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 17)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0012898099224737723, 'rotation_range': 16, 'optimizer': 'RMSProp', 'width_shift_range': 0.1923638579603008, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.14958852413514515, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:55:15.202499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 13s - loss: 12.7722 - acc: 0.1343 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 2/4
 - 5s - loss: 13.6479 - acc: 0.1533 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 3/4
 - 5s - loss: 13.2415 - acc: 0.1785 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 4/4
 - 6s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 1)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1923638579603008, 'base_model': 'MobileNet', 'zoom_range': 0.0012898099224737723, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 16, 'height_shift_range': 0.14958852413514515, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339446123587, 'info': {'runtime': 41.74696683883667, 'histories': {'val_acc': [0.11009174311926606, 0.11009174448634507, 0.0917431196078248, 0.11926605538764132], 'loss': [13.179488769949298, 14.130933108395093, 13.689341244632251, 14.351728883508134], 'acc': [0.10273972602739725, 0.1232876712328767, 0.1506849315068493, 0.1095890410958904], 'val_loss': [14.343625899848588, 14.343625952344421, 14.63937104951351, 14.195753814977243]}}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 21) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.10340454376382442, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.20524188789474698, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1140943526997985, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:55:56.441987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 13s - loss: 12.3608 - acc: 0.1217 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 2/8
 - 6s - loss: 13.6479 - acc: 0.1533 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 3/8
 - 6s - loss: 13.0696 - acc: 0.1891 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 4/8
 - 6s - loss: 13.5777 - acc: 0.1576 - val_loss: 13.4564 - val_acc: 0.1651
Epoch 5/8
 - 7s - loss: 13.1399 - acc: 0.1848 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 6/8
 - 7s - loss: 13.1967 - acc: 0.1812 - val_loss: 13.4564 - val_acc: 0.1651
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 7/8
 - 5s - loss: 14.4922 - acc: 0.1009 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 8/8
 - 5s - loss: 13.7564 - acc: 0.1465 - val_loss: 13.1606 - val_acc: 0.1835
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 9)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.20524188789474698, 'base_model': 'MobileNet', 'zoom_range': 0.10340454376382442, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.1140943526997985, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8165137614678899, 'info': {'runtime': 66.58673214912415, 'histories': {'val_acc': [0.14678899150922758, 0.13761467958262208, 0.1559633034358331, 0.1651376165928097, 0.11926605538764132, 0.16513761502066884, 0.13761467958262208, 0.1834862385321101], 'loss': [12.732540287383616, 14.130932899370585, 12.806157987411709, 13.358147608090754, 13.57894327869154, 13.196690654754638, 14.351728674483626, 13.309639323841441], 'acc': [0.08904109589041095, 0.1232876712328767, 0.2054794520547945, 0.17123287671232876, 0.15753424657534246, 0.18125, 0.1095890410958904, 0.17424242424242425], 'val_loss': [13.752136326711112, 13.90000911152691, 13.604263821873095, 13.45639190323856, 14.19575342125849, 13.45639145702397, 13.90000911152691, 13.160646701077802]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 21)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 21) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 14) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 21) on hpbandster.run_0.worker.tfpool20.19325140106390476544
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 21)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.03218892286583146, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.21629165317056206, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.07816227044651974, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
2018-02-07 19:57:03.627451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 13s - loss: 6.4234 - acc: 0.1533 - val_loss: 2.5734 - val_acc: 0.1743
Epoch 2/8
 - 6s - loss: 2.1508 - acc: 0.2687 - val_loss: 1.7144 - val_acc: 0.4954
Epoch 3/8
 - 5s - loss: 2.3144 - acc: 0.2166 - val_loss: 4.9782 - val_acc: 0.0917
Epoch 4/8
 - 6s - loss: 1.9445 - acc: 0.4117 - val_loss: 1.4992 - val_acc: 0.5413
Epoch 5/8
 - 7s - loss: 1.2705 - acc: 0.5312 - val_loss: 1.6178 - val_acc: 0.4220
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 6/8
 - 5s - loss: 1.8129 - acc: 0.4681 - val_loss: 1.8807 - val_acc: 0.4128
Epoch 7/8
 - 6s - loss: 1.7422 - acc: 0.5820 - val_loss: 1.8426 - val_acc: 0.4679
Epoch 8/8
 - 6s - loss: 0.9360 - acc: 0.7250 - val_loss: 0.9105 - val_acc: 0.7064
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 21), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 21) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 21)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21629165317056206, 'base_model': 'MobileNet', 'zoom_range': 0.03218892286583146, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.07816227044651974, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.29357797290207044, 'info': {'runtime': 67.18247365951538, 'histories': {'val_acc': [0.17431192694727435, 0.4954128467708553, 0.0917431196078248, 0.5412844069507143, 0.42201835245167446, 0.4128440388845741, 0.46788991208470193, 0.7064220270979296], 'loss': [6.848801655312107, 2.150761914253235, 2.2776976065202192, 1.945452441907909, 1.2705420136451722, 1.6855331289045739, 1.771223104163392, 0.9360040545463562], 'acc': [0.1232876712328767, 0.26875, 0.25757575757575757, 0.4041095890410959, 0.53125, 0.4621212121212121, 0.589041095890411, 0.725], 'val_loss': [2.5733776617487636, 1.7144444513758388, 4.978199390096402, 1.4991652921799126, 1.6178355501332413, 1.8807441783607552, 1.842624011389706, 0.9105076702362901]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 21)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 14)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 14) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 15) to dispatcher
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 14)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.054949645659345354, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.26716847752572814, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2796118284202028, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:58:10.300877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 14s - loss: 8.0316 - acc: 0.0693 - val_loss: 2.3893 - val_acc: 0.2110
Epoch 2/8
 - 5s - loss: 2.3880 - acc: 0.2563 - val_loss: 2.4753 - val_acc: 0.1651
Epoch 3/8
 - 5s - loss: 2.1291 - acc: 0.2627 - val_loss: 1.8601 - val_acc: 0.3578
Epoch 4/8
 - 6s - loss: 2.0307 - acc: 0.2563 - val_loss: 1.6459 - val_acc: 0.4862
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 5/8
 - 5s - loss: 1.9230 - acc: 0.4427 - val_loss: 1.4875 - val_acc: 0.5413
Epoch 6/8
 - 6s - loss: 1.7084 - acc: 0.5063 - val_loss: 1.4126 - val_acc: 0.5046
Epoch 7/8
 - 5s - loss: 1.4725 - acc: 0.5189 - val_loss: 1.3671 - val_acc: 0.4679
Epoch 8/8
 - 5s - loss: 1.4164 - acc: 0.5250 - val_loss: 0.9234 - val_acc: 0.6881
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 14), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 14) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 14)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.26716847752572814, 'base_model': 'MobileNet', 'zoom_range': 0.054949645659345354, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.2796118284202028, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.31192660277042916, 'info': {'runtime': 62.697391748428345, 'histories': {'val_acc': [0.21100917622583723, 0.1651376165928097, 0.3577981689654359, 0.48623853593791294, 0.5412844080443776, 0.5045871586974607, 0.46788990907712813, 0.6880733972295708], 'loss': [8.495656385813675, 2.3879658460617064, 2.1284708163954993, 2.0306761026382447, 1.83838947614034, 1.7176801897075078, 1.456443727832951, 1.4164153933525085], 'acc': [0.07534246575342465, 0.25625, 0.26515151515151514, 0.25625, 0.4318181818181818, 0.5068493150684932, 0.5205479452054794, 0.525], 'val_loss': [2.389329822785264, 2.4753478951410415, 1.8601152404732662, 1.6458810863144901, 1.4874934592378248, 1.412590164657033, 1.3670535186015138, 0.9233930351537302]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 14)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 15)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 15) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 12) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 15) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 15) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 15)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1846201829154883, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.14433006298527634, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.13074497487237965, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 19:59:13.597385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 12s - loss: 13.5965 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/8
 - 6s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 3/8
 - 6s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 4/8
 - 7s - loss: 14.3725 - acc: 0.1083 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 5/8
 - 5s - loss: 13.8512 - acc: 0.1406 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 6/8
 - 5s - loss: 14.8085 - acc: 0.0813 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 7/8
 - 5s - loss: 13.5011 - acc: 0.1624 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 8/8
 - 6s - loss: 14.9092 - acc: 0.0750 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 15), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 15) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 15) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 15) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 15)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.14433006298527634, 'base_model': 'MobileNet', 'zoom_range': 0.1846201829154883, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.13074497487237965, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9082568803921752, 'info': {'runtime': 65.14408850669861, 'histories': {'val_acc': [0.10091743119266056, 0.10091743153443031, 0.10091743310657117, 0.0825688076812193, 0.09174311994959455, 0.10091743310657117, 0.10091743153443031, 0.0917431196078248], 'loss': [13.378532853845048, 14.572524606365047, 14.506285858154296, 14.042280023748225, 14.351728726739752, 14.808499908447265, 14.530707041422525, 14.909238243103028], 'acc': [0.08904109589041095, 0.0958904109589041, 0.1, 0.12878787878787878, 0.1095890410958904, 0.08125, 0.09848484848484848, 0.075], 'val_loss': [14.491498684664386, 14.491498544675494, 14.491498317193548, 14.787243554351527, 14.639370682042673, 14.491498317193548, 14.491498710912301, 14.639370769535729]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 15)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 12)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 12) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 19) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 12)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0407398762639929, 'rotation_range': 13, 'optimizer': 'RMSProp', 'width_shift_range': 0.1984552572785443, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.24526274023440595, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:00:18.229422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 14s - loss: 11.7136 - acc: 0.1324 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 2/8
 - 5s - loss: 14.3906 - acc: 0.1072 - val_loss: 13.7519 - val_acc: 0.1468
Epoch 3/8
 - 5s - loss: 12.9952 - acc: 0.1938 - val_loss: 13.8927 - val_acc: 0.1376
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 4/8
 - 4s - loss: 13.9618 - acc: 0.1338 - val_loss: 13.7472 - val_acc: 0.1468
Epoch 5/8
 - 5s - loss: 13.1967 - acc: 0.1812 - val_loss: 14.1891 - val_acc: 0.1193
Epoch 6/8
 - 4s - loss: 14.2698 - acc: 0.1147 - val_loss: 13.5965 - val_acc: 0.1560
Epoch 7/8
 - 7s - loss: 13.4989 - acc: 0.1625 - val_loss: 14.0341 - val_acc: 0.1284
Epoch 8/8
 - 7s - loss: 14.4922 - acc: 0.1009 - val_loss: 13.7464 - val_acc: 0.1468
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 12), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 12) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 12)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1984552572785443, 'base_model': 'MobileNet', 'zoom_range': 0.0407398762639929, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 13, 'height_shift_range': 0.24526274023440595, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8532110088325422, 'info': {'runtime': 59.65479779243469, 'histories': {'val_acc': [0.13761467924085233, 0.14678899150922758, 0.13761467924085233, 0.14678899150922758, 0.11926605695978217, 0.1559633034358331, 0.12844036888638768, 0.14678899116745783], 'loss': [11.332969195222201, 14.241330708542915, 12.995214557647705, 13.553853006073922, 13.196690654754638, 13.920173413825758, 13.498904800415039, 14.351728778995879], 'acc': [0.14383561643835616, 0.11643835616438356, 0.19375, 0.1590909090909091, 0.18125, 0.13636363636363635, 0.1625, 0.1095890410958904], 'val_loss': [13.900009365256773, 13.751897111945196, 13.892695111965914, 13.747188935586072, 14.189085356686093, 13.59652523600727, 14.034109535567257, 13.746418874198143]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 12)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 19)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 19) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 26) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 19) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 19)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.11015208910422, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.10175963795004203, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.23288763901072626, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:01:18.485645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 13s - loss: 12.2566 - acc: 0.1659 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 2/8
 - 7s - loss: 13.7809 - acc: 0.1450 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 3/8
 - 5s - loss: 14.3906 - acc: 0.1072 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 4/8
 - 5s - loss: 14.2890 - acc: 0.1135 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 5/8
 - 5s - loss: 13.1399 - acc: 0.1848 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 6/8
 - 5s - loss: 13.4761 - acc: 0.1639 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 7/8
 - 6s - loss: 13.8825 - acc: 0.1387 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 8/8
 - 5s - loss: 14.0858 - acc: 0.1261 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 19), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 19) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 19) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 19) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 19)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10175963795004203, 'base_model': 'MobileNet', 'zoom_range': 0.11015208910422, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.23288763901072626, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853204173779, 'info': {'runtime': 58.53731942176819, 'histories': {'val_acc': [0.1559633034358331, 0.13761467924085233, 0.11926605538764132, 0.14678899150922758, 0.13761467924085233, 0.1559633034358331, 0.12844036765601657, 0.13761467958262208], 'loss': [12.619334756511531, 13.578943435459921, 14.24133081305517, 14.130932951626713, 13.57894327869154, 13.247749642150042, 13.689341505912886, 13.91013701974529], 'acc': [0.136986301369863, 0.15753424657534246, 0.11643835616438356, 0.1232876712328767, 0.15753424657534246, 0.1780821917808219, 0.1506849315068493, 0.136986301369863], 'val_loss': [13.604264381828658, 13.900009085278992, 14.19575370123627, 13.752136606688893, 13.900009085278992, 13.604264381828658, 14.047881336387144, 13.90000911152691]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 19)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 26)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 26) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 26) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 26) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 26)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24267164938303276, 'rotation_range': 5, 'optimizer': 'RMSProp', 'width_shift_range': 0.27037026875639975, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.110180090036293, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:02:16.503531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 14s - loss: 13.3957 - acc: 0.0687 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/8
 - 5s - loss: 14.2576 - acc: 0.1154 - val_loss: 15.2309 - val_acc: 0.0550
Epoch 3/8
 - 5s - loss: 15.1940 - acc: 0.0573 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 4/8
 - 6s - loss: 14.4055 - acc: 0.1062 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 5/8
 - 6s - loss: 13.9528 - acc: 0.1343 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 6/8
 - 4s - loss: 14.1172 - acc: 0.1241 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 7/8
 - 5s - loss: 14.7078 - acc: 0.0875 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 8/8
 - 4s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 26), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 26) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 26) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 26) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 26)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.27037026875639975, 'base_model': 'MobileNet', 'zoom_range': 0.24267164938303276, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 5, 'height_shift_range': 0.110180090036293, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.9174311923187807, 'info': {'runtime': 54.58352279663086, 'histories': {'val_acc': [0.10091743187620006, 0.05504587155963303, 0.09174311994959455, 0.11926605695978217, 0.06422018348623854, 0.11009174346103581, 0.10091743310657117, 0.0825688076812193], 'loss': [13.3956862449646, 14.79332017245358, 15.019134174693715, 14.405547714233398, 14.462126692680464, 15.263347741329309, 14.70776195526123, 14.46212674493659], 'acc': [0.06875, 0.0821917808219178, 0.06818181818181818, 0.10625, 0.10273972602739725, 0.05303030303030303, 0.0875, 0.10273972602739725], 'val_loss': [14.491498177204656, 15.230860368921123, 14.639370795783647, 14.195753587495297, 15.082988144060888, 14.343625926096506, 14.49149859717133, 14.787243160632773]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 26)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.13070844626277076, 'rotation_range': 11, 'optimizer': 'RMSProp', 'width_shift_range': 0.28809388168018457, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.07922358039346385, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:03:11.702008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/8
 - 10s - loss: 13.0856 - acc: 0.0883 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/8
 - 5s - loss: 13.4447 - acc: 0.1659 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 3/8
 - 5s - loss: 14.2890 - acc: 0.1135 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 4/8
 - 5s - loss: 13.0382 - acc: 0.1911 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 5/8
 - 5s - loss: 13.9528 - acc: 0.1343 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 6/8
 - 5s - loss: 14.8987 - acc: 0.0757 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 7/8
 - 5s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 8/8
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 2)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.28809388168018457, 'base_model': 'MobileNet', 'zoom_range': 0.13070844626277076, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 11, 'height_shift_range': 0.07922358039346385, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825684655697, 'info': {'runtime': 52.4299955368042, 'histories': {'val_acc': [0.0825688076812193, 0.0825688076812193, 0.11009174311926606, 0.11926605572941107, 0.11926605538764132, 0.0917431196078248, 0.11926605538764132, 0.10091743153443031], 'loss': [14.023861999381078, 13.910136967489164, 14.130932951626713, 13.468545521775336, 14.462126588168209, 14.793320224709706, 14.572524345084412, 14.572524501852794], 'acc': [0.0958904109589041, 0.136986301369863, 0.1232876712328767, 0.1643835616438356, 0.10273972602739725, 0.0821917808219178, 0.0958904109589041, 0.0958904109589041], 'val_loss': [14.787243274373745, 14.787243160632773, 14.34362617982637, 14.195753561247379, 14.19575370123627, 14.639370769535729, 14.19575370123627, 14.491498430934522]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.14703694115643196, 'rotation_range': 12, 'optimizer': 'RMSProp', 'width_shift_range': 0.12498631192332765, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11771351816088055, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:04:03.602766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 10s - loss: 12.9870 - acc: 0.1135 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 2/4
 - 5s - loss: 13.4989 - acc: 0.1625 - val_loss: 13.4564 - val_acc: 0.1651
Epoch 3/4
 - 4s - loss: 14.4752 - acc: 0.1019 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 4/4
 - 6s - loss: 13.3982 - acc: 0.1687 - val_loss: 13.9000 - val_acc: 0.1376
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 2)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.12498631192332765, 'base_model': 'MobileNet', 'zoom_range': 0.14703694115643196, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 12, 'height_shift_range': 0.11771351816088055, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8623853204173779, 'info': {'runtime': 32.6763482093811, 'histories': {'val_acc': [0.1376146808129932, 0.1651376165928097, 0.14678899116745783, 0.13761467958262208], 'loss': [12.716408768745318, 13.498904991149903, 14.164386980461352, 13.39816665649414], 'acc': [0.1232876712328767, 0.1625, 0.12121212121212122, 0.16875], 'val_loss': [13.900009137774827, 13.456391623260778, 13.752136300463196, 13.900008717808154]}}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 21) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.10340454376382442, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.20524188789474698, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1140943526997985, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:04:36.895819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/16
 - 11s - loss: 12.9206 - acc: 0.1009 - val_loss: 3.0534 - val_acc: 0.1743
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 2/16
 - 4s - loss: 2.8507 - acc: 0.0946 - val_loss: 2.0539 - val_acc: 0.2936
Epoch 3/16
 - 6s - loss: 2.1959 - acc: 0.2375 - val_loss: 1.9200 - val_acc: 0.4404
Epoch 4/16
 - 4s - loss: 2.0603 - acc: 0.3280 - val_loss: 1.6069 - val_acc: 0.5321
Epoch 5/16
 - 5s - loss: 1.7360 - acc: 0.4413 - val_loss: 2.7731 - val_acc: 0.2110
Epoch 6/16
 - 6s - loss: 1.4632 - acc: 0.5312 - val_loss: 1.0473 - val_acc: 0.5963
Epoch 7/16
 - 5s - loss: 1.8151 - acc: 0.3972 - val_loss: 1.0365 - val_acc: 0.7064
Epoch 8/16
 - 4s - loss: 1.2446 - acc: 0.6241 - val_loss: 2.0513 - val_acc: 0.5413
Epoch 9/16
 - 5s - loss: 1.5612 - acc: 0.4981 - val_loss: 1.0642 - val_acc: 0.6422
Epoch 10/16
 - 4s - loss: 0.7257 - acc: 0.7667 - val_loss: 0.7886 - val_acc: 0.7798
Epoch 11/16
 - 5s - loss: 1.0589 - acc: 0.6954 - val_loss: 1.0879 - val_acc: 0.6881
Epoch 12/16
 - 5s - loss: 0.5273 - acc: 0.8026 - val_loss: 4.4799 - val_acc: 0.3945
Epoch 13/16
 - 5s - loss: 1.9934 - acc: 0.6188 - val_loss: 1.3586 - val_acc: 0.6055
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 14/16
 - 4s - loss: 0.6972 - acc: 0.7961 - val_loss: 1.1830 - val_acc: 0.6606
Epoch 15/16
 - 5s - loss: 0.7778 - acc: 0.7688 - val_loss: 1.2109 - val_acc: 0.6697
Epoch 16/16
 - 4s - loss: 0.9280 - acc: 0.6975 - val_loss: 1.5521 - val_acc: 0.6422
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 9)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.20524188789474698, 'base_model': 'MobileNet', 'zoom_range': 0.10340454376382442, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.1140943526997985, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.35779816240345663, 'info': {'runtime': 91.4387137889862, 'histories': {'val_acc': [0.1743119285194152, 0.29357798356528675, 0.44036697384414325, 0.5321100944772773, 0.21100917622583723, 0.5963302850723267, 0.7064220205359503, 0.541284407497546, 0.642201838143375, 0.7798165225107735, 0.6880733966827393, 0.3944954172186895, 0.6055045904369529, 0.6605504685585651, 0.6697247728295282, 0.6422018375965434], 'loss': [12.683544955841482, 2.93152098786341, 2.195924472808838, 2.0433410153244482, 1.6719060140113309, 1.4631686985492707, 1.7246929652070346, 1.0084281457613593, 1.4344177344073987, 0.7466463916105767, 0.9612525031991201, 0.5299810538553211, 1.9934205740690232, 0.7398491844986425, 0.7778134122490883, 0.7120929017211451], 'acc': [0.1095890410958904, 0.10273972602739725, 0.2375, 0.29545454545454547, 0.4794520547945205, 0.53125, 0.4315068493150685, 0.678082191780822, 0.541095890410959, 0.7465753424657534, 0.7123287671232876, 0.8287671232876712, 0.61875, 0.7575757575757576, 0.76875, 0.7348484848484849], 'val_loss': [3.053377886430933, 2.053873591466781, 1.919997024973598, 1.6069283594778918, 2.773062307900245, 1.0473274200334461, 1.0365001695965408, 2.051324048173537, 1.0642216139977132, 0.7885759467378669, 1.087893180344083, 4.479854334385023, 1.3586416135140515, 1.1830438528585872, 1.2109056415907833, 1.5521171399212759]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 21)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 21) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 14) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 21) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 21)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.03218892286583146, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.21629165317056206, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.07816227044651974, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:06:07.814227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/16
 - 10s - loss: 13.6534 - acc: 0.0757 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 2/16
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 3/16
 - 4s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 4/16
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 5/16
 - 5s - loss: 14.3906 - acc: 0.1072 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 6/16
 - 5s - loss: 15.0100 - acc: 0.0687 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 7/16
 - 5s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.6394 - val_acc: 0.0917
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 8/16
 - 5s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 9/16
 - 4s - loss: 14.8859 - acc: 0.0764 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 10/16
 - 5s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 11/16
 - 4s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 12/16
 - 5s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 13/16
 - 5s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 14/16
 - 5s - loss: 14.2041 - acc: 0.1187 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 15/16
 - 5s - loss: 14.2576 - acc: 0.1154 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 16/16
 - 4s - loss: 14.8859 - acc: 0.0764 - val_loss: 14.7872 - val_acc: 0.0826
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 21), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 21) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 21) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 21)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21629165317056206, 'base_model': 'MobileNet', 'zoom_range': 0.03218892286583146, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.07816227044651974, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.917431191977011, 'info': {'runtime': 89.07286548614502, 'histories': {'val_acc': [0.12844036731424682, 0.11009174380280556, 0.10091743119266056, 0.07339449575461379, 0.0825688076812193, 0.11009174380280556, 0.09174311994959455, 0.09174311926605505, 0.08256880802298905, 0.11009174346103581, 0.0825688076812193, 0.0825688076812193, 0.07339449575461379, 0.10091743187620006, 0.09174311926605505, 0.08256880802298905], 'loss': [13.440382029912243, 14.572524606365047, 14.572524292828286, 14.572524397340539, 14.241330708542915, 15.009976291656494, 14.572524449596667, 14.903718190650418, 14.652813882538766, 14.506285762786865, 14.572524397340539, 14.462126535912082, 14.351728674483626, 14.204071521759033, 14.793320276965833, 14.652813882538766], 'acc': [0.0821917808219178, 0.0958904109589041, 0.0958904109589041, 0.0958904109589041, 0.11643835616438356, 0.06875, 0.0958904109589041, 0.07534246575342465, 0.09090909090909091, 0.1, 0.0958904109589041, 0.10273972602739725, 0.1095890410958904, 0.11875, 0.0821917808219178, 0.09090909090909091], 'val_loss': [14.047881310139227, 14.343625786107614, 14.491498684664386, 14.935115945448569, 14.787243274373745, 14.343625672366642, 14.639370962020454, 14.63937090952462, 14.787243300621663, 14.343625926096506, 14.787242994395966, 14.787243160632773, 14.935115779211761, 14.491498177204656, 14.63937090952462, 14.787243186880689]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 21)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 14)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 14) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 12) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 14)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.054949645659345354, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.26716847752572814, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2796118284202028, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:07:37.504902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/16
 - 10s - loss: 13.4336 - acc: 0.1072 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 2/16
 - 4s - loss: 13.3117 - acc: 0.1741 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 3/16
 - 5s - loss: 13.2101 - acc: 0.1804 - val_loss: 14.9351 - val_acc: 0.0734
Epoch 4/16
 - 5s - loss: 13.5463 - acc: 0.1596 - val_loss: 15.0830 - val_acc: 0.0642
Epoch 5/16
 - 5s - loss: 15.0003 - acc: 0.0693 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 6/16
 - 5s - loss: 14.4055 - acc: 0.1062 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 7/16
 - 5s - loss: 13.8512 - acc: 0.1406 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 8/16
 - 5s - loss: 13.7496 - acc: 0.1469 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 9/16
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 10/16
 - 4s - loss: 14.5779 - acc: 0.0956 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 11/16
 - 5s - loss: 14.4055 - acc: 0.1062 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 12/16
 - 4s - loss: 13.9528 - acc: 0.1343 - val_loss: 14.4915 - val_acc: 0.1009
Epoch 13/16
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 14/16
 - 5s - loss: 14.3906 - acc: 0.1072 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 15/16
 - 5s - loss: 13.1085 - acc: 0.1867 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 16/16
 - 5s - loss: 14.6070 - acc: 0.0938 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 14), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 14) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 14)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.26716847752572814, 'base_model': 'MobileNet', 'zoom_range': 0.054949645659345354, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.2796118284202028, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8990825684655697, 'info': {'runtime': 91.92709040641785, 'histories': {'val_acc': [0.10091743153443031, 0.11926605504587157, 0.07339449541284404, 0.06422018416977804, 0.11009174503317666, 0.0917431196078248, 0.09174311994959455, 0.11009174346103581, 0.10091743153443031, 0.0825688076812193, 0.08256880733944955, 0.10091743153443031, 0.10091743187620006, 0.13761468327373538, 0.12844036731424682, 0.10091743153443031], 'loss': [13.201581066601896, 14.462126433032832, 14.351728676116629, 14.020535037942128, 14.90371798162591, 14.40554780960083, 14.351728726739752, 14.241330760799043, 14.572524397340539, 14.286493705980705, 14.405547714233398, 14.462126588168209, 14.682922467793503, 14.241331022079677, 14.241330814688173, 14.607023811340332], 'acc': [0.11643835616438356, 0.10273972602739725, 0.1095890410958904, 0.13013698630136986, 0.07534246575342465, 0.10625, 0.1095890410958904, 0.11643835616438356, 0.0958904109589041, 0.11363636363636363, 0.10625, 0.10273972602739725, 0.08904109589041095, 0.11643835616438356, 0.11643835616438356, 0.09375], 'val_loss': [14.491498544675494, 14.195753954966134, 14.935115639222872, 15.082988476534503, 14.343626092333313, 14.639370769535729, 14.639370515805865, 14.343626206074285, 14.49149815095674, 14.787243160632773, 14.787243134384855, 14.491498264697714, 14.491498570923412, 13.90000846407829, 14.047880916420473, 14.49149815095674]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 14)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 12)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 12) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 12)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0407398762639929, 'rotation_range': 13, 'optimizer': 'RMSProp', 'width_shift_range': 0.1984552572785443, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.24526274023440595, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:09:08.893326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/16
 - 10s - loss: 13.2693 - acc: 0.0946 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 2/16
 - 5s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 3/16
 - 5s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 4/16
 - 4s - loss: 14.5939 - acc: 0.0946 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 5/16
 - 5s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 6/16
 - 5s - loss: 14.5063 - acc: 0.1000 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 7/16
 - 4s - loss: 14.3906 - acc: 0.1072 - val_loss: 14.4915 - val_acc: 0.1009
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 8/16
 - 4s - loss: 13.7496 - acc: 0.1469 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 9/16
 - 5s - loss: 14.3906 - acc: 0.1072 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 10/16
 - 5s - loss: 13.7496 - acc: 0.1469 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 11/16
 - 5s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 12/16
 - 6s - loss: 14.4922 - acc: 0.1009 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 13/16
 - 5s - loss: 14.0544 - acc: 0.1280 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 14/16
 - 5s - loss: 14.1033 - acc: 0.1250 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 15/16
 - 5s - loss: 14.3906 - acc: 0.1072 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 16/16
 - 4s - loss: 13.3984 - acc: 0.1687 - val_loss: 14.3436 - val_acc: 0.1101
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 12), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 12) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 12)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1984552572785443, 'base_model': 'MobileNet', 'zoom_range': 0.0407398762639929, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 13, 'height_shift_range': 0.24526274023440595, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8899082561971945, 'info': {'runtime': 88.92958235740662, 'histories': {'val_acc': [0.11926605538764132, 0.11009174346103581, 0.11009174380280556, 0.12844036765601657, 0.11009174346103581, 0.13761467924085233, 0.10091743255973956, 0.12844036888638768, 0.1376146808129932, 0.11009174311926606, 0.12844036731424682, 0.11926605572941107, 0.11926605572941107, 0.12844036731424682, 0.12844036765601657, 0.11009174380280556], 'loss': [13.02312161171273, 14.351728569971373, 14.68292236328125, 14.462126535912082, 14.351728674483626, 14.506285667419434, 14.24133081305517, 14.241330551774535, 14.24133081305517, 14.241330865311296, 14.351728674483626, 14.351728778995879, 14.572524345084412, 14.103333568572998, 14.24133081305517, 14.408600315903172], 'acc': [0.10273972602739725, 0.1095890410958904, 0.08904109589041095, 0.10273972602739725, 0.1095890410958904, 0.1, 0.11643835616438356, 0.11643835616438356, 0.11643835616438356, 0.11643835616438356, 0.1095890410958904, 0.1095890410958904, 0.0958904109589041, 0.125, 0.11643835616438356, 0.10606060606060606], 'val_loss': [14.19575370123627, 14.343625926096506, 14.343626232322203, 14.047881336387144, 14.34362631981526, 13.900008805301212, 14.491498177204656, 14.047880802679499, 13.900008577819264, 14.34362645980415, 14.047881590117008, 14.19575384122516, 14.195753447506405, 14.04788187009479, 14.047881336387144, 14.343626066085395]}}}
exception: None

DEBUG:hpbandster:job_callback for (1, 0, 12)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 3) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 3)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06936853429270425, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.29450179086895434, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.15365940175518866, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:10:38.462430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/4
 - 12s - loss: 13.4299 - acc: 0.0938 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 2/4
 - 4s - loss: 14.8859 - acc: 0.0764 - val_loss: 14.7872 - val_acc: 0.0826
Epoch 3/4
 - 5s - loss: 14.6955 - acc: 0.0883 - val_loss: 14.6394 - val_acc: 0.0917
Epoch 4/4
 - 4s - loss: 14.7971 - acc: 0.0820 - val_loss: 14.1958 - val_acc: 0.1193
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 3), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 3)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.29450179086895434, 'base_model': 'MobileNet', 'zoom_range': 0.06936853429270425, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.15365940175518866, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: {'loss': 0.8807339446123587, 'info': {'runtime': 32.96678018569946, 'histories': {'val_acc': [0.08256880733944955, 0.08256880925336016, 0.09174311994959455, 0.11926605538764132], 'loss': [13.429860925674438, 14.652813882538766, 14.572524606365047, 14.682922467793503], 'acc': [0.09375, 0.09090909090909091, 0.0958904109589041, 0.08904109589041095], 'val_loss': [14.787243414362637, 14.78724360684736, 14.639370795783647, 14.195753814977243]}}}
exception: None

DEBUG:hpbandster:job_callback for (2, 0, 3)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 0, 12) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (1, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.10340454376382442, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.20524188789474698, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1140943526997985, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:11:10.875172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
training model MobileNet
old directory removed data/model_train
old directory removed data/model_valid
copy 34 images for whale # 1, called w_1287fbc
copy 27 images for whale # 2, called w_98baff9
copy 26 images for whale # 3, called w_7554f44
copy 23 images for whale # 4, called w_1eafe46
copy 22 images for whale # 5, called w_693c9ee
copy 22 images for whale # 6, called w_ab4cae2
copy 22 images for whale # 7, called w_fd1cb9d
copy 21 images for whale # 8, called w_43be268
copy 21 images for whale # 9, called w_73d5489
copy 21 images for whale # 10, called w_987a36f
239  images of  10  whales copied in total
Target Directory train:  data/model_train  validation:  data/model_valid
162  images copied as training data
77  images copied as validation data
Found 162 images belonging to 10 classes.
Found 77 images belonging to 10 classes.
Epoch 1/20
 - 11s - loss: 12.4604 - acc: 0.1576 - val_loss: 14.1958 - val_acc: 0.1193
Epoch 2/20
 - 4s - loss: 13.6793 - acc: 0.1513 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 3/20
 - 4s - loss: 14.3906 - acc: 0.1072 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 4/20
 - 4s - loss: 13.3431 - acc: 0.1722 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 5/20
 - 5s - loss: 13.4989 - acc: 0.1625 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 6/20
 - 4s - loss: 13.5463 - acc: 0.1596 - val_loss: 13.7521 - val_acc: 0.1468
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 7/20
 - 5s - loss: 13.1399 - acc: 0.1848 - val_loss: 13.4564 - val_acc: 0.1651
Epoch 8/20
 - 4s - loss: 12.8850 - acc: 0.2006 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 9/20
 - 5s - loss: 13.8011 - acc: 0.1438 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 10/20
 - 5s - loss: 12.6797 - acc: 0.2133 - val_loss: 13.4564 - val_acc: 0.1651
Epoch 11/20
 - 5s - loss: 13.8011 - acc: 0.1438 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 12/20
 - 4s - loss: 13.6793 - acc: 0.1513 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 13/20
 - 5s - loss: 13.1399 - acc: 0.1848 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 14/20
 - 4s - loss: 14.1874 - acc: 0.1198 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 15/20
 - 4s - loss: 14.1874 - acc: 0.1198 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 16/20
 - 7s - loss: 13.8011 - acc: 0.1438 - val_loss: 14.3436 - val_acc: 0.1101
Epoch 17/20
 - 4s - loss: 14.4922 - acc: 0.1009 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 18/20
 - 5s - loss: 13.0382 - acc: 0.1911 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 19/20
 - 4s - loss: 12.8350 - acc: 0.2037 - val_loss: 13.7521 - val_acc: 0.1468
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
Epoch 20/20
 - 5s - loss: 14.0858 - acc: 0.1261 - val_loss: 14.0479 - val_acc: 0.1284
{'base_model': 'MobileNet', 'zoom_range': 0.10340454376382442, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.20524188789474698, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1140943526997985, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}

 ****** MobileNet unfrozen 2 top blocks, cut_off after layer 75 ******
Epoch 1/12
 - 8s - loss: 14.0858 - acc: 0.1261 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 2/12
 - 5s - loss: 13.8011 - acc: 0.1438 - val_loss: 14.0479 - val_acc: 0.1284
Epoch 3/12
 - 4s - loss: 13.7564 - acc: 0.1465 - val_loss: 13.9000 - val_acc: 0.1376
Epoch 4/12
 - 5s - loss: 13.9842 - acc: 0.1324 - val_loss: 13.4564 - val_acc: 0.1651
Epoch 5/12
 - 4s - loss: 13.9842 - acc: 0.1324 - val_loss: 13.4564 - val_acc: 0.1651
Epoch 6/12
 - 5s - loss: 13.3982 - acc: 0.1687 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 7/12
 - 4s - loss: 13.1931 - acc: 0.1815 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 8/12
 - 5s - loss: 14.1874 - acc: 0.1198 - val_loss: 13.7521 - val_acc: 0.1468
Epoch 9/12
 - 5s - loss: 13.9019 - acc: 0.1375 - val_loss: 13.6043 - val_acc: 0.1560
Epoch 10/12
 - 5s - loss: 13.4447 - acc: 0.1659 - val_loss: 13.7521 - val_acc: 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 0, 12), trying to register it.
--- Logging error ---
Traceback (most recent call last):
  File "/usr/lib/python3.5/logging/__init__.py", line 984, in emit
    self.flush()
  File "/usr/lib/python3.5/logging/__init__.py", line 964, in flush
    self.stream.flush()
OSError: [Errno 122] Disk quota exceeded
Call stack:
  File "/usr/lib/python3.5/threading.py", line 882, in _bootstrap
    self._bootstrap_inner()
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/Pyro4-4.70-py3.5.egg/Pyro4/core.py", line 1886, in run
    super(_OnewayCallThread, self).run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 112, in start_computation
    self.logger.debug('WORKER: done with job %s, trying to register it.'%str(id))
Message: 'WORKER: done with job (1, 0, 12), trying to register it.'
Arguments: ()
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 0, 12) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 0, 12)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1984552572785443, 'base_model': 'MobileNet', 'zoom_range': 0.0407398762639929, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 13, 'height_shift_range': 0.24526274023440595, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 513, in get
    inputs = self.queue.get(block=True).get()
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 608, in get
    raise self._value
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 379, in get_index
    return ds[i]
  File "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py", line 759, in __getitem__
    return self._get_batches_of_transformed_samples(index_array)
  File "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py", line 1109, in _get_batches_of_transformed_samples
    img.save(os.path.join(self.save_to_dir, fname))
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/PIL/Image.py", line 1934, in save
    fp.close()
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 250, in train
    epochs=training_epochs_dense)
  File "/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py", line 87, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py", line 2046, in fit_generator
    generator_output = next(output_generator)
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 518, in get
    raise StopIteration(e)
StopIteration: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (1, 0, 12)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (1, 0, 12) failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 513, in get
    inputs = self.queue.get(block=True).get()
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 608, in get
    raise self._value
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 379, in get_index
    return ds[i]
  File "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py", line 759, in __getitem__
    return self._get_batches_of_transformed_samples(index_array)
  File "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py", line 1109, in _get_batches_of_transformed_samples
    img.save(os.path.join(self.save_to_dir, fname))
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/PIL/Image.py", line 1934, in save
    fp.close()
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 250, in train
    epochs=training_epochs_dense)
  File "/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py", line 87, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py", line 2046, in fit_generator
    generator_output = next(output_generator)
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 518, in get
    raise StopIteration(e)
StopIteration: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 4)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 4) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 1
DEBUG:hpbandster:HBMASTER: submitting job (1, 5, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 4) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 4) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 4)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0617473775717515, 'rotation_range': 10, 'optimizer': 'RMSProp', 'width_shift_range': 0.21554881877121734, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.18467046248942345, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:05.145932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 4), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 4) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 4) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 4)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21554881877121734, 'base_model': 'MobileNet', 'zoom_range': 0.0617473775717515, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 10, 'height_shift_range': 0.18467046248942345, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 513, in get
    inputs = self.queue.get(block=True).get()
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 608, in get
    raise self._value
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 379, in get_index
    return ds[i]
  File "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py", line 759, in __getitem__
    return self._get_batches_of_transformed_samples(index_array)
  File "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py", line 1109, in _get_batches_of_transformed_samples
    img.save(os.path.join(self.save_to_dir, fname))
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/PIL/Image.py", line 1934, in save
    fp.close()
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 250, in train
    epochs=training_epochs_dense)
  File "/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py", line 87, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py", line 2046, in fit_generator
    generator_output = next(output_generator)
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 518, in get
    raise StopIteration(e)
StopIteration: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 4)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 4) failed with exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 513, in get
    inputs = self.queue.get(block=True).get()
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 608, in get
    raise self._value
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 379, in get_index
    return ds[i]
  File "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py", line 759, in __getitem__
    return self._get_batches_of_transformed_samples(index_array)
  File "/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py", line 1109, in _get_batches_of_transformed_samples
    img.save(os.path.join(self.save_to_dir, fname))
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/PIL/Image.py", line 1934, in save
    fp.close()
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 250, in train
    epochs=training_epochs_dense)
  File "/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py", line 87, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py", line 2046, in fit_generator
    generator_output = next(output_generator)
  File "/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py", line 518, in get
    raise StopIteration(e)
StopIteration: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (1, 5, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (1, 5, 0) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (1, 5, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 5) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (1, 5, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (1, 5, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.056517758480323595, 'rotation_range': 0, 'optimizer': 'RMSProp', 'width_shift_range': 0.13080562214803976, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2636398195515913, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:14.504864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (1, 5, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (1, 5, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (1, 5, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (1, 5, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (1, 5, 0)
args: ()
kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'width_shift_range': 0.13080562214803976, 'base_model': 'MobileNet', 'zoom_range': 0.056517758480323595, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 0, 'height_shift_range': 0.2636398195515913, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (1, 5, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (1, 5, 0) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 5)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 5) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 6) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 5) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 5) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 5)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2761406682742516, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.2077862968504915, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.03383033114684335, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:18.141476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 5), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 5) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 5) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 5) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 5)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2077862968504915, 'base_model': 'MobileNet', 'zoom_range': 0.2761406682742516, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.03383033114684335, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 5)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 5) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 6)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 6) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 6) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 6) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 6)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.00042302996187398856, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.13267718282014118, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.09159655338002111, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:22.249176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 6), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 6) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 6) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 6) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 6)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.13267718282014118, 'base_model': 'MobileNet', 'zoom_range': 0.00042302996187398856, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.09159655338002111, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 6)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 6) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 7)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 8) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 7) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 7)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2881862195297734, 'rotation_range': 3, 'optimizer': 'RMSProp', 'width_shift_range': 0.13613282339292856, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.17248467157596692, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:25.823977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 7), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 7)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.13613282339292856, 'base_model': 'MobileNet', 'zoom_range': 0.2881862195297734, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 3, 'height_shift_range': 0.17248467157596692, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 7)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 7) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 8)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 8) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 9) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 8) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 8) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 8)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.22094796554592433, 'rotation_range': 24, 'optimizer': 'RMSProp', 'width_shift_range': 0.1441443726329278, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.04936557032826067, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:30.382052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 8), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 8) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 8) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 8) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 8)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1441443726329278, 'base_model': 'MobileNet', 'zoom_range': 0.22094796554592433, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 24, 'height_shift_range': 0.04936557032826067, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 8)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 8) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 9)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 9) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 10) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 9) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 9)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2917800692411725, 'rotation_range': 7, 'optimizer': 'RMSProp', 'width_shift_range': 0.2022406574612013, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.28785056788843627, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:34.633065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 9), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 9) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 9) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 9) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 9)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2022406574612013, 'base_model': 'MobileNet', 'zoom_range': 0.2917800692411725, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.28785056788843627, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 9)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 9) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 10)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 10) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 10) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 11) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 0, 10) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 10)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06151872055462221, 'rotation_range': 27, 'optimizer': 'RMSProp', 'width_shift_range': 0.2195965173588055, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2379830624223403, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:38.044002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 10), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 10) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 10) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 10) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 10)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2195965173588055, 'base_model': 'MobileNet', 'zoom_range': 0.06151872055462221, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 27, 'height_shift_range': 0.2379830624223403, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 10)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 10) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 11)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 11) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 11) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 12) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 0, 11) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 11)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.13874607434596803, 'rotation_range': 28, 'optimizer': 'RMSProp', 'width_shift_range': 0.044067790681413664, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.22561365004784384, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:42.398108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 11), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 11) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 11) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 11) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 11)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.044067790681413664, 'base_model': 'MobileNet', 'zoom_range': 0.13874607434596803, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.22561365004784384, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 11)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 11) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 12)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 12) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 13) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 0, 12) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 12)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.28401265221792277, 'rotation_range': 18, 'optimizer': 'RMSProp', 'width_shift_range': 0.09714374215622408, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.0675097803114198, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:46.022124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 12), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 12) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 12) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 12) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 12)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.09714374215622408, 'base_model': 'MobileNet', 'zoom_range': 0.28401265221792277, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 18, 'height_shift_range': 0.0675097803114198, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 12)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 12) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 13)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 13) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 13) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 14) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 0, 13) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 13)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.16824106972110314, 'rotation_range': 2, 'optimizer': 'RMSProp', 'width_shift_range': 0.008218159512905231, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.0456555035482098, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:50.314758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 13), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 13) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 13) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 13) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 13)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.008218159512905231, 'base_model': 'MobileNet', 'zoom_range': 0.16824106972110314, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 2, 'height_shift_range': 0.0456555035482098, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 13)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 13) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 14)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 14) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 15) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 0, 14) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 14)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.09702949823012472, 'rotation_range': 13, 'optimizer': 'RMSProp', 'width_shift_range': 0.09583156760033221, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.03733918063952805, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:55.043558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 14), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 14) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 14) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 14) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 14)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.09583156760033221, 'base_model': 'MobileNet', 'zoom_range': 0.09702949823012472, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 13, 'height_shift_range': 0.03733918063952805, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 14)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 14) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 15)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 15) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 15) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 3
DEBUG:hpbandster:HBMASTER: submitting job (3, 0, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 0, 15) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 15)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2767051311421287, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.21945283641105087, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.013112520848041098, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:14:59.573090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 15), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 15) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 15) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 15) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 15)
args: ()
kwargs: {'budget': 4.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21945283641105087, 'base_model': 'MobileNet', 'zoom_range': 0.2767051311421287, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.013112520848041098, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 15)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 15) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (3, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (3, 0, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (3, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (3, 0, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (3, 0, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1597626789483336, 'rotation_range': 26, 'optimizer': 'RMSProp', 'width_shift_range': 0.05094321342231889, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1335726346446268, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:15:04.981776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (3, 0, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (3, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (3, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (3, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (3, 0, 0)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.05094321342231889, 'base_model': 'MobileNet', 'zoom_range': 0.1597626789483336, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 26, 'height_shift_range': 0.1335726346446268, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (3, 0, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (3, 0, 0) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 3)
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 3) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 3)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06936853429270425, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.29450179086895434, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.15365940175518866, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:15:09.645386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 3), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 3)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.29450179086895434, 'base_model': 'MobileNet', 'zoom_range': 0.06936853429270425, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.15365940175518866, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 0, 3)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 0, 3) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 0, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 0, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 0, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.14703694115643196, 'rotation_range': 12, 'optimizer': 'RMSProp', 'width_shift_range': 0.12498631192332765, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11771351816088055, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:15:14.214592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 0, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 0, 2)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.12498631192332765, 'base_model': 'MobileNet', 'zoom_range': 0.14703694115643196, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 12, 'height_shift_range': 0.11771351816088055, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py",                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 1, 5), trying to register it.
--- Logging error ---
Traceback (most recent call last):
  File "/usr/lib/python3.5/logging/__init__.py", line 984, in emit
    self.flush()
  File "/usr/lib/python3.5/logging/__init__.py", line 964, in flush
    self.stream.flush()
OSError: [Errno 122] Disk quota exceeded
Call stack:
  File "/usr/lib/python3.5/threading.py", line 882, in _bootstrap
    self._bootstrap_inner()
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/Pyro4-4.70-py3.5.egg/Pyro4/core.py", line 1886, in run
    super(_OnewayCallThread, self).run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 112, in start_computation
    self.logger.debug('WORKER: done with job %s, trying to register it.'%str(id))
Message: 'WORKER: done with job (2, 1, 5), trying to register it.'
Arguments: ()
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 1, 5) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 1, 5) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 1, 5) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 1, 5)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.12616770144138464, 'base_model': 'MobileNet', 'zoom_range': 0.1053409913788102, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 28, 'height_shift_range': 0.034722053022636236, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 1, 5)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 1, 5) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 1, 6)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 1, 6) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 1, 6) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 1, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 1, 6) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 1, 6)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.01808777033223905, 'rotation_range': 27, 'optimizer': 'RMSProp', 'width_shift_range': 0.045584397619569006, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.12682266707185239, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:15:35.732642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 1, 6), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 1, 6) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 1, 6) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 1, 6) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 1, 6)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.045584397619569006, 'base_model': 'MobileNet', 'zoom_range': 0.01808777033223905, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 27, 'height_shift_range': 0.12682266707185239, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 1, 6)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 1, 6) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 1, 7)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 1, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 3
DEBUG:hpbandster:HBMASTER: submitting job (3, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 1, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 1, 7) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 1, 7)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2590063614813323, 'rotation_range': 21, 'optimizer': 'RMSProp', 'width_shift_range': 0.06781223817069323, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20249448060020186, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:15:39.304694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 1, 7), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 1, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 1, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 1, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 1, 7)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.06781223817069323, 'base_model': 'MobileNet', 'zoom_range': 0.2590063614813323, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 21, 'height_shift_range': 0.20249448060020186, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 1, 7)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 1, 7) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (3, 0, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (3, 0, 1) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (3, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 2, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (3, 0, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (3, 0, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.19343948314665188, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.1289821187729699, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.08479413306435352, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:15:44.162512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (3, 0, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (3, 0, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (3, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (3, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (3, 0, 1)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.1289821187729699, 'base_model': 'MobileNet', 'zoom_range': 0.19343948314665188, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.08479413306435352, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (3, 0, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (3, 0, 1) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 2, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 2, 0) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 2, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 2, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 2, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 2, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.07394209790527748, 'rotation_range': 5, 'optimizer': 'RMSProp', 'width_shift_range': 0.2792135178531667, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.1448482282614826, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:15:48.310696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 2, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 2, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 2, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 2, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 2, 0)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2792135178531667, 'base_model': 'MobileNet', 'zoom_range': 0.07394209790527748, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 5, 'height_shift_range': 0.1448482282614826, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 2, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 2, 0) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 2, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 2, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 2, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 2, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (2, 2, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 2, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1496794823158165, 'rotation_range': 16, 'optimizer': 'RMSProp', 'width_shift_range': 0.14737949780871581, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21431727191003946, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:15:52.409321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 2, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 2, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 2, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 2, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 2, 1)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.14737949780871581, 'base_model': 'MobileNet', 'zoom_range': 0.1496794823158165, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 16, 'height_shift_range': 0.21431727191003946, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 2, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 2, 1) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 2, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 2, 2) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 2, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 2
DEBUG:hpbandster:HBMASTER: submitting job (2, 2, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 2, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 2, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.20091134276247838, 'rotation_range': 8, 'optimizer': 'RMSProp', 'width_shift_range': 0.10010582613805649, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.19598768569809255, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:15:55.979882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 2, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 2, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 2, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 2, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 2, 2)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10010582613805649, 'base_model': 'MobileNet', 'zoom_range': 0.20091134276247838, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 8, 'height_shift_range': 0.19598768569809255, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (2, 2, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (2, 2, 2) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (2, 2, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (2, 2, 3) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (2, 2, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 3
DEBUG:hpbandster:HBMASTER: submitting job (3, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (2, 2, 3) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (2, 2, 3)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1979460963360255, 'rotation_range': 14, 'optimizer': 'RMSProp', 'width_shift_range': 0.11710588475022443, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.15574101823814648, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:16:00.979994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (2, 2, 3), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (2, 2, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (2, 2, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (2, 2, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (2, 2, 3)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.11710588475022443, 'base_model': 'MobileNet', 'zoom_range': 0.1979460963360255, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 14, 'height_shift_range': 0.15574101823814648, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (3, 0, 5), trying to register it.
--- Logging error ---
Traceback (most recent call last):
  File "/usr/lib/python3.5/logging/__init__.py", line 984, in emit
    self.flush()
  File "/usr/lib/python3.5/logging/__init__.py", line 964, in flush
    self.stream.flush()
OSError: [Errno 122] Disk quota exceeded
Call stack:
  File "/usr/lib/python3.5/threading.py", line 882, in _bootstrap
    self._bootstrap_inner()
  File "/usr/lib/python3.5/threading.py", line 914, in _bootstrap_inner
    self.run()
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/Pyro4-4.70-py3.5.egg/Pyro4/core.py", line 1886, in run
    super(_OnewayCallThread, self).run()
  File "/usr/lib/python3.5/threading.py", line 862, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 112, in start_computation
    self.logger.debug('WORKER: done with job %s, trying to register it.'%str(id))
Message: 'WORKER: done with job (3, 0, 5), trying to register it.'
Arguments: ()
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (3, 0, 5) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (3, 0, 5) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (3, 0, 5) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (3, 0, 5)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.12334521037619373, 'base_model': 'MobileNet', 'zoom_range': 0.22266327376959102, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 7, 'height_shift_range': 0.18164278135111836, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (3, 0, 5)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (3, 0, 5) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (3, 0, 6)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (3, 0, 6) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 3
DEBUG:hpbandster:HBMASTER: submitting job (3, 0, 7) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (3, 0, 6) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (3, 0, 6) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (3, 0, 6)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.20741442703534874, 'rotation_range': 12, 'optimizer': 'RMSProp', 'width_shift_range': 0.071905031306858, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.23543053829579255, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:16:36.285640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (3, 0, 6), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (3, 0, 6) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (3, 0, 6) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (3, 0, 6) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (3, 0, 6)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.071905031306858, 'base_model': 'MobileNet', 'zoom_range': 0.20741442703534874, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 12, 'height_shift_range': 0.23543053829579255, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (3, 0, 6)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (3, 0, 6) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (3, 0, 7)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (3, 0, 7) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 4
DEBUG:hpbandster:HBMASTER: submitting job (4, 0, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (3, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (3, 0, 7) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (3, 0, 7)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.20525456771967027, 'rotation_range': 16, 'optimizer': 'RMSProp', 'width_shift_range': 0.01037066622373084, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.17488474538089033, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:16:39.763464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (3, 0, 7), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (3, 0, 7) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (3, 0, 7) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (3, 0, 7) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (3, 0, 7)
args: ()
kwargs: {'budget': 8.0, 'working_directory': '.', 'config': {'width_shift_range': 0.01037066622373084, 'base_model': 'MobileNet', 'zoom_range': 0.20525456771967027, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 16, 'height_shift_range': 0.17488474538089033, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (3, 0, 7)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (3, 0, 7) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (4, 0, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (4, 0, 0) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (4, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 3
DEBUG:hpbandster:HBMASTER: submitting job (3, 1, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (4, 0, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (4, 0, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.07776500601259022, 'rotation_range': 27, 'optimizer': 'RMSProp', 'width_shift_range': 0.08199534017642779, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.05914304081159963, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:16:44.382166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (4, 0, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (4, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (4, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (4, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (4, 0, 0)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08199534017642779, 'base_model': 'MobileNet', 'zoom_range': 0.07776500601259022, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 27, 'height_shift_range': 0.05914304081159963, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (4, 0, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (4, 0, 0) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (3, 1, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (3, 1, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 3
DEBUG:hpbandster:HBMASTER: submitting job (3, 1, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (3, 1, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (3, 1, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (3, 1, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.22100052143538598, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.050723924975274504, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.053777830217916565, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:16:48.012945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (3, 1, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (3, 1, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (3, 1, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (3, 1, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (3, 1, 0)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.050723924975274504, 'base_model': 'MobileNet', 'zoom_range': 0.22100052143538598, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.053777830217916565, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (3, 1, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (3, 1, 0) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (3, 1, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (3, 1, 1) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (3, 1, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 3
DEBUG:hpbandster:HBMASTER: submitting job (3, 1, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (3, 1, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (3, 1, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.035599975381253465, 'rotation_range': 24, 'optimizer': 'RMSProp', 'width_shift_range': 0.08248055884784604, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.02990019767109999, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:16:52.533953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (3, 1, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (3, 1, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (3, 1, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (3, 1, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (3, 1, 1)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08248055884784604, 'base_model': 'MobileNet', 'zoom_range': 0.035599975381253465, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 24, 'height_shift_range': 0.02990019767109999, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (3, 1, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (3, 1, 1) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (3, 1, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (3, 1, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 3
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: submitting job (3, 1, 3) to dispatcher
DEBUG:hpbandster:DISPATCHER: starting job (3, 1, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (3, 1, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (3, 1, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.17630808042616875, 'rotation_range': 13, 'optimizer': 'RMSProp', 'width_shift_range': 0.21183417087627096, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.017212144983133813, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:16:56.109711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (3, 1, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (3, 1, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (3, 1, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (3, 1, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (3, 1, 2)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21183417087627096, 'base_model': 'MobileNet', 'zoom_range': 0.17630808042616875, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 13, 'height_shift_range': 0.017212144983133813, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (3, 1, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (3, 1, 2) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (3, 1, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (3, 1, 3) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (3, 1, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 4
DEBUG:hpbandster:HBMASTER: submitting job (4, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (3, 1, 3) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (3, 1, 3)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1876490365607206, 'rotation_range': 12, 'optimizer': 'RMSProp', 'width_shift_range': 0.023094742276554902, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.10492647656927502, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:16:59.562850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (3, 1, 3), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (3, 1, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (3, 1, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (3, 1, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (3, 1, 3)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.023094742276554902, 'base_model': 'MobileNet', 'zoom_range': 0.1876490365607206, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 12, 'height_shift_range': 0.10492647656927502, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_mode                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (4, 0, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (4, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (4, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (4, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (4, 0, 2)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.001567179492161941, 'base_model': 'MobileNet', 'zoom_range': 0.2937306214925229, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 8, 'height_shift_range': 0.22708064277713635, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (4, 0, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (4, 0, 2) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (3, 3, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (3, 3, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 4
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: submitting job (4, 0, 3) to dispatcher
DEBUG:hpbandster:DISPATCHER: starting job (3, 3, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (3, 3, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (3, 3, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.21517904308903668, 'rotation_range': 20, 'optimizer': 'RMSProp', 'width_shift_range': 0.10586424625216878, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21720042703710604, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:17:22.077608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (3, 3, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (3, 3, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (3, 3, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (3, 3, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (3, 3, 0)
args: ()
kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10586424625216878, 'base_model': 'MobileNet', 'zoom_range': 0.21517904308903668, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 20, 'height_shift_range': 0.21720042703710604, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (3, 3, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (3, 3, 0) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (4, 0, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (4, 0, 3) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (4, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 4
DEBUG:hpbandster:HBMASTER: submitting job (4, 0, 4) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (4, 0, 3) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (4, 0, 3)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.053227760111662824, 'rotation_range': 4, 'optimizer': 'RMSProp', 'width_shift_range': 0.19030767873027998, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.28877957006108657, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:17:25.948327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (4, 0, 3), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (4, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (4, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (4, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (4, 0, 3)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.19030767873027998, 'base_model': 'MobileNet', 'zoom_range': 0.053227760111662824, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 4, 'height_shift_range': 0.28877957006108657, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (4, 0, 3)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (4, 0, 3) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (4, 0, 4)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (4, 0, 4) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 4
DEBUG:hpbandster:HBMASTER: submitting job (4, 0, 5) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (4, 0, 4) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (4, 0, 4) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (4, 0, 4)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.06378491950893939, 'rotation_range': 19, 'optimizer': 'RMSProp', 'width_shift_range': 0.15625099505876158, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.23796475321542532, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:17:29.594140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (4, 0, 4), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (4, 0, 4) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (4, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (4, 0, 4) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (4, 0, 4)
args: ()
kwargs: {'budget': 16.0, 'working_directory': '.', 'config': {'width_shift_range': 0.15625099505876158, 'base_model': 'MobileNet', 'zoom_range': 0.06378491950893939, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 19, 'height_shift_range': 0.23796475321542532, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *a                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (5, 0, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (5, 0, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (5, 0, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (5, 0, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (5, 0, 0)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.21810589487375545, 'base_model': 'MobileNet', 'zoom_range': 0.2473740861894151, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 29, 'height_shift_range': 0.08285175219364911, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (5, 0, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (5, 0, 0) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (4, 1, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (4, 1, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 4
DEBUG:hpbandster:HBMASTER: submitting job (4, 1, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (4, 1, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (4, 1, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (4, 1, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.09947038743104775, 'rotation_range': 21, 'optimizer': 'RMSProp', 'width_shift_range': 0.04164811642753737, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.22005272837444262, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:17:52.348370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (4, 1, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (4, 1, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (4, 1, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (4, 1, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (4, 1, 0)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.04164811642753737, 'base_model': 'MobileNet', 'zoom_range': 0.09947038743104775, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 21, 'height_shift_range': 0.22005272837444262, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (4, 1, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (4, 1, 0) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (4, 1, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (4, 1, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 4
DEBUG:hpbandster:HBMASTER: submitting job (4, 1, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (4, 1, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (4, 1, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (4, 1, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.24713566653420607, 'rotation_range': 3, 'optimizer': 'RMSProp', 'width_shift_range': 0.15274755749880517, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.13055301532215766, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:17:57.049751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (4, 1, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (4, 1, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (4, 1, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (4, 1, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (4, 1, 1)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.15274755749880517, 'base_model': 'MobileNet', 'zoom_range': 0.24713566653420607, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 3, 'height_shift_range': 0.13055301532215766, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (4, 1, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (4, 1, 1) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (4, 1, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (4, 1, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 4
DEBUG:hpbandster:HBMASTER: submitting job (4, 1, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (4, 1, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (4, 1, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (4, 1, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.17491582007715592, 'rotation_range': 24, 'optimizer': 'RMSProp', 'width_shift_range': 0.23855232558591888, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.17900446279068127, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:18:01.004326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (4, 1, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (4, 1, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (4, 1, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (4, 1, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (4, 1, 2)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.23855232558591888, 'base_model': 'MobileNet', 'zoom_range': 0.17491582007715592, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 24, 'height_shift_range': 0.17900446279068127, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (4, 1, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (4, 1, 2) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (4, 1, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (4, 1, 3) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (4, 1, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 5
DEBUG:hpbandster:HBMASTER: submitting job (5, 0, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (4, 1, 3) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (4, 1, 3)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.01941162974885906, 'rotation_range': 18, 'optimizer': 'RMSProp', 'width_shift_range': 0.04513568081889169, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.20782785155774003, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:18:05.098308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (4, 1, 3), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (4, 1, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (4, 1, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (4, 1, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (4, 1, 3)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.04513568081889169, 'base_model': 'MobileNet', 'zoom_range': 0.01941162974885906, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 18, 'height_shift_range': 0.20782785155774003, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (4, 1, 3)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (4, 1, 3) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (5, 0, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (5, 0, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 4
DEBUG:hpbandster:HBMASTER: submitting job (4, 2, 0) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (5, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (5, 0, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (5, 0, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.07692945182444164, 'rotation_range': 9, 'optimizer': 'RMSProp', 'width_shift_range': 0.010179708849325042, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.13714309329605465, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:18:08.866943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (5, 0, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (5, 0, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (5, 0, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (5, 0, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (5, 0, 1)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.010179708849325042, 'base_model': 'MobileNet', 'zoom_range': 0.07692945182444164, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 9, 'height_shift_range': 0.13714309329605465, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (5, 0, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (5, 0, 1) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (4, 2, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (4, 2, 0) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 4
DEBUG:hpbandster:HBMASTER: submitting job (4, 2, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (4, 2, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (4, 2, 0) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (4, 2, 0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.10180136285014742, 'rotation_range': 23, 'optimizer': 'RMSProp', 'width_shift_range': 0.2300984585124779, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.28145985143580005, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:18:13.138878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (4, 2, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (4, 2, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (4, 2, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (4, 2, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (4, 2, 0)
args: ()
kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'width_shift_range': 0.2300984585124779, 'base_model': 'MobileNet', 'zoom_range': 0.10180136285014742, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 23, 'height_shift_range': 0.28145985143580005, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (4, 2, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (4, 2, 0) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (4, 2, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (4, 2, 1) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (4, 2, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 5
DEBUG:hpbandster:HBMASTER: submitting job (5, 0, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (4, 2, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (4, 2, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.015938011709855916, 'rotation_range': 0, 'optimizer': 'RMSProp', 'width_shift_range': 0.08177844833307447, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.27861119620061425, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:18:16.722602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (4, 2, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (4, 2, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (4, 2, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (4, 2, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (4, 2, 1)
args: ()
kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08177844833307447, 'base_model': 'MobileNet', 'zoom_range': 0.015938011709855916, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 0, 'height_shift_range': 0.27861119620061425, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (4, 2, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (4, 2, 1) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (5, 0, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (5, 0, 2) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 5
DEBUG:hpbandster:HBMASTER: submitting job (5, 0, 3) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (5, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (5, 0, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (5, 0, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.05785423416347163, 'rotation_range': 15, 'optimizer': 'RMSProp', 'width_shift_range': 0.12788768957202137, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.15529662601755292, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:18:21.570673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (5, 0, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (5, 0, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (5, 0, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (5, 0, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (5, 0, 2)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.12788768957202137, 'base_model': 'MobileNet', 'zoom_range': 0.05785423416347163, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 15, 'height_shift_range': 0.15529662601755292, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 233, in create_small_case
    os.path.join(train_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (5, 0, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (5, 0, 2) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 233, in create_small_case
    os.path.join(train_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (5, 0, 3)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (5, 0, 3) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (5, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 5
DEBUG:hpbandster:HBMASTER: submitting job (5, 0, 4) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: job (5, 0, 3) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (5, 0, 3)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.2637608521772452, 'rotation_range': 13, 'optimizer': 'RMSProp', 'width_shift_range': 0.10793254330563536, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.11099626103159914, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:18:26.700970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (5, 0, 3), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (5, 0, 3) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (5, 0, 3) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (5, 0, 3) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (5, 0, 3)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.10793254330563536, 'base_model': 'MobileNet', 'zoom_range': 0.2637608521772452, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 13, 'height_shift_range': 0.11099626103159914, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (5, 0, 3)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (5, 0, 3) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (5, 0, 4)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (5, 0, 4) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 5
DEBUG:hpbandster:HBMASTER: submitting job (5, 0, 5) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (5, 0, 4) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (5, 0, 4) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (5, 0, 4)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.1957228097459182, 'rotation_range': 21, 'optimizer': 'RMSProp', 'width_shift_range': 0.08129065562152957, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.026888568823989, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:18:30.585680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (5, 0, 4), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (5, 0, 4) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (5, 0, 4) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (5, 0, 4) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (5, 0, 4)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.08129065562152957, 'base_model': 'MobileNet', 'zoom_range': 0.1957228097459182, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 21, 'height_shift_range': 0.026888568823989, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 233, in create_small_case
    os.path.join(train_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (5, 0, 4)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (5, 0, 4) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 233, in create_small_case
    os.path.join(train_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (5, 0, 5)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (5, 0, 5) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (5, 0, 5) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (5, 0, 5) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (5, 0, 5)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.05657297447451116, 'rotation_range': 30, 'optimizer': 'RMSProp', 'width_shift_range': 0.12201527312060072, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.21921766792193806, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:18:38.874619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster:DISPATCHER: Starting worker discovery
DEBUG:hpbandster:DISPATCHER: Found 1 potential workers, 1 currently in the pool.
DEBUG:hpbandster:DISPATCHER: Finished worker discovery
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (5, 0, 5), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (5, 0, 5) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (5, 0, 5) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (5, 0, 5) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (5, 0, 5)
args: ()
kwargs: {'budget': 32.0, 'working_directory': '.', 'config': {'width_shift_range': 0.12201527312060072, 'base_model': 'MobileNet', 'zoom_range': 0.05657297447451116, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 30, 'height_shift_range': 0.21921766792193806, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 233, in create_small_case
    os.path.join(train_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (5, 0, 5)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (5, 0, 5) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 233, in create_small_case
    os.path.join(train_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 5
DEBUG:hpbandster:HBMASTER: submitting job (5, 1, 0) to dispatcher
DEBUG:hpbandster:DISPATCHER: trying to submit job (5, 1, 0)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (5, 1, 0) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 5
DEBUG:hpbandster:DISPATCHER: starting job (5, 1, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:HBMASTER: submitting job (5, 1, 1) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: j                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (5, 1, 0), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (5, 1, 0) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (5, 1, 0) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (5, 1, 0) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (5, 1, 0)
args: ()
kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'width_shift_range': 0.013148427504222493, 'base_model': 'MobileNet', 'zoom_range': 0.17867714353186268, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 3, 'height_shift_range': 0.29022864206524185, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (5, 1, 0)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (5, 1, 0) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!
DEBUG:hpbandster:DISPATCHER: trying to submit job (5, 1, 1)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (5, 1, 1) submitted to dispatcher
DEBUG:hpbandster:HBMASTER: schedule new run for iteration 5
DEBUG:hpbandster:HBMASTER: submitting job (5, 1, 2) to dispatcher
DEBUG:hpbandster:HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (5, 1, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: job (5, 1, 1) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (5, 1, 1)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.13469785570761497, 'rotation_range': 29, 'optimizer': 'RMSProp', 'width_shift_range': 0.09424699246147039, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.2788885116393651, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
2018-02-07 20:19:07.181596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (5, 1, 1), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (5, 1, 1) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (5, 1, 1) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (5, 1, 1) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (5, 1, 1)
args: ()
kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'width_shift_range': 0.09424699246147039, 'base_model': 'MobileNet', 'zoom_range': 0.13469785570761497, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 29, 'height_shift_range': 0.2788885116393651, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (5, 1, 1)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (5, 1, 1) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded

DEBUG:hpbandster:DISPATCHER: trying to submit job (5, 1, 2)
DEBUG:hpbandster:DISPATCHER: trying to notify the job_runner thread.
DEBUG:hpbandster:HBMASTER: job (5, 1, 2) submitted to dispatcher
DEBUG:hpbandster:DISPATCHER: Trying to submit another job.
DEBUG:hpbandster:DISPATCHER: starting job (5, 1, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: start processing job (5, 1, 2)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: args: ()
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'base_model': 'MobileNet', 'zoom_range': 0.0545189949114539, 'rotation_range': 21, 'optimizer': 'RMSProp', 'width_shift_range': 0.17934426151465938, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'num_dense_units_2': 1024, 'height_shift_range': 0.09367263433818859, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
DEBUG:hpbandster:DISPATCHER: job (5, 1, 2) dispatched on hpbandster.run_0.worker.tfpool20.19325140106390476544
DEBUG:hpbandster:DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!
2018-02-07 20:19:13.741879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:01:00.0)
DEBUG:hpbandster.run_0.worker.tfpool20.19325:WORKER: done with job (5, 1, 2), trying to register it.
INFO:hpbandster.run_0.worker.tfpool20.19325:WORKER: registered result for job (5, 1, 2) with dispatcher
DEBUG:hpbandster:DISPATCHER: job (5, 1, 2) finished
DEBUG:hpbandster:DISPATCHER: register_result: lock acquired
DEBUG:hpbandster:DISPATCHER: job (5, 1, 2) on hpbandster.run_0.worker.tfpool20.19325140106390476544 finished
DEBUG:hpbandster:job_id: (5, 1, 2)
args: ()
kwargs: {'budget': 64.0, 'working_directory': '.', 'config': {'width_shift_range': 0.17934426151465938, 'base_model': 'MobileNet', 'zoom_range': 0.0545189949114539, 'optimizer': 'RMSProp', 'num_dense_units_2': 1024, 'num_dense_layers': 3, 'cnn_learning_rate': 0.0001, 'cnn_unlock_epoch': 20, 'num_dense_units_1': 1024, 'learning_rate': 0.001, 'rotation_range': 21, 'height_shift_range': 0.09367263433818859, 'batch_size': 16, 'activation': 'relu', 'unfreeze_percentage': 0.1, 'num_dense_units_0': 1024}}
result: None
exception: Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5/site-packages/hpbandster-0.1.0-py3.5.egg/hpbandster/distributed/worker.py", line 106, in start_computation
    result = {'result': self.compute(*args, **kwargs),
  File "keras_hyperband.py", line 206, in compute
    *args, **kwargs)
  File "keras_hyperband.py", line 190, in keras_objective
    loss, runtime, histories = keras_model.train(config, epochs, save_data_path=base_path)
  File "/home/wilhelmb/Schreibtisch/Whales/keras_model.py", line 207, in train
    sub_dirs=True)
  File "/home/wilhelmb/Schreibtisch/Whales/utilities.py", line 241, in create_small_case
    os.path.join(valid_path, fn))
  File "/usr/lib/python3.5/shutil.py", line 235, in copy
    copyfile(src, dst, follow_symlinks=follow_symlinks)
  File "/usr/lib/python3.5/shutil.py", line 116, in copyfile
    copyfileobj(fsrc, fdst)
OSError: [Errno 122] Disk quota exceeded


DEBUG:hpbandster:job_callback for (5, 1, 2)
DEBUG:hpbandster:HBMASTER: Trying to run another job!
WARNING:hpbandster:job (5, 1, 2) failed with exception
Traceback (most recent call last):
  File "/home/wilhelmb/.local/lib/python3.5
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old directory removed data/model_train\n",
      "copy 34 images for whale # 1 in ordered list, called w_1287fbc\n",
      "copy 27 images for whale # 2 in ordered list, called w_98baff9\n",
      "copy 26 images for whale # 3 in ordered list, called w_7554f44\n",
      "copy 23 images for whale # 4 in ordered list, called w_1eafe46\n",
      "copy 22 images for whale # 5 in ordered list, called w_693c9ee\n",
      "copy 22 images for whale # 6 in ordered list, called w_ab4cae2\n",
      "copy 22 images for whale # 7 in ordered list, called w_fd1cb9d\n",
      "176  images of  7  whales copied\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "train_dir = \"data/model_train\"\n",
    "test_dir = \"data/model_test\"\n",
    "test_csv = \"data/model_test.csv\"\n",
    "num_classes = 7    # number of whales to be considered (in order of occuurence)\n",
    "max_pred = 5       # number of ranked predictions (default 5)\n",
    "batch_size = 16    # used for training as well as validation\n",
    "\n",
    "# create training environment for training data\n",
    "num_train_imgs = create_small_case(sel_whales = np.arange(1,num_classes+1),          # whales to be considered\n",
    "                                   small_dir = train_dir, \n",
    "                                   sub_dirs = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old directory removed data/model_test\n",
      "copy 34 images for whale # 1 in ordered list, called w_1287fbc\n",
      "copy 27 images for whale # 2 in ordered list, called w_98baff9\n",
      "copy 26 images for whale # 3 in ordered list, called w_7554f44\n",
      "copy 23 images for whale # 4 in ordered list, called w_1eafe46\n",
      "copy 22 images for whale # 5 in ordered list, called w_693c9ee\n",
      "copy 22 images for whale # 6 in ordered list, called w_ab4cae2\n",
      "copy 22 images for whale # 7 in ordered list, called w_fd1cb9d\n",
      "write csv file: data/model_test.csv\n",
      "176  images of  7  whales copied\n"
     ]
    }
   ],
   "source": [
    "# create training environment for validation data\n",
    "# for first testing make test directory same as train directory (no real solution !!)\n",
    "num_test_imgs = create_small_case(sel_whales = np.arange(1,num_classes+1),   # whales to be considered\n",
    "                                  small_dir = test_dir, \n",
    "                                  small_csv = test_csv,       # create csv file for later use                                  \n",
    "                                  sub_dirs = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 176 images belonging to 7 classes.\n",
      "{'w_7554f44': 3, 'w_1eafe46': 1, 'w_98baff9': 4, 'w_693c9ee': 2, 'w_ab4cae2': 5, 'w_fd1cb9d': 6, 'w_1287fbc': 0}\n",
      "{0: 'w_1287fbc', 1: 'w_1eafe46', 2: 'w_693c9ee', 3: 'w_7554f44', 4: 'w_98baff9', 5: 'w_ab4cae2', 6: 'w_fd1cb9d'}\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# define image generator\n",
    "train_gen = image.ImageDataGenerator()\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "train_flow = train_gen.flow_from_directory(train_dir, batch_size = batch_size)\n",
    "whale_class_map = (train_flow.class_indices)           # get dict mapping whalenames --> class_no\n",
    "class_whale_map = make_label_dict(directory=train_dir) # get dict mapping class_no --> whalenames\n",
    "print(whale_class_map)\n",
    "print(class_whale_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 79s - loss: 6.0587\n",
      "Epoch 2/5\n",
      " - 84s - loss: 6.6013\n",
      "Epoch 3/5\n",
      " - 79s - loss: 3.5672\n",
      "Epoch 4/5\n",
      " - 84s - loss: 4.1117\n",
      "Epoch 5/5\n",
      " - 81s - loss: 3.4059\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_flow, verbose = 2, steps_per_epoch=num_train_imgs//batch_size, epochs=5)                        \n",
    "\n",
    "# let's predict the test set to see a rough score\n",
    "labels = make_label_dict(directory=train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 176 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_gen = image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "valid_flow = valid_gen.flow_from_directory(test_dir, target_size = (299,299), class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 234s 39s/step\n",
      "(176, 7)\n",
      "[[  1.43390670e-01   1.20498249e-02   9.96106640e-02   1.70189682e-02\n",
      "    2.39478111e-01   3.71767074e-01   1.16684653e-01]\n",
      " [  3.59858155e-01   5.44713298e-03   6.46971539e-02   4.19636928e-02\n",
      "    1.20005965e-01   3.64625931e-01   4.34020013e-02]\n",
      " [  7.32351840e-01   6.97384530e-04   9.58802830e-03   8.39053129e-04\n",
      "    1.41878715e-02   6.60437346e-02   1.76291972e-01]\n",
      " [  1.36970937e-01   1.69535000e-02   8.93628374e-02   1.72086097e-02\n",
      "    1.72094017e-01   4.66754287e-01   1.00655846e-01]\n",
      " [  1.88263923e-01   1.35726733e-02   1.01994358e-01   2.51630675e-02\n",
      "    1.50598407e-01   3.19591492e-01   2.00816125e-01]\n",
      " [  2.46684030e-01   1.36084538e-02   1.70694068e-02   5.85768605e-03\n",
      "    2.94588115e-02   2.99378067e-01   3.87943566e-01]\n",
      " [  2.92610496e-01   1.54833402e-02   4.02200632e-02   1.01385666e-02\n",
      "    4.00396556e-01   1.20670527e-01   1.20480441e-01]\n",
      " [  1.86274096e-01   3.46491598e-02   8.29836577e-02   2.01654173e-02\n",
      "    1.50789559e-01   3.28331083e-01   1.96807086e-01]\n",
      " [  7.07709372e-01   2.85713887e-03   3.81740443e-02   1.19480968e-03\n",
      "    2.83940081e-02   5.51139861e-02   1.66556627e-01]\n",
      " [  3.58660042e-01   1.18677849e-02   4.60921973e-02   7.53225572e-03\n",
      "    9.98836011e-02   1.37698948e-01   3.38265091e-01]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_generator(valid_flow, verbose = 1)\n",
    "print(preds.shape)\n",
    "print(preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels: \n",
      " [['w_ab4cae2' 'w_98baff9' 'w_1287fbc' 'w_fd1cb9d' 'w_693c9ee']\n",
      " ['w_ab4cae2' 'w_1287fbc' 'w_98baff9' 'w_693c9ee' 'w_fd1cb9d']\n",
      " ['w_1287fbc' 'w_fd1cb9d' 'w_ab4cae2' 'w_98baff9' 'w_693c9ee']\n",
      " ['w_ab4cae2' 'w_98baff9' 'w_1287fbc' 'w_fd1cb9d' 'w_693c9ee']\n",
      " ['w_ab4cae2' 'w_fd1cb9d' 'w_1287fbc' 'w_98baff9' 'w_693c9ee']\n",
      " ['w_fd1cb9d' 'w_ab4cae2' 'w_1287fbc' 'w_98baff9' 'w_693c9ee']\n",
      " ['w_98baff9' 'w_1287fbc' 'w_ab4cae2' 'w_fd1cb9d' 'w_693c9ee']\n",
      " ['w_ab4cae2' 'w_fd1cb9d' 'w_1287fbc' 'w_98baff9' 'w_693c9ee']\n",
      " ['w_1287fbc' 'w_fd1cb9d' 'w_ab4cae2' 'w_693c9ee' 'w_98baff9']\n",
      " ['w_1287fbc' 'w_fd1cb9d' 'w_ab4cae2' 'w_98baff9' 'w_693c9ee']]\n",
      "model predictions: \n",
      " ['w_1287fbc' 'w_fd1cb9d' 'w_fd1cb9d' 'w_1287fbc' 'w_7554f44' 'w_1eafe46'\n",
      " 'w_98baff9' 'w_98baff9' 'w_7554f44' 'w_693c9ee']\n"
     ]
    }
   ],
   "source": [
    "# ge list of model predictions: one ordered list of maxpred whalenames per image\n",
    "top_k = preds.argsort()[:, -max_preds:][:, ::-1]    \n",
    "model_preds = [([class_whale_map[i] for i in line]) for line in top_k]  \n",
    "\n",
    "# get list of true labels: one whalename per image\n",
    "valid_list = read_csv(file_name = test_csv)    # list with (filename, whalename)\n",
    "true_labels = []\n",
    "for fn in valid_flow.filenames:\n",
    "    offset, filename = fn.split('/')\n",
    "    whale = [line[1] for line in valid_list if line[0]==filename][0]\n",
    "    true_labels.append(whale)\n",
    "\n",
    "print(\"true labels: \\n\", np.array(model_preds)[:10])\n",
    "print(\"model predictions: \\n\", np.array(true_labels)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP 0.320359848485\n",
      "Dummy MAP uniform 0.258712121212\n",
      "Dummy MAP weighted 0.260700757576\n"
     ]
    }
   ],
   "source": [
    "MAP = mean_average_precision(model_preds, true_labels, max_preds)\n",
    "print(\"MAP\", MAP)\n",
    "\n",
    "Dummy_map = Dummy_MAP(probs = 'weighted', distributed_as = test_csv, image_no = len(valid_list))\n",
    "print(\"Dummy MAP weighted\", Dummy_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
